{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "k1gpzj4guo8e1riwj3om1k"
   },
   "source": [
    "### N-gram language models or how to write scientific papers (4 pts)\n",
    "\n",
    "We shall train our language model on a corpora of [ArXiv](http://arxiv.org/) articles and see if we can generate a new one!\n",
    "\n",
    "![img](https://media.npr.org/assets/img/2013/12/10/istock-18586699-monkey-computer_brick-16e5064d3378a14e0e4c2da08857efe03c04695e-s800-c85.jpg)\n",
    "\n",
    "_data by neelshah18 from [here](https://www.kaggle.com/neelshah18/arxivdataset/)_\n",
    "\n",
    "_Disclaimer: this has nothing to do with actual science. But it's fun, so who cares?!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "u8jdaiy68oib3jvr4k01"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "0c76vnyl3zui9yhtkodgrlf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>day</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>month</th>\n",
       "      <th>summary</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12230</th>\n",
       "      <td>[{'name': 'Yunchuan Kong'}, {'name': 'Xiaodan ...</td>\n",
       "      <td>24</td>\n",
       "      <td>1710.08846v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>10</td>\n",
       "      <td>We present a new model-based integrative metho...</td>\n",
       "      <td>[{'term': 'stat.ML', 'scheme': 'http://arxiv.o...</td>\n",
       "      <td>A Bayesian Method for Joint Clustering of Vect...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7124</th>\n",
       "      <td>[{'name': 'Amal Rannen Triki'}, {'name': 'Maxi...</td>\n",
       "      <td>18</td>\n",
       "      <td>1710.06703v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>10</td>\n",
       "      <td>Deep neural networks (DNNs) have become increa...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Stochastic Weighted Function Norm Regularization</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26646</th>\n",
       "      <td>[{'name': 'Junbo Wang'}, {'name': 'Wei Wang'},...</td>\n",
       "      <td>17</td>\n",
       "      <td>1611.05592v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>11</td>\n",
       "      <td>Video captioning which automatically translate...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Multimodal Memory Modelling for Video Captioning</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33543</th>\n",
       "      <td>[{'name': 'Boulif Menouar'}]</td>\n",
       "      <td>16</td>\n",
       "      <td>1612.05536v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>12</td>\n",
       "      <td>Cell formation is a critical step in the desig...</td>\n",
       "      <td>[{'term': 'cs.DM', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>A new cut-based genetic algorithm for graph pa...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29661</th>\n",
       "      <td>[{'name': 'Helen L. Bear'}, {'name': 'Gari Owe...</td>\n",
       "      <td>3</td>\n",
       "      <td>1710.01084v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>10</td>\n",
       "      <td>In the quest for greater computer lip-reading ...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Some observations on computer lip-reading: mov...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  author  day            id  \\\n",
       "12230  [{'name': 'Yunchuan Kong'}, {'name': 'Xiaodan ...   24  1710.08846v1   \n",
       "7124   [{'name': 'Amal Rannen Triki'}, {'name': 'Maxi...   18  1710.06703v1   \n",
       "26646  [{'name': 'Junbo Wang'}, {'name': 'Wei Wang'},...   17  1611.05592v1   \n",
       "33543                       [{'name': 'Boulif Menouar'}]   16  1612.05536v1   \n",
       "29661  [{'name': 'Helen L. Bear'}, {'name': 'Gari Owe...    3  1710.01084v1   \n",
       "\n",
       "                                                    link  month  \\\n",
       "12230  [{'rel': 'alternate', 'href': 'http://arxiv.or...     10   \n",
       "7124   [{'rel': 'alternate', 'href': 'http://arxiv.or...     10   \n",
       "26646  [{'rel': 'alternate', 'href': 'http://arxiv.or...     11   \n",
       "33543  [{'rel': 'alternate', 'href': 'http://arxiv.or...     12   \n",
       "29661  [{'rel': 'alternate', 'href': 'http://arxiv.or...     10   \n",
       "\n",
       "                                                 summary  \\\n",
       "12230  We present a new model-based integrative metho...   \n",
       "7124   Deep neural networks (DNNs) have become increa...   \n",
       "26646  Video captioning which automatically translate...   \n",
       "33543  Cell formation is a critical step in the desig...   \n",
       "29661  In the quest for greater computer lip-reading ...   \n",
       "\n",
       "                                                     tag  \\\n",
       "12230  [{'term': 'stat.ML', 'scheme': 'http://arxiv.o...   \n",
       "7124   [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...   \n",
       "26646  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n",
       "33543  [{'term': 'cs.DM', 'scheme': 'http://arxiv.org...   \n",
       "29661  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n",
       "\n",
       "                                                   title  year  \n",
       "12230  A Bayesian Method for Joint Clustering of Vect...  2017  \n",
       "7124    Stochastic Weighted Function Norm Regularization  2017  \n",
       "26646   Multimodal Memory Modelling for Video Captioning  2016  \n",
       "33543  A new cut-based genetic algorithm for graph pa...  2016  \n",
       "29661  Some observations on computer lip-reading: mov...  2017  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative manual download link: https://yadi.sk/d/_nGyU2IajjR9-w\n",
    "# !wget \"https://www.dropbox.com/s/99az9n1b57qkd9j/arxivData.json.tar.gz?dl=1\" -O arxivData.json.tar.gz\n",
    "# !tar -xvzf arxivData.json.tar.gz\n",
    "data = pd.read_json(\"./resources/arxivData.json\")\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations between several\\nparts of the image and question. Our single model outperforms the first place\\nwinner on the VQA 1.0 dataset, performs within margin to the current\\nstate-of-the-art ensemble model. We also experiment with replacing attention\\nmechanisms in other state-of-the-art models with our implementation and show\\nincreased accuracy. In both cases, our recurrent attention mechanism improves\\nperformance in tasks requiring sequential or relational reasoning on the VQA\\ndataset.',\n",
       "       'Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a document or utterances in a dialog),\\nand most existing ANN-based systems do not leverage the preceding short texts\\nwhen classifying a subsequent one. In this work, we present a model based on\\nrecurrent neural networks and convolutional neural networks that incorporates\\nthe preceding short texts. Our model achieves state-of-the-art results on three\\ndifferent datasets for dialog act prediction.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.summary.values[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "lbyqb5rx7j8jpo591r06ak"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Differential Contrastive Divergence ; This paper has been retracted.',\n",
       " 'What Does Artificial Life Tell Us About Death? ; Short philosophical essay',\n",
       " 'P=NP ; We claim to resolve the P=?NP problem via a formal argument for P=NP.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assemble lines: concatenate title and description\n",
    "lines = data.apply(lambda row: row['title'] + ' ; ' + row['summary'].replace('\\n', ' '), axis=1).tolist()\n",
    "\n",
    "sorted(lines, key=len)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7u97m5s8ekl5zd5a43a1yc"
   },
   "source": [
    "# Tokenization\n",
    "\n",
    "You know the dril. The data is messy. Go clean the data. Use WordPunctTokenizer or something.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "u8rvfk719iek97t3rarwr"
   },
   "outputs": [],
   "source": [
    "# Task: convert lines (in-place) into strings of space-separated tokens. import & use WordPunctTokenizer\n",
    "\n",
    "lines = [' '.join(tokenizer.tokenize(line.lower())) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellId": "w88nddpp2k8edoeyyyjh0l"
   },
   "outputs": [],
   "source": [
    "assert sorted(lines, key=len)[0] == \\\n",
    "    'differential contrastive divergence ; this paper has been retracted .'\n",
    "assert sorted(lines, key=len)[2] == \\\n",
    "    'p = np ; we claim to resolve the p =? np problem via a formal argument for p = np .'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qb6h3hxmr095egzv8rlzul"
   },
   "source": [
    "### N-Gram Language Model (1point)\n",
    "\n",
    "A language model is a probabilistic model that estimates text probability: the joint probability of all tokens $w_t$ in text $X$: $P(X) = P(w_1, \\dots, w_T)$.\n",
    "\n",
    "It can do so by following the chain rule:\n",
    "$$P(w_1, \\dots, w_T) = P(w_1)P(w_2 \\mid w_1)\\dots P(w_T \\mid w_1, \\dots, w_{T-1}).$$ \n",
    "\n",
    "The problem with such approach is that the final term $P(w_T \\mid w_1, \\dots, w_{T-1})$ depends on $n-1$ previous words. This probability is impractical to estimate for long texts, e.g. $T = 1000$.\n",
    "\n",
    "One popular approximation is to assume that next word only depends on a finite amount of previous words:\n",
    "\n",
    "$$P(w_t \\mid w_1, \\dots, w_{t - 1}) = P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1})$$\n",
    "\n",
    "Such model is called __n-gram language model__ where n is a parameter. For example, in 3-gram language model, each word only depends on 2 previous words. \n",
    "\n",
    "$$\n",
    "    P(w_1, \\dots, w_n) = \\prod_t P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1}).\n",
    "$$\n",
    "\n",
    "You can also sometimes see such approximation under the name of _n-th order markov assumption_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "u68wydbiioqlp5gl96mhd"
   },
   "source": [
    "The first stage to building such a model is counting all word occurences given N-1 previous words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2)\n",
      "(1, 2, 3)\n",
      "(2, 3, 4)\n",
      "(3, 4, 5)\n",
      "(4, 5, 6)\n",
      "(5, 6, 7)\n",
      "(6, 7, 8)\n"
     ]
    }
   ],
   "source": [
    "a=[i for i in range(10)]\n",
    "n=4\n",
    "for i in range(n-1,len(a)):\n",
    "    print(tuple(a[i-(n-1):i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "cellId": "og84gjipnumsakhiiu9ap"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# special tokens: \n",
    "# - unk represents absent tokens, \n",
    "# - eos is a special token after the end of sequence\n",
    "\n",
    "UNK, EOS = \"_UNK_\", \"_EOS_\"\n",
    "\n",
    "def count_ngrams(lines, n):\n",
    "    \"\"\"\n",
    "    Count how many times each word occured after (n - 1) previous words\n",
    "    :param lines: an iterable of strings with space-separated tokens\n",
    "    :returns: a dictionary { tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2}}\n",
    "\n",
    "    When building counts, please consider the following two edge cases\n",
    "    - if prefix is shorter than (n - 1) tokens, it should be padded with UNK. For n=3,\n",
    "      empty prefix: \"\" -> (UNK, UNK)\n",
    "      short prefix: \"the\" -> (UNK, the)\n",
    "      long prefix: \"the new approach\" -> (new, approach)\n",
    "    - you should add a special token, EOS, at the end of each sequence\n",
    "      \"... with deep neural networks .\" -> (..., with, deep, neural, networks, ., EOS)\n",
    "      count the probability of this token just like all others.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(Counter)\n",
    "    \n",
    "    for line in lines:\n",
    "        tokens = [UNK]*(n-1) +line.split(' ') + [EOS]\n",
    "        for i in range(n-1,len(tokens)):\n",
    "            counts[tuple(tokens[i-(n-1):i])][tokens[i]]+=1\n",
    "#             counts[(tokens[i-2],tokens[i-1])][tokens[i]]+=1\n",
    "    # counts[(word1, word2)][word3] = how many times word3 occured after (word1, word2)    \n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "cellId": "xyf2he6lak9mmqarl3nck"
   },
   "outputs": [],
   "source": [
    "# let's test it\n",
    "dummy_lines = sorted(lines, key=len)[:100]\n",
    "dummy_counts = count_ngrams(dummy_lines, n=3)\n",
    "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
    "assert len(dummy_counts[('_UNK_', '_UNK_')]) == 78\n",
    "assert dummy_counts['_UNK_', 'a']['note'] == 3\n",
    "assert dummy_counts['p', '=']['np'] == 2\n",
    "assert dummy_counts['author', '.']['_EOS_'] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4j620npeqvj0k8ak8xqx8xk"
   },
   "source": [
    "Once we can count N-grams, we can build a probabilistic language model.\n",
    "The simplest way to compute probabilities is in proporiton to counts:\n",
    "\n",
    "$$ P(w_t | prefix) = { Count(prefix, w_t) \\over \\sum_{\\hat w} Count(prefix, \\hat w) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 1, 'c': 9}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'b':1,'c':3}\n",
    "for i in a:\n",
    "    a[i]**=2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "cellId": "c7cm76wmzlaa12bctznzei"
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModel:    \n",
    "    def __init__(self, lines, n):\n",
    "        \"\"\" \n",
    "        Train a simple count-based language model: \n",
    "        compute probabilities P(w_t | prefix) given ngram counts\n",
    "        \n",
    "        :param n: computes probability of next token given (n - 1) previous words\n",
    "        :param lines: an iterable of strings with space-separated tokens\n",
    "        \"\"\"\n",
    "        assert n >= 1\n",
    "        self.n = n\n",
    "    \n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        \n",
    "        # compute token proabilities given counts\n",
    "        self.probs = defaultdict(dict)\n",
    "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
    "        \n",
    "        # populate self.probs with actual probabilities\n",
    "        for prefix in counts.keys():\n",
    "            for word in counts[prefix].keys():\n",
    "                self.probs[prefix][word] = counts[prefix][word] / sum(counts[prefix].values())\n",
    "        \n",
    "#         for word1, word2 in counts.keys():\n",
    "#             for word3 in counts[(word1, word2)].keys():\n",
    "#                 self.probs[(word1, word2)][word3] = counts[(word1, word2)][word3]/ sum(counts[(word1, word2)].values())\n",
    "            \n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :returns: a dictionary {token : it's probability} for all tokens with positive probabilities\n",
    "        \"\"\"\n",
    "        prefix = prefix.split()\n",
    "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
    "        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n",
    "        return self.probs[tuple(prefix)]\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :param next_token: the next token to predict probability for\n",
    "        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n",
    "        \"\"\"\n",
    "        return self.get_possible_next_tokens(prefix).get(next_token, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "0ftnn4nmuzrup6c0vvhb8q"
   },
   "source": [
    "Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "cellId": "a7zajcnvhqupvcrmacvkur"
   },
   "outputs": [],
   "source": [
    "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
    "\n",
    "p_initial = dummy_lm.get_possible_next_tokens('') # '' -> ['_UNK_', '_UNK_']\n",
    "assert np.allclose(p_initial['learning'], 0.02)\n",
    "assert np.allclose(p_initial['a'], 0.13)\n",
    "assert np.allclose(p_initial.get('meow', 0), 0)\n",
    "assert np.allclose(sum(p_initial.values()), 1)\n",
    "\n",
    "p_a = dummy_lm.get_possible_next_tokens('a') # '' -> ['_UNK_', 'a']\n",
    "assert np.allclose(p_a['machine'], 0.15384615)\n",
    "assert np.allclose(p_a['note'], 0.23076923)\n",
    "assert np.allclose(p_a.get('the', 0), 0)\n",
    "assert np.allclose(sum(p_a.values()), 1)\n",
    "\n",
    "assert np.allclose(dummy_lm.get_possible_next_tokens('a note')['on'], 1)\n",
    "assert dummy_lm.get_possible_next_tokens('a machine') == \\\n",
    "    dummy_lm.get_possible_next_tokens(\"there have always been ghosts in a machine\"), \\\n",
    "    \"your 3-gram model should only depend on 2 previous words\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oh8r9a41kuk4r51wra9"
   },
   "source": [
    "Now that you've got a working n-gram language model, let's see what sequences it can generate. But first, let's train it on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "cellId": "f17xoejjppmooo2nopw4xo"
   },
   "outputs": [],
   "source": [
    "lm = NGramLanguageModel(lines, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2kd9glwnkr470qc4bt7f1e"
   },
   "source": [
    "The process of generating sequences is... well, it's sequential. You maintain a list of tokens and iteratively add next token by sampling with probabilities.\n",
    "\n",
    "$ X = [] $\n",
    "\n",
    "__forever:__\n",
    "* $w_{next} \\sim P(w_{next} | X)$\n",
    "* $X = concat(X, w_{next})$\n",
    "\n",
    "\n",
    "Instead of sampling with probabilities, one can also try always taking most likely token, sampling among top-K most likely tokens or sampling with temperature. In the latter case (temperature), one samples from\n",
    "\n",
    "$$w_{next} \\sim {P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{\\hat w} P(\\hat w | X) ^ {1 / \\tau}}$$\n",
    "\n",
    "Where $\\tau > 0$ is model temperature. If $\\tau << 1$, more likely tokens will be sampled with even higher probability while less likely tokens will vanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "cellId": "sgbatlm9vzb4z889fho7"
   },
   "outputs": [],
   "source": [
    "def get_next_token(lm, prefix, temperature=1.0):\n",
    "    \"\"\"\n",
    "    return next token after prefix;\n",
    "    :param temperature: samples proportionally to lm probabilities ^ (1 / temperature)\n",
    "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    \"\"\"\n",
    "    # Get possible next tokens\n",
    "    # next_tokens -> dict{token1:p1, token2:p2...}\n",
    "    next_token_probability = lm.get_possible_next_tokens(prefix).copy()\n",
    "    if temperature==0:\n",
    "        # Return the most likely token\n",
    "        return sorted(next_token_probability,key=next_token_probability.get,reverse=True)[0]\n",
    "    else:\n",
    "        for key in next_token_probability:\n",
    "            next_token_probability[key] **=(1/temperature)\n",
    "            \n",
    "        new_sum = sum(next_token_probability.values())\n",
    "        \n",
    "        for key in next_token_probability:\n",
    "            next_token_probability[key] /=new_sum\n",
    "            \n",
    "        return list(next_token_probability.keys())[np.random.choice(len(next_token_probability), 1, p=list(next_token_probability.values()))[0]]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'been': 0.9083969465648855, 'not': 0.03816793893129771, 'only': 0.015267175572519083, 'also': 0.015267175572519083, 'lately': 0.007633587786259542, 'very': 0.007633587786259542, 'occurred': 0.007633587786259542}\n",
      "{'been': 0.5749535115459828, 'not': 0.11785397966402933, 'only': 0.07453740141069969, 'also': 0.07453740141069969, 'lately': 0.05270590198952948, 'very': 0.05270590198952948, 'occurred': 0.05270590198952948}\n"
     ]
    }
   ],
   "source": [
    "temperature=2\n",
    "test = lm.get_possible_next_tokens('there have').copy()\n",
    "print(test)\n",
    "\n",
    "for key in test:\n",
    "    test[key] **=(1/temperature)\n",
    "\n",
    "new_sum = sum(test.values())\n",
    "\n",
    "for key in test:\n",
    "    test[key] /=new_sum\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'been': 9049,\n",
       "         'very': 75,\n",
       "         'only': 175,\n",
       "         'not': 399,\n",
       "         'lately': 86,\n",
       "         'also': 142,\n",
       "         'occurred': 74})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_freqs = Counter([get_next_token(lm, 'there have') for _ in range(10000)])\n",
    "test_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "cellId": "98l40131wjtd5xbdm5b2nr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks nice!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "test_freqs = Counter([get_next_token(lm, 'there have') for _ in range(10000)])\n",
    "assert 250 < test_freqs['not'] < 450\n",
    "assert 8500 < test_freqs['been'] < 9500\n",
    "assert 1 < test_freqs['lately'] < 200\n",
    "\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=1.0) for _ in range(10000)])\n",
    "assert 1500 < test_freqs['learning'] < 3000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.5) for _ in range(10000)])\n",
    "assert 8000 < test_freqs['learning'] < 9000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.0) for _ in range(10000)])\n",
    "assert test_freqs['learning'] == 10000\n",
    "\n",
    "print(\"Looks nice!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ux4n8iq523n4s3ftrelhxj"
   },
   "source": [
    "Let's have fun with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "cellId": "1nnnycga61rijt6nd8zai"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial neural networks ) would lead to the baseline , while preserving their identity has been whether dl - lite , that collaboratively contribute to belief change ; languages for which they can specify the relations among features from the rest is based on bayesian networks . this method can also achieve competitive accuracy . extensive experiments on various benchmarks and achieve a base transceiver station ( bts ) broadcasts multiple data ( e . g . classification of demographic dynamics within it to provide high - accuracy . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'artificial' # <- your ideas :)\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "cellId": "pxyjsv3b7r8thdfxlgitl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bridging the gap between the two tasks : ( i . e . g ., the number of layers , and the algorithm . we also propose a probabilistic model for the purpose of this paper , we propose a novel and robust method even outperforms it for learning . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'bridging the' # <- more of your ideas\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix, temperature=0.5)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what i can say that there are three - dimensional data and real - time and space complexities at once . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'what i can say' # <- more of your ideas\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix, temperature=0.5)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2n90bscmzfko0qnctp7ysc"
   },
   "source": [
    "__More in the homework:__ nucleous sampling, top-k sampling, beam search(not for the faint of heart)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3gdmey7g8at5n5c5x4gayh"
   },
   "source": [
    "### Evaluating language models: perplexity (1point)\n",
    "\n",
    "Perplexity is a measure of how well does your model approximate true probability distribution behind data. __Smaller perplexity = better model__.\n",
    "\n",
    "To compute perplexity on one sentence, use:\n",
    "$$\n",
    "    {\\mathbb{P}}(w_1 \\dots w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_t P(w_t \\mid w_{t - n}, \\dots, w_{t - 1})\\right)^{-\\frac1N},\n",
    "$$\n",
    "\n",
    "\n",
    "On the corpora level, perplexity is a product of probabilities of all tokens in all sentences to the power of 1, divided by __total length of all sentences__ in corpora.\n",
    "\n",
    "This number can quickly get too small for float32/float64 precision, so we recommend you to first compute log-perplexity (from log-probabilities) and then take the exponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-115.12925464970229"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(10 ** -50.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "cellId": "5hp010xyzzb4vqewo1bhny"
   },
   "outputs": [],
   "source": [
    "def perplexity(lm, lines, min_logprob=np.log(10 ** -50.)):\n",
    "    \"\"\"\n",
    "    :param lines: a list of strings with space-separated tokens\n",
    "    :param min_logprob: if log(P(w | ...)) is smaller than min_logprop, set it equal to min_logrob\n",
    "    :returns: corpora-level perplexity - a single scalar number from the formula above\n",
    "    \n",
    "    Note: do not forget to compute P(w_first | empty) and P(eos | full_sequence)\n",
    "    \n",
    "    PLEASE USE lm.get_next_token_prob and NOT lm.get_possible_next_tokens\n",
    "    \"\"\"\n",
    "    UNK, EOS = \"_UNK_\", \"_EOS_\"\n",
    "    corpora_length=0\n",
    "    log_lines_perplexity = []\n",
    "    # Walk through each line\n",
    "    for line in lines:\n",
    "        tokens = line.split(' ') + [EOS]\n",
    "        log_line_perplexity=0\n",
    "        N=0\n",
    "        # Walk through each token\n",
    "        for i in range(len(tokens)):\n",
    "            log_line_perplexity += max(np.log(lm.get_next_token_prob(prefix=' '.join(tokens[:i]), next_token=tokens[i])), min_logprob)\n",
    "            N+=1\n",
    "            \n",
    "        corpora_length+=N\n",
    "#         print(log_line_perplexity,N,log_line_perplexity*(-1/N))\n",
    "        log_lines_perplexity.append(log_line_perplexity)\n",
    "    \n",
    "    return  np.exp(sum(log_lines_perplexity) / -corpora_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307.24502881156855"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1 = NGramLanguageModel(dummy_lines, n=1)\n",
    "ppx1 = perplexity(lm1, dummy_lines[:10])\n",
    "ppx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "cellId": "8b689bobhkey04x7pabupj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexities: ppx1=318.213 ppx3=1.520 ppx10=1.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-264-91263a57f5af>:21: RuntimeWarning: divide by zero encountered in log\n",
      "  log_line_perplexity += max(np.log(lm.get_next_token_prob(prefix=' '.join(tokens[:i]), next_token=tokens[i])), min_logprob)\n"
     ]
    }
   ],
   "source": [
    "lm1 = NGramLanguageModel(dummy_lines, n=1)\n",
    "lm3 = NGramLanguageModel(dummy_lines, n=3)\n",
    "lm10 = NGramLanguageModel(dummy_lines, n=10)\n",
    "\n",
    "ppx1 = perplexity(lm1, dummy_lines)\n",
    "ppx3 = perplexity(lm3, dummy_lines)\n",
    "ppx10 = perplexity(lm10, dummy_lines)\n",
    "ppx_missing = perplexity(lm3, ['the jabberwock , with eyes of flame , '])  # thanks, L. Carrol\n",
    "\n",
    "print(\"Perplexities: ppx1=%.3f ppx3=%.3f ppx10=%.3f\" % (ppx1, ppx3, ppx10))\n",
    "\n",
    "assert all(0 < ppx < 500 for ppx in (ppx1, ppx3, ppx10)), \"perplexity should be nonnegative and reasonably small\"\n",
    "assert ppx1 > ppx3 > ppx10, \"higher N models should overfit and \"\n",
    "assert np.isfinite(ppx_missing) and ppx_missing > 10 ** 6, \"missing words should have large but finite perplexity. \" \\\n",
    "    \" Make sure you use min_logprob right\"\n",
    "assert np.allclose([ppx1, ppx3, ppx10], (318.2132342216302, 1.5199996213739575, 1.1838145037901249))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ypc4lks4vs1li908fqi8"
   },
   "source": [
    "Now let's measure the actual perplexity: we'll split the data into train and test and score model on test data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "cellId": "tjnehsem2lmijkg2lto4w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-264-91263a57f5af>:21: RuntimeWarning: divide by zero encountered in log\n",
      "  log_line_perplexity += max(np.log(lm.get_next_token_prob(prefix=' '.join(tokens[:i]), next_token=tokens[i])), min_logprob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 1832.23136\n",
      "N = 2, Perplexity = 85653987.28543\n",
      "N = 3, Perplexity = 61999196239911532363776.00000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, test_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
    "\n",
    "for n in (1, 2, 3):\n",
    "    lm = NGramLanguageModel(n=n, lines=train_lines)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "38nfbfkpzgfxik8kccyt1l"
   },
   "outputs": [],
   "source": [
    "# whoops, it just blew up :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oopn2o57wxm9vbxzycytce"
   },
   "source": [
    "### LM Smoothing\n",
    "\n",
    "The problem with our simple language model is that whenever it encounters an n-gram it has never seen before, it assigns it with the probabilitiy of 0. Every time this happens, perplexity explodes.\n",
    "\n",
    "To battle this issue, there's a technique called __smoothing__. The core idea is to modify counts in a way that prevents probabilities from getting too low. The simplest algorithm here is Additive smoothing (aka [Lapace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)):\n",
    "\n",
    "$$ P(w_t | prefix) = { Count(prefix, w_t) + \\delta \\over \\sum_{\\hat w} (Count(prefix, \\hat w) + \\delta) } $$\n",
    "\n",
    "If counts for a given prefix are low, additive smoothing will adjust probabilities to a more uniform distribution. Not that the summation in the denominator goes over _all words in the vocabulary_.\n",
    "\n",
    "Here's an example code we've implemented for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "cellId": "ioh26rlov6g8l2ssj1c8pm"
   },
   "outputs": [],
   "source": [
    "class LaplaceLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" this code is an example, no need to change anything \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.n = n\n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        self.vocab = set(token for token_counts in counts.values() for token in token_counts)\n",
    "        self.probs = defaultdict(Counter)\n",
    "\n",
    "        for prefix in counts:\n",
    "            token_counts = counts[prefix]\n",
    "            total_count = sum(token_counts.values()) + delta * len(self.vocab)\n",
    "            self.probs[prefix] = {token: (token_counts[token] + delta) / total_count\n",
    "                                          for token in token_counts}\n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        return {token: token_probs.get(token, missing_prob) for token in self.vocab}\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        if next_token in token_probs:\n",
    "            return token_probs[next_token]\n",
    "        else:\n",
    "            missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "            missing_prob_total = max(0, missing_prob_total) # prevent rounding errors\n",
    "            return missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "90vsann3920ie05r2blbmi",
    "execution_id": "3868303d-0bb9-42c6-a9a8-dcf485c8220c"
   },
   "source": [
    "**Disclaimer**: the implementation above assumes all words unknown within a given context to be equally likely, *as well as the words outside of vocabulary*. Therefore, its' perplexity will be lower than it should when encountering such words. Therefore, comparing it with a model with less unknown words will not be fair. When implementing your own smoothing, you may handle this by adding a virtual `UNK` token of non-zero probability. Technically, this will result in a model where probabilities do not add up to $1$, but it is close enough for a practice excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "cellId": "3xvxkdxcmfqucruyt66mdc"
   },
   "outputs": [],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = LaplaceLanguageModel(dummy_lines, n=n)\n",
    "    assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "cellId": "j6zqa50koitjjri9ipd8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 977.67559\n",
      "N = 2, Perplexity = 470.48021\n",
      "N = 3, Perplexity = 3679.44765\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = LaplaceLanguageModel(train_lines, n=n, delta=0.1)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "pjuqt30jcerwbz1ym9zv1"
   },
   "outputs": [],
   "source": [
    "# optional: try to sample tokens from such a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT FINISH YET!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3b8s1y9uls4fosu3yp28gg"
   },
   "source": [
    "### Kneser-Ney smoothing (2 points)\n",
    "\n",
    "Additive smoothing is simple, reasonably good but definitely not a State of The Art algorithm.\n",
    "\n",
    "\n",
    "Your final task in this notebook is to implement [Kneser-Ney](https://en.wikipedia.org/wiki/Kneser%E2%80%93Ney_smoothing) smoothing.\n",
    "\n",
    "It can be computed recurrently, for n>1:\n",
    "\n",
    "$$P_{kn}(w_t | prefix_{n-1}) = { \\max(0, Count(prefix_{n-1}, w_t) - \\delta) \\over \\sum_{\\hat w} Count(prefix_{n-1}, \\hat w)} + \\lambda_{prefix_{n-1}} \\cdot P_{kn}(w_t | prefix_{n-2})$$\n",
    "\n",
    "where\n",
    "- $prefix_{n-1}$ is a tuple of {n-1} previous tokens\n",
    "- $lambda_{prefix_{n-1}}$ is a normalization constant chosen so that probabilities add up to 1\n",
    "- Unigram $P_{kn}(w_t | prefix_{n-2})$ corresponds to Kneser Ney smoothing for {N-1}-gram language model.\n",
    "- Unigram $P_{kn}(w_t)$ is a special case: how likely it is to see x_t in an unfamiliar context\n",
    "\n",
    "See lecture slides or wiki for more detailed formulae.\n",
    "\n",
    "__Your task__ is to\n",
    "- implement KneserNeyLanguageModel\n",
    "- test it on 1-3 gram language models\n",
    "- find optimal (within reason) smoothing delta for 3-gram language model with Kneser-Ney smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "cellId": "2ix7kzw02v30oye55322all"
   },
   "outputs": [],
   "source": [
    "class KneserNeyLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" A template for Kneser-Ney language model. Default delta may be suboptimal. \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.n = n\n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        self.vocab = set(token for token_counts in counts.values() for token in token_counts)\n",
    "        # compute token proabilities given counts\n",
    "        self.probs = defaultdict(dict)\n",
    "        \n",
    "#         # populate self.probs with actual probabilities\n",
    "#         for prefix in counts.keys():\n",
    "#             for word in counts[prefix].keys():\n",
    "#                 self.probs[prefix][word] = counts[prefix][word] / sum(counts[prefix].values())\n",
    "# -----  \n",
    "        self.counts_ = {}\n",
    "        self.lambda_ = {}\n",
    "        self.prob_kn_ = defaultdict(dict)\n",
    "        for i in range(1, n+1):\n",
    "            self.counts_[f\"counts_{i}\"] = count_ngrams(lines, i)\n",
    "            if i == 1:\n",
    "                total_count = sum(self.counts_[f\"counts_{i}\"][()].values())\n",
    "                p_wt = { k:v/total_count for k,v in self.counts_[f\"counts_{i}\"][()].items()}\n",
    "                \n",
    "                self.prob_kn_[1] = {():p_wt}\n",
    "            else:\n",
    "                self.lambda_[i-1] = {}\n",
    "                for prefix in self.counts_[f\"counts_{i}\"].keys():\n",
    "                    total_sum= total_count = 0\n",
    "                    for token in self.counts_[f\"counts_{i}\"][prefix].keys():\n",
    "                        total_count += self.counts_[f\"counts_{i}\"][prefix][token]\n",
    "                        total_sum += max(0, self.counts_[f\"counts_{i}\"][prefix][token] - delta)\n",
    "                        self.lambda_[i-1][prefix] = total_count-total_sum\n",
    "                \n",
    "                self.prob_kn_[i]=defaultdict(dict)\n",
    "\n",
    "                for prefix in self.counts_[f\"counts_{i}\"].keys():\n",
    "                    self.prob_kn_[i][prefix]=defaultdict(dict)\n",
    "                    for word in self.counts_[f\"counts_{i}\"][prefix].keys():\n",
    "                        \n",
    "                        if i == 2:\n",
    "#                             print(prefix,self.counts_[f\"counts_{i}\"][prefix][token])\n",
    "                            if prefix not in p_wt:\n",
    "                                self.prob_kn_[i][prefix][word] = (max(0, self.counts_[f\"counts_{i}\"][prefix][word] - delta) / total_count)\n",
    "                            else:\n",
    "                                self.prob_kn_[i][prefix][word] = (max(0, self.counts_[f\"counts_{i}\"][prefix][word] - delta) / total_count) + self.lambda_[i-1][prefix]*p_wt[prefix]\n",
    "                        else:\n",
    "                            self.prob_kn_[i][prefix][word] = (max(0, self.counts_[f\"counts_{i}\"][prefix][word] - delta) / total_count) + self.lambda_[i-1][prefix]*self.prob_kn_[i-1][prefix[1:]][word]\n",
    "    \n",
    "        self.probs = self.prob_kn_[n]\n",
    "\n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :returns: a dictionary {token : it's probability} for all tokens with positive probabilities\n",
    "        \"\"\"\n",
    "        prefix = prefix.split()\n",
    "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
    "        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n",
    "        return self.probs[tuple(prefix)]\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :param next_token: the next token to predict probability for\n",
    "        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n",
    "        \"\"\"\n",
    "        return self.get_possible_next_tokens(prefix).get(next_token, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('_UNK_',), ('differential',), ('contrastive',), ('divergence',), (';',), ('this',), ('paper',), ('has',), ('been',), ('retracted',), ('.',), ('what',), ('does',), ('artificial',), ('life',), ('tell',), ('us',), ('about',), ('death',), ('?',), ('short',), ('philosophical',), ('essay',), ('p',), ('=',), ('np',), ('we',), ('claim',), ('to',), ('resolve',), ('the',), ('=?',), ('problem',), ('via',), ('a',), ('formal',), ('argument',), ('for',), ('computational',), ('geometry',), ('column',), ('38',), ('recent',), ('results',), ('on',), ('curve',), ('reconstruction',), ('are',), ('described',), ('weak',), ('evolvability',), ('equals',), ('strong',), ('an',), ('updated',), ('version',), ('will',), ('be',), ('uploaded',), ('later',), ('creating',), ('new',), ('ontology',), (':',), ('modular',), ('approach',), ('defeasible',), ('reasoning',), ('in',), ('oscar',), ('is',), ('system',), ('description',), ('reasoner',), ('essence',), (\"'\",), ('of',), ('language',), ('as',), ('used',), ('by',), ('tool',), ('savile',), ('row',), ('deep',), ('neural',), ('networks',), ('-',), ('brief',), ('history',), ('introduction',), ('and',), ('their',), ('statistical',), ('physics',), ('natural',), ('processing',), ('withdrawn',), ('author',), ('complex',), ('special',), ('issue',), (',',), ('journal',), ('serious',), ('flaws',), ('korf',), ('et',), ('al',), (\".'\",), ('s',), ('analysis',), ('time',), ('complexity',), ('*',), ('preprocessing',), ('step',), ('automating',), ('early',), ('detection',), ('cervical',), ('cancer',), ('liquid',), ('state',), ('machines',), ('adbiatic',), ('quantum',), ('computers',), ('general',), ('computation',), ('major',), ('mistakes',), ('do',), ('not',), ('read',), ('mining',), ('trees',), ('graph',), ('complete',), ('shown',), ('towards',), ('hierarchical',), ('model',), ('consciousness',), ('intelligence',), ('mind',), ('body',), ('article',), ('taken',), ('out',), ('notation',), ('markov',), ('decision',), ('processes',), ('specifies',), ('icon',), ('challenge',), ('algorithm',), ('selection',), ('present',), ('recognition',), ('regular',), ('shapes',), ('satelite',), ('images',), ('ali',), ('pourmohammad',), ('glottochronologic',), ('retrognostic',), ('proposed',), ('evolution',), ('due',), ('extremely',), ('unscientific',), ('errors',), ('utility',), ('probability',), ('duality',), ('presents',), ('between',), ('distributions',), ('functions',), ('temporized',), ('equilibria',), ('crucial',), ('error',), ('submission',), ('action',), ('backpropagation',), ('matrix',), ('note',), ('calculate',), ('gradient',), ('network',), ('function',), ('random',), ('dfas',), ('efficiently',), ('pac',), ('learnable',), ('found',), ('dana',), ('angluin',), ('lev',), ('reyzin',), ('motifs',), ('music',), ('sequences',), ('because',), ('it',), ('needs',), ('methodological',), ('revision',), ('glottochronology',), ('problems',), ('protolanguage',), ('method',), ('languages',), ('genealogical',), ('construction',), ('using',), ('slp',), ('persian',), ('handwritten',), ('digits',), ('hopping',), ('technique',), ('faster',), ('reinforcement',), ('learning',), ('simulations',), ('preprint',), ('convolutional',), ('matching',), ('pursuit',), ('dictionary',), ('training',), ('k',), ('svd',), ('demonstrated',), ('translation',), ('invariant',), ('setting',), ('fitness',), ('landscape',), ('dynamic',), ('resource',), ('allocation',), ('multiuser',), ('ofdm',), ('based',), ('cognitive',), ('radio',), ('systems',), ('darwiche',), ('pearl',), ('that',), ('postulates',), ('imply',), ('interesting',), ('property',), ('noticed',), ('authors',), ('flip',), ('flop',), ('sublinear',), ('models',), ('graphs',), ('proof',), ('theorem',), ('1',), ('prove',), ('there',), ('no',), ('class',), ('dual',), ('almost',), ('all',), ('autonomous',), ('perceptron',), ('inspired',), ('from',), ('computing',), ('abstract',), ('modified',), ('after',), ('correcting',), ('minor',), ('eq',), ('.(',), ('2',), (')',), ('sets',), ('measures',), ('represent',), ('uncertainty',), ('i',), ('explore',), ('use',), ('representation',), ('comment',), ('argumentation',), ('theory',), ('defaults',), ('meaning',), ('[',), ('gs16',), (']',), ('develop',), ('(',), ('outline',), ('activitynet',), ('2017',), ('summary',), ('large',), ('scale',), ('activity',), ('participants',), ('papers',), ('yahoo',), ('query',), ('treebank',), ('v',), ('0',), ('annotation',), ('guidelines',), ('webscope',), ('release',), ('may',), ('2016',), ('under',), ('derive',), ('axiomatically',), ('should',), ('make',), ('decisions',), ('given',), ('any',), ('form',), ('underlying',), ('text',), ('tools',), ('spoken',), ('contains',), ('postscript',), ('final',), ('slides',), ('our',), ('acl',), ('94',), ('tutorial',), ('discrimination',), ('arabic',), ('latin',), ('bilingual',), ('documents',), ('2011',), ('international',), ('conference',), ('communications',), ('control',), ('applications',), ('ccca',), ('machine',), ('framework',), ('design',), ('manufacturability',), ('duplicate',), ('original',), ('arxiv',), ('1612',), ('02141',), (').',), ('hence',), ('want',), ('withdraw',), ('experiment',), ('aims',), ('at',), ('clarifying',), ('practice',), ('scientific',), ('mainly',), ('hooking',), ('observability',), ('calculability',), ('minds',), ('computable',), ('explores',), ('limits',), ('turing',), ('concerning',), ('modeling',), ('suggests',), ('alternatives',), ('go',), ('beyond',), ('those',), ('extraction',), ('de',), ('concepts',), ('sous',), ('contraintes',), ('dans',), ('des',), ('donnes',), ('d',), ('expression',), ('gnes',), ('propose',), ('extract',), ('constrained',), ('comments',), ('\"',), ('combination',), ('evidence',), ('compromise',), ('yamada',), ('``',), (\"''\",), ('low',), ('shot',), ('facial',), ('representations',), ('2d',), ('warping',), ('work',), ('study',), ('influence',), ('module',), ('one',), ('face',), ('automatic',), ('generation',), ('benchmarks',), ('plagiarism',), ('grammatical',), ('rewriting',), ('mu',), ('partial',), ('channel',), ('information',), ('some',), ('advances',), ('require',), ('progress',), ('across',), ('computer',), ('science',), ('exploration',), ('object',), ('3d',), ('point',), ('cloud',), ('latest',), ('data',), ('collected',), ('through',), ('moving',), ('car',), ('quantified',), ('conditional',), ('logics',), ('fragments',), ('hol',), ('semantic',), ('embedding',), ('constant',), ('domain',), ('logic',), ('classical',), ('higher',), ('order',), ('presented',), ('memoriam',), ('maurice',), ('gross',), ('1934',), ('2001',), ('was',), ('both',), ('great',), ('linguist',), ('pioneer',), ('written',), ('homage',), ('his',), ('memory',), ('26th',), ('programming',), ('preface',), ('approaching',), ('human',), ('with',), ('cong',), ('&',), ('liu',), ('norm',), ('capacity',), ('investigate',), ('convexity',), ('characterization',), ('family',), ('feed',), ('forward',), ('compression',), ('vocabulary',), ('oriented',), ('uses',), ('entropy',), ('ideal',), ('bose',), ('einstein',), ('gas',), ('minimize',), ('losses',), ('unary',), ('coding',), ('properties',), ('significance',), ('biological',), ('instantaneously',), ('trained',), ('ukrainian',), ('writing',), ('grapheme',), ('phoneme',), ('relation',), ('cyrillic',), ('alphabet',), ('convex',), ('multiview',), ('fisher',), ('discriminant',), ('section',), ('3',), ('incorrect',), ('removed',), ('further',), ('submissions',), ('rewritten',), ('posted',), ('future',), ('why',), ('bother',), ('syntax',), ('discusses',), ('role',), ('vs',), ('semantics',), ('interplay',), ('philosophy',), ('game',), ('gsa',), ('gravitational',), ('search',), ('genuinely',), ('law',), ('gravity',), ('neurocontrol',), ('methods',), ('review',), ('applying',), ('plants',), ('considered',), ('schemes',), ('advantages',), ('disadvantages',), ('discussed',), ('universality',), ('online',), ('mirror',), ('descent',), ('show',), ('can',), ('always',), ('achieve',), ('nearly',), ('optimal',), ('regret',), ('guarantee',), ('possibility',), ('making',), ('brain',), ('development',), ('building',), ('corresponding',), ('parts',), ('dna',), ('code',), ('discuss',), ('how',), ('ai',), ('community',), ('views',), ('concerns',), ('emergence',), ('superintelligent',), ('related',), ('issues',), ('survey',), ('contextual',), ('multi',), ('armed',), ('bandits',), ('cover',), ('few',), ('stochastic',), ('adversarial',), ('bandit',), ('algorithms',), ('analyze',), ('each',), ('assumption',), ('bound',), ('parallels',), ('behavior',), ('bottlenose',), ('dolphins',), ('similarities',), ('humans',), ('help',), ('quantitative',), ('linguistics',), ('metaheuristics',), ('chapter',), ('describes',), ('five',), ('distinct',), ('periods',), ('starting',), ('long',), ('before',), ('first',), ('term',), ('ending',), ('energy',), ('efficient',), ('scheme',), ('gathering',), ('wireless',), ('sensor',), ('particle',), ('swarm',), ('optimization',), ('sign',), ('equation',), ('bengali',), ('readability',), ('score',), ('have',), ('texts',), ('got',), ('exceptionally',), ('good',), ('experiments',), ('paradigm',), ('prolog',), ('appropriate',), ('course',), ('students',), ('familiar',), ('imperative',), ('distance',), ('area',), ('where',), ('video',), ('cameras',), ('installed',), ('its',), ('movement',), ('group',), ('actions',), ('evolutionary',), ('global',), ('orbit',), ('understand',), ('solve',), ('nonconvex',), ('telugu',), ('investigation',), ('script',), ('since',), ('syllabic',), ('alphabetic',), ('somewhat',), ('complicated',), ('word',), ('segmentation',), ('micro',), ('blog',), ('external',), ('lexicon',), ('heterogeneous',), ('designed',), ('nlpcc',), ('shared',), ('task',), ('guarded',), ('resolution',), ('answer',), ('set',), ('describe',), ('variant',), ('rule',), ('stable',), ('programs',), ('result',), ('cornell',), ('spf',), ('parsing',), ('inference',), ('mapping',), ('semistability',), ('convergence',), ('paracontracting',), ('multiagent',), ('coordination',), ('sequential',), ('technical',), ('report',), ('extends',), ('previous',), ('1306',), ('0225',), ('proceedings',), ('workshop',), ('joint',), ('ijcnn',), ('anchorage',), ('17',), ('18',), ('attack',), ('rmse',), ('leaderboard',), ('case',), ('manuscript',), ('briefly',), ('introduce',), ('several',), ('tricks',), ('climb',), ('leaderboards',), ('which',), ('evaluation',), ('without',), ('exploiting',), ('standardization',), ('lexical',), ('nlp',), ('formats',), ('well',), ('presentation',), ('standardisation',), ('activities',), ('stock',), ('market',), ('prediction',), ('act',), ('trying',), ('determine',), ('value',), ('company',), ('or',), ('other',), ('financial',), ('instrument',), ('traded',), ('exchange',), ('defensive',), ('distillation',), ('robust',), ('examples',), ('secure',), ('more',), ('resistant',), ('targeted',), ('misclassification',), ('attacks',), ('than',), ('unprotected',), ('nips',), ('symposium',), ('interpretable',), ('held',), ('beach',), ('california',), ('usa',), ('december',), ('7',), ('piecewise',), ('linear',), ('activation',), ('administrators',), ('intentionally',), ('incomplete',), ('violation',), ('policies',), ('triangle',), ('inequality',), ('jaccard',), ('two',), ('simple',), ('proofs',), ('terms',), ('nonnegative',), ('monotone',), ('submodular',), ('realize',), ('sense',), ('humour',), ('suggested',), ('previously',), ('0711',), ('2058',), ('2061',), ('2270',), ('raised',), ('level',), ('realistic',), ('multilayer',), ('perceptrons',), ('dropout',), ('type',), ('hidden',), ('layer',), ('demonstrate',), ('obtains',), ('best',), ('reported',), ('performance',), ('mlp',), ('mnist',), ('dataset',), ('measuring',), ('prosodic',), ('accommodation',), ('submitter',), ('did',), ('legal',), ('authority',), ('grant',), ('license',), ('applied',), ('remark',), ('rue',), ('extrue',), ('prominent',), ('counterexample',), ('completeness',), ('apply',), ('sat',), ('funny',), ('while',), ('primary',), ('interest',), ('propositional',), ('satisfiability',), ('playful',), ('way',), ('pedagogical',), ('purposes',), ('could',), ('also',), ('inspire',), ('heuristics',), ('adjusting',), ('$',), ('r',), ('^',), ('cross',), ('validation',), ('adjust',), ('coefficient',), ('determination',), ('($',), ('$)',), ('when',), ('predictive',), ('accuracy',), ('leave',), ('approximated',), ('structured',), ('graphical',), ('manuscripts',), ('primal',), ('message',), ('passing',), ('\".',), ('liver',), ('ct',), ('aim',), ('priori',), ('knowledge',), ('image',), ('such',), ('location',), ('shape',), ('existence',), ('projective',), ('connection',), ('fundamental',), ('satisfying',), ('epipolar',), ('constraints',), ('solving',), ('traveling',), ('salesman',), ('marker',), ('mutation',), ('operator',), ('selects',), ('nearest',), ('neighbor',), ('among',), ('near',), ('neighbors',), ('primer',), ('intended',), ('handout',), ('graduate',), ('taking',), ('intlligence',), ('classes',), ('agent',), ('political',), ('interactions',), ('looks',), ('perspective',), ('see',), ('example',), ('emergent',), ('intelligent',), ('exposes',), ('basic',), ('principles',), ('states',), ('pomdp',), ('deal',), ('only',), ('observations',), ('available',), ('latent',), ('space',), ('accurately',), ('learned',)])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_lm.probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {('_UNK_',): Counter({'differential': 1,\n",
       "                      'what': 1,\n",
       "                      'p': 1,\n",
       "                      'computational': 1,\n",
       "                      'weak': 1,\n",
       "                      'creating': 1,\n",
       "                      'defeasible': 1,\n",
       "                      'essence': 1,\n",
       "                      'deep': 1,\n",
       "                      'statistical': 1,\n",
       "                      'complex': 1,\n",
       "                      'serious': 1,\n",
       "                      'preprocessing': 1,\n",
       "                      'liquid': 1,\n",
       "                      'mining': 1,\n",
       "                      'towards': 1,\n",
       "                      'a': 13,\n",
       "                      'icon': 1,\n",
       "                      'recognition': 1,\n",
       "                      'glottochronologic': 1,\n",
       "                      'the': 3,\n",
       "                      'utility': 1,\n",
       "                      'temporized': 1,\n",
       "                      'backpropagation': 1,\n",
       "                      'random': 1,\n",
       "                      'network': 1,\n",
       "                      'glottochronology': 1,\n",
       "                      'using': 2,\n",
       "                      'time': 1,\n",
       "                      'convolutional': 1,\n",
       "                      'fitness': 1,\n",
       "                      'flip': 1,\n",
       "                      'autonomous': 1,\n",
       "                      'activitynet': 1,\n",
       "                      'decision': 1,\n",
       "                      'text': 1,\n",
       "                      'discrimination': 1,\n",
       "                      'are': 1,\n",
       "                      'extraction': 1,\n",
       "                      'comments': 1,\n",
       "                      'learning': 2,\n",
       "                      'automatic': 2,\n",
       "                      'resource': 1,\n",
       "                      'advances': 1,\n",
       "                      'exploration': 1,\n",
       "                      'quantified': 1,\n",
       "                      'in': 1,\n",
       "                      'introduction': 1,\n",
       "                      'beyond': 1,\n",
       "                      'norm': 1,\n",
       "                      'about': 1,\n",
       "                      'unary': 1,\n",
       "                      'some': 1,\n",
       "                      'convex': 1,\n",
       "                      'why': 2,\n",
       "                      'neurocontrol': 1,\n",
       "                      'on': 3,\n",
       "                      'philosophy': 1,\n",
       "                      'parallels': 1,\n",
       "                      'an': 1,\n",
       "                      'calculate': 1,\n",
       "                      'group': 1,\n",
       "                      'entropy': 1,\n",
       "                      'word': 1,\n",
       "                      'guarded': 1,\n",
       "                      'cornell': 1,\n",
       "                      'semistability': 1,\n",
       "                      'proceedings': 2,\n",
       "                      'attack': 1,\n",
       "                      'standardization': 1,\n",
       "                      'defensive': 1,\n",
       "                      'piecewise': 2,\n",
       "                      'how': 1,\n",
       "                      'technical': 1,\n",
       "                      'sat': 1,\n",
       "                      'approximated': 1,\n",
       "                      'solving': 1,\n",
       "                      'agent': 1}),\n",
       "             ('differential',): Counter({'contrastive': 1}),\n",
       "             ('contrastive',): Counter({'divergence': 1}),\n",
       "             ('divergence',): Counter({';': 1}),\n",
       "             (';',): Counter({'this': 36,\n",
       "                      'short': 1,\n",
       "                      'we': 16,\n",
       "                      'recent': 1,\n",
       "                      'an': 1,\n",
       "                      'creating': 1,\n",
       "                      'a': 8,\n",
       "                      'introduction': 2,\n",
       "                      'major': 1,\n",
       "                      'mining': 1,\n",
       "                      'in': 10,\n",
       "                      'matching': 1,\n",
       "                      'it': 1,\n",
       "                      'i': 1,\n",
       "                      'the': 6,\n",
       "                      '2011': 1,\n",
       "                      'comments': 1,\n",
       "                      'advances': 1,\n",
       "                      'maurice': 1,\n",
       "                      'comment': 1,\n",
       "                      'section': 1,\n",
       "                      'why': 1,\n",
       "                      'methods': 1,\n",
       "                      'proceedings': 1,\n",
       "                      'stock': 1,\n",
       "                      'two': 1,\n",
       "                      'computer': 1,\n",
       "                      'looks': 1}),\n",
       "             ('this',): Counter({'paper': 23,\n",
       "                      'is': 5,\n",
       "                      'article': 5,\n",
       "                      'note': 2,\n",
       "                      'preprint': 1,\n",
       "                      'abstract': 1,\n",
       "                      'submission': 2,\n",
       "                      'essay': 1,\n",
       "                      'work': 2,\n",
       "                      'short': 1,\n",
       "                      'survey': 1,\n",
       "                      'chapter': 1,\n",
       "                      'script': 1,\n",
       "                      'result': 1,\n",
       "                      'sequential': 1,\n",
       "                      'manuscript': 1,\n",
       "                      'manuscripts': 1}),\n",
       "             ('paper',): Counter({'has': 14,\n",
       "                      'specifies': 1,\n",
       "                      'presents': 3,\n",
       "                      ',': 1,\n",
       "                      'we': 3,\n",
       "                      'describes': 1}),\n",
       "             ('has',): Counter({'been': 17}),\n",
       "             ('been',): Counter({'retracted': 1, 'withdrawn': 16}),\n",
       "             ('retracted',): Counter({'.': 1}),\n",
       "             ('.',): Counter({'_EOS_': 81,\n",
       "                      '1': 2,\n",
       "                      '0': 2,\n",
       "                      '02141': 1,\n",
       "                      'yamada': 2,\n",
       "                      'this': 1,\n",
       "                      'comment': 1,\n",
       "                      '3': 1,\n",
       "                      'a': 1,\n",
       "                      'semantics': 1,\n",
       "                      'methods': 1,\n",
       "                      'we': 3,\n",
       "                      'since': 1,\n",
       "                      '0225': 1,\n",
       "                      '2058': 1,\n",
       "                      '2061': 1,\n",
       "                      '2270': 1,\n",
       "                      'while': 1,\n",
       "                      'exposes': 1}),\n",
       "             ('what',): Counter({'does': 1}),\n",
       "             ('does',): Counter({'artificial': 1, 'not': 1}),\n",
       "             ('artificial',): Counter({'life': 2,\n",
       "                      'intelligence': 3,\n",
       "                      'intlligence': 1}),\n",
       "             ('life',): Counter({'tell': 1, 'journal': 1}),\n",
       "             ('tell',): Counter({'us': 1}),\n",
       "             ('us',): Counter({'about': 1, ',': 1}),\n",
       "             ('about',): Counter({'death': 1, 'compression': 1, 'the': 1}),\n",
       "             ('death',): Counter({'?': 1}),\n",
       "             ('?',): Counter({';': 4}),\n",
       "             ('short',): Counter({'philosophical': 1, 'note': 1, 'review': 1}),\n",
       "             ('philosophical',): Counter({'essay': 1, 'issues': 1}),\n",
       "             ('essay',): Counter({'_EOS_': 1, 'explores': 1}),\n",
       "             ('p',): Counter({'=': 2, '=?': 1}),\n",
       "             ('=',): Counter({'np': 2}),\n",
       "             ('np',): Counter({';': 1, 'problem': 1, '.': 1, '-': 2}),\n",
       "             ('we',): Counter({'claim': 1,\n",
       "                      'present': 2,\n",
       "                      'calculate': 1,\n",
       "                      'prove': 1,\n",
       "                      'use': 3,\n",
       "                      'derive': 1,\n",
       "                      'propose': 4,\n",
       "                      'mainly': 1,\n",
       "                      'investigate': 2,\n",
       "                      'show': 5,\n",
       "                      'cover': 1,\n",
       "                      'analyze': 1,\n",
       "                      'have': 2,\n",
       "                      'describe': 1,\n",
       "                      'posted': 1,\n",
       "                      'briefly': 1,\n",
       "                      'study': 1}),\n",
       "             ('claim',): Counter({'to': 1}),\n",
       "             ('to',): Counter({'resolve': 1,\n",
       "                      'deep': 1,\n",
       "                      'the': 8,\n",
       "                      'be': 1,\n",
       "                      'extremely': 1,\n",
       "                      'a': 3,\n",
       "                      'an': 1,\n",
       "                      'persian': 1,\n",
       "                      'represent': 1,\n",
       "                      'develop': 2,\n",
       "                      'make': 1,\n",
       "                      'withdraw': 1,\n",
       "                      'go': 1,\n",
       "                      'extract': 1,\n",
       "                      'some': 1,\n",
       "                      'his': 1,\n",
       "                      'minimize': 1,\n",
       "                      'control': 1,\n",
       "                      'analyze': 1,\n",
       "                      'object': 1,\n",
       "                      'calculate': 1,\n",
       "                      'understand': 1,\n",
       "                      'formal': 1,\n",
       "                      'climb': 1,\n",
       "                      'determine': 1,\n",
       "                      'adversarial': 1,\n",
       "                      'targeted': 1,\n",
       "                      'realize': 1,\n",
       "                      'grant': 1,\n",
       "                      'present': 1,\n",
       "                      'adjust': 1,\n",
       "                      '[': 1,\n",
       "                      'see': 1,\n",
       "                      'deal': 1}),\n",
       "             ('resolve',): Counter({'the': 1}),\n",
       "             ('the',): Counter({'p': 1,\n",
       "                      'oscar': 1,\n",
       "                      'essence': 1,\n",
       "                      'tool': 1,\n",
       "                      'author': 10,\n",
       "                      'special': 1,\n",
       "                      'results': 1,\n",
       "                      'icon': 1,\n",
       "                      'model': 1,\n",
       "                      'submission': 1,\n",
       "                      'gradient': 1,\n",
       "                      'network': 1,\n",
       "                      'translation': 1,\n",
       "                      'authors': 2,\n",
       "                      'minor': 1,\n",
       "                      'use': 1,\n",
       "                      'theory': 1,\n",
       "                      'outline': 1,\n",
       "                      'activitynet': 1,\n",
       "                      'yahoo': 2,\n",
       "                      'probability': 1,\n",
       "                      'postscript': 1,\n",
       "                      'final': 1,\n",
       "                      'slides': 1,\n",
       "                      'language': 1,\n",
       "                      'limits': 1,\n",
       "                      'modeling': 1,\n",
       "                      'influence': 1,\n",
       "                      '2d': 1,\n",
       "                      '26th': 2,\n",
       "                      'preface': 1,\n",
       "                      'capacity': 1,\n",
       "                      'entropy': 2,\n",
       "                      'ideal': 1,\n",
       "                      'ukrainian': 2,\n",
       "                      'grapheme': 1,\n",
       "                      'cyrillic': 1,\n",
       "                      'future': 3,\n",
       "                      'role': 1,\n",
       "                      'interplay': 1,\n",
       "                      'law': 2,\n",
       "                      'universality': 1,\n",
       "                      'possibility': 1,\n",
       "                      'complete': 1,\n",
       "                      'development': 1,\n",
       "                      'algorithm': 1,\n",
       "                      'corresponding': 1,\n",
       "                      'face': 1,\n",
       "                      'ai': 1,\n",
       "                      'emergence': 1,\n",
       "                      'behavior': 1,\n",
       "                      'help': 1,\n",
       "                      'history': 1,\n",
       "                      'first': 3,\n",
       "                      'term': 1,\n",
       "                      'readability': 1,\n",
       "                      'experiments': 1,\n",
       "                      'logic': 1,\n",
       "                      'area': 1,\n",
       "                      'method': 1,\n",
       "                      'car': 1,\n",
       "                      'distance': 1,\n",
       "                      'object': 1,\n",
       "                      'telugu': 1,\n",
       "                      'computation': 1,\n",
       "                      'nlpcc': 1,\n",
       "                      'cornell': 1,\n",
       "                      'previous': 1,\n",
       "                      'leaderboards': 1,\n",
       "                      'formal': 1,\n",
       "                      'act': 1,\n",
       "                      'proceedings': 1,\n",
       "                      'triangle': 2,\n",
       "                      'jaccard': 2,\n",
       "                      'level': 1,\n",
       "                      'best': 1,\n",
       "                      'mnist': 1,\n",
       "                      'submitter': 1,\n",
       "                      'legal': 1,\n",
       "                      'license': 1,\n",
       "                      'work': 1,\n",
       "                      'completeness': 1,\n",
       "                      'higher': 1,\n",
       "                      'primary': 1,\n",
       "                      'coefficient': 1,\n",
       "                      'proofs': 1,\n",
       "                      'aim': 1,\n",
       "                      'liver': 2,\n",
       "                      'image': 1,\n",
       "                      'existence': 3,\n",
       "                      'connection': 1,\n",
       "                      'epipolar': 1,\n",
       "                      'nearest': 1,\n",
       "                      'syntax': 1}),\n",
       "             ('=?',): Counter({'np': 1}),\n",
       "             ('problem',): Counter({'via': 1, 'by': 1, '.': 1}),\n",
       "             ('via',): Counter({'a': 1, '2d': 1, 'leave': 1}),\n",
       "             ('a',): Counter({'formal': 1,\n",
       "                      'new': 7,\n",
       "                      'modular': 2,\n",
       "                      'system': 1,\n",
       "                      'description': 2,\n",
       "                      'brief': 1,\n",
       "                      '*': 1,\n",
       "                      'step': 1,\n",
       "                      'graph': 2,\n",
       "                      'hierarchical': 1,\n",
       "                      'notation': 2,\n",
       "                      'glottochronologic': 1,\n",
       "                      'crucial': 2,\n",
       "                      'deep': 1,\n",
       "                      'method': 2,\n",
       "                      'note': 3,\n",
       "                      'representation': 1,\n",
       "                      'comment': 1,\n",
       "                      ')': 1,\n",
       "                      'machine': 2,\n",
       "                      'duplicate': 1,\n",
       "                      'theory': 1,\n",
       "                      'technique': 1,\n",
       "                      'major': 1,\n",
       "                      'semantic': 1,\n",
       "                      'great': 1,\n",
       "                      'pioneer': 1,\n",
       "                      'general': 2,\n",
       "                      'rewritten': 1,\n",
       "                      'gravitational': 2,\n",
       "                      '(': 1,\n",
       "                      'human': 1,\n",
       "                      'neural': 1,\n",
       "                      'dna': 1,\n",
       "                      'survey': 2,\n",
       "                      'few': 1,\n",
       "                      'short': 1,\n",
       "                      'history': 1,\n",
       "                      'long': 1,\n",
       "                      'tutorial': 1,\n",
       "                      'course': 1,\n",
       "                      'variant': 1,\n",
       "                      'learning': 1,\n",
       "                      'presentation': 1,\n",
       "                      'company': 1,\n",
       "                      'financial': 1,\n",
       "                      'sense': 1,\n",
       "                      '\"': 1,\n",
       "                      'realistic': 1,\n",
       "                      'multilayer': 1,\n",
       "                      'tool': 1,\n",
       "                      'remark': 1,\n",
       "                      'prominent': 1,\n",
       "                      'game': 1,\n",
       "                      'funny': 1,\n",
       "                      'playful': 1,\n",
       "                      'primal': 1,\n",
       "                      'priori': 1,\n",
       "                      'projective': 2,\n",
       "                      'fundamental': 1,\n",
       "                      'primer': 1,\n",
       "                      'introduction': 1,\n",
       "                      'latent': 1}),\n",
       "             ('formal',): Counter({'argument': 1,\n",
       "                      'concepts': 1,\n",
       "                      'representation': 2}),\n",
       "             ('argument',): Counter({'for': 1}),\n",
       "             ('for',): Counter({'p': 1,\n",
       "                      'the': 6,\n",
       "                      'natural': 1,\n",
       "                      'general': 1,\n",
       "                      'trees': 2,\n",
       "                      'markov': 2,\n",
       "                      'faster': 1,\n",
       "                      'revision': 1,\n",
       "                      'dynamic': 1,\n",
       "                      'graphs': 1,\n",
       "                      'almost': 1,\n",
       "                      'design': 1,\n",
       "                      'manufacturability': 1,\n",
       "                      'one': 1,\n",
       "                      'plagiarism': 1,\n",
       "                      'neural': 1,\n",
       "                      'biological': 1,\n",
       "                      'a': 3,\n",
       "                      'data': 1,\n",
       "                      'students': 1,\n",
       "                      'answer': 1,\n",
       "                      'stable': 1,\n",
       "                      'mapping': 1,\n",
       "                      'paracontracting': 1,\n",
       "                      'evaluation': 1,\n",
       "                      'nlp': 1,\n",
       "                      'stock': 1,\n",
       "                      'more': 1,\n",
       "                      'an': 1,\n",
       "                      'measuring': 2,\n",
       "                      'pedagogical': 1,\n",
       "                      'using': 1,\n",
       "                      'learning': 1,\n",
       "                      '\"': 1,\n",
       "                      'approximated': 1,\n",
       "                      'automatic': 1}),\n",
       "             ('computational',): Counter({'geometry': 1}),\n",
       "             ('geometry',): Counter({'column': 1}),\n",
       "             ('column',): Counter({'38': 1}),\n",
       "             ('38',): Counter({';': 1}),\n",
       "             ('recent',): Counter({'results': 1, 'standardisation': 1}),\n",
       "             ('results',): Counter({'on': 1,\n",
       "                      'of': 2,\n",
       "                      'and': 1,\n",
       "                      'out': 1,\n",
       "                      'we': 1}),\n",
       "             ('on',): Counter({'curve': 1,\n",
       "                      'complex': 1,\n",
       "                      'time': 1,\n",
       "                      'algorithm': 2,\n",
       "                      'darwiche': 1,\n",
       "                      'graphs': 1,\n",
       "                      'argumentation': 1,\n",
       "                      'communications': 1,\n",
       "                      'calculability': 1,\n",
       "                      '\"': 3,\n",
       "                      'compromise': 2,\n",
       "                      '``': 1,\n",
       "                      'logic': 3,\n",
       "                      'the': 8,\n",
       "                      'contextual': 1,\n",
       "                      'programming': 1,\n",
       "                      'micro': 2,\n",
       "                      'word': 1,\n",
       "                      'deep': 2,\n",
       "                      'a': 2,\n",
       "                      'interpretable': 2,\n",
       "                      'december': 1,\n",
       "                      'higher': 1,\n",
       "                      'adjusting': 1,\n",
       "                      'answer': 1,\n",
       "                      'which': 1}),\n",
       "             ('curve',): Counter({'reconstruction': 1}),\n",
       "             ('reconstruction',): Counter({'are': 1, ';': 2, 'and': 1}),\n",
       "             ('are',): Counter({'described': 2,\n",
       "                      'efficiently': 1,\n",
       "                      'minds': 1,\n",
       "                      'fragments': 1,\n",
       "                      'considered': 1,\n",
       "                      'discussed': 1,\n",
       "                      'given': 1,\n",
       "                      'available': 1}),\n",
       "             ('described',): Counter({'.': 1, ',': 1}),\n",
       "             ('weak',): Counter({'evolvability': 1}),\n",
       "             ('evolvability',): Counter({'equals': 1, ';': 1}),\n",
       "             ('equals',): Counter({'strong': 1}),\n",
       "             ('strong',): Counter({'evolvability': 1}),\n",
       "             ('an',): Counter({'updated': 1,\n",
       "                      'error': 1,\n",
       "                      'interesting': 1,\n",
       "                      'energy': 1,\n",
       "                      'investigation': 1,\n",
       "                      'introduction': 1,\n",
       "                      'mlp': 1,\n",
       "                      'handout': 1,\n",
       "                      'agent': 1,\n",
       "                      'example': 1}),\n",
       "             ('updated',): Counter({'version': 1}),\n",
       "             ('version',): Counter({'will': 2, '1': 1, 'of': 2}),\n",
       "             ('will',): Counter({'be': 4}),\n",
       "             ('be',): Counter({'uploaded': 1,\n",
       "                      'np': 1,\n",
       "                      'modified': 1,\n",
       "                      'used': 1,\n",
       "                      'removed': 1,\n",
       "                      'posted': 1,\n",
       "                      'accurately': 1}),\n",
       "             ('uploaded',): Counter({'later': 1}),\n",
       "             ('later',): Counter({'.': 1}),\n",
       "             ('creating',): Counter({'a': 2}),\n",
       "             ('new',): Counter({'ontology': 2,\n",
       "                      'theory': 1,\n",
       "                      'combination': 2,\n",
       "                      'bengali': 1,\n",
       "                      'type': 1,\n",
       "                      'search': 1,\n",
       "                      'mutation': 1}),\n",
       "             ('ontology',): Counter({':': 2}),\n",
       "             (':',): Counter({'a': 6,\n",
       "                      'proof': 1,\n",
       "                      'results': 1,\n",
       "                      '1612': 1,\n",
       "                      'cornell': 1,\n",
       "                      '1306': 1,\n",
       "                      'an': 1,\n",
       "                      'it': 1,\n",
       "                      '0711': 1}),\n",
       "             ('modular',): Counter({'approach': 2}),\n",
       "             ('approach',): Counter({';': 1, '_EOS_': 1, 'extrue': 1}),\n",
       "             ('defeasible',): Counter({'reasoning': 1, 'reasoner': 1}),\n",
       "             ('reasoning',): Counter({'in': 1}),\n",
       "             ('in',): Counter({'oscar': 1,\n",
       "                      'korf': 1,\n",
       "                      'automating': 1,\n",
       "                      'adbiatic': 1,\n",
       "                      'a': 3,\n",
       "                      'satelite': 1,\n",
       "                      'the': 7,\n",
       "                      'matrix': 2,\n",
       "                      'this': 10,\n",
       "                      'music': 1,\n",
       "                      'simulations': 1,\n",
       "                      'multiuser': 1,\n",
       "                      'eq': 1,\n",
       "                      'spoken': 1,\n",
       "                      'our': 1,\n",
       "                      'artificial': 2,\n",
       "                      'classical': 1,\n",
       "                      'memoriam': 1,\n",
       "                      'natural': 1,\n",
       "                      'homage': 1,\n",
       "                      'neural': 1,\n",
       "                      'computer': 3,\n",
       "                      'ukrainian': 1,\n",
       "                      'five': 1,\n",
       "                      'wireless': 1,\n",
       "                      'equation': 1,\n",
       "                      'its': 1,\n",
       "                      'long': 1,\n",
       "                      'violation': 1,\n",
       "                      'terms': 1,\n",
       "                      'computers': 1,\n",
       "                      'ct': 1,\n",
       "                      'pomdp': 1}),\n",
       "             ('oscar',): Counter({';': 1, 'defeasible': 1}),\n",
       "             ('is',): Counter({'a': 4,\n",
       "                      'np': 1,\n",
       "                      'shown': 2,\n",
       "                      'taken': 1,\n",
       "                      'proposed': 2,\n",
       "                      'demonstrated': 1,\n",
       "                      'no': 2,\n",
       "                      'arxiv': 1,\n",
       "                      'presented': 2,\n",
       "                      'written': 1,\n",
       "                      'the': 3,\n",
       "                      'not': 4,\n",
       "                      'discussed': 1,\n",
       "                      'syllabic': 1,\n",
       "                      'somewhat': 1,\n",
       "                      'complete': 1,\n",
       "                      'intentionally': 1,\n",
       "                      'in': 1,\n",
       "                      'raised': 1,\n",
       "                      'to': 2}),\n",
       "             ('system',): Counter({'description': 1,\n",
       "                      ';': 2,\n",
       "                      'is': 1,\n",
       "                      'designed': 1}),\n",
       "             ('description',): Counter({'for': 1,\n",
       "                      ';': 1,\n",
       "                      'of': 1,\n",
       "                      'and': 1,\n",
       "                      '.': 1}),\n",
       "             ('reasoner',): Counter({'.': 1}),\n",
       "             ('essence',): Counter({\"'\": 2}),\n",
       "             (\"'\",): Counter({'description': 1,\n",
       "                      'language': 1,\n",
       "                      's': 2,\n",
       "                      'expression': 1,\n",
       "                      'gsa': 2,\n",
       "                      'is': 2}),\n",
       "             ('of',): Counter({'the': 23,\n",
       "                      'a': 12,\n",
       "                      'cervical': 1,\n",
       "                      'consciousness': 1,\n",
       "                      'regular': 1,\n",
       "                      'language': 2,\n",
       "                      'quantum': 1,\n",
       "                      'protolanguage': 1,\n",
       "                      'languages': 1,\n",
       "                      'theorem': 1,\n",
       "                      'probability': 2,\n",
       "                      'sets': 1,\n",
       "                      'uncertainty': 1,\n",
       "                      'defaults': 1,\n",
       "                      '[': 1,\n",
       "                      'argumentation': 1,\n",
       "                      'query': 1,\n",
       "                      'underlying': 1,\n",
       "                      'experiment': 1,\n",
       "                      'scientific': 1,\n",
       "                      'turing': 1,\n",
       "                      'minds': 1,\n",
       "                      'evidence': 2,\n",
       "                      'benchmarks': 1,\n",
       "                      'mu': 1,\n",
       "                      'computer': 2,\n",
       "                      'object': 2,\n",
       "                      'hol': 1,\n",
       "                      '(': 1,\n",
       "                      'norm': 1,\n",
       "                      'vocabulary': 1,\n",
       "                      'unary': 1,\n",
       "                      'significance': 1,\n",
       "                      'syntax': 1,\n",
       "                      'gravity': 2,\n",
       "                      'applying': 1,\n",
       "                      'online': 1,\n",
       "                      'convex': 1,\n",
       "                      'making': 1,\n",
       "                      'artificial': 1,\n",
       "                      'superintelligent': 1,\n",
       "                      'human': 1,\n",
       "                      'bottlenose': 1,\n",
       "                      'similarities': 1,\n",
       "                      'quantitative': 1,\n",
       "                      'metaheuristics': 2,\n",
       "                      'bengali': 1,\n",
       "                      'using': 1,\n",
       "                      'movement': 1,\n",
       "                      'telugu': 1,\n",
       "                      'entropy': 1,\n",
       "                      'resolution': 1,\n",
       "                      'proof': 1,\n",
       "                      'logic': 1,\n",
       "                      'this': 2,\n",
       "                      'its': 1,\n",
       "                      'lexical': 1,\n",
       "                      'dictionary': 1,\n",
       "                      'corresponding': 1,\n",
       "                      'trying': 1,\n",
       "                      'nips': 2,\n",
       "                      'our': 1,\n",
       "                      'nonnegative': 1,\n",
       "                      'humour': 2,\n",
       "                      'hidden': 1,\n",
       "                      'first': 1,\n",
       "                      'sat': 1,\n",
       "                      'determination': 1,\n",
       "                      'answer': 1,\n",
       "                      'political': 1,\n",
       "                      'emergent': 1,\n",
       "                      'game': 1}),\n",
       "             ('language',): Counter({'as': 1,\n",
       "                      'processing': 3,\n",
       "                      'system': 2,\n",
       "                      'and': 1,\n",
       "                      'with': 2,\n",
       "                      'in': 2,\n",
       "                      'texts': 1,\n",
       "                      'to': 1}),\n",
       "             ('as',): Counter({'used': 1,\n",
       "                      'a': 3,\n",
       "                      'well': 1,\n",
       "                      'location': 1,\n",
       "                      'an': 2}),\n",
       "             ('used',): Counter({'by': 1, 'to': 1, 'in': 1, 'for': 1}),\n",
       "             ('by',): Counter({'the': 13,\n",
       "                      'dana': 1,\n",
       "                      'hooking': 1,\n",
       "                      'k': 2,\n",
       "                      'cong': 2,\n",
       "                      'arxiv': 2,\n",
       "                      'marker': 1,\n",
       "                      'learning': 1}),\n",
       "             ('tool',): Counter({'savile': 1, 'for': 1}),\n",
       "             ('savile',): Counter({'row': 1}),\n",
       "             ('row',): Counter({'.': 1}),\n",
       "             ('deep',): Counter({'neural': 2,\n",
       "                      'methodological': 1,\n",
       "                      'learning': 2,\n",
       "                      'networks': 1}),\n",
       "             ('neural',): Counter({'networks': 6, 'network': 4}),\n",
       "             ('networks',): Counter({'-': 1,\n",
       "                      'and': 1,\n",
       "                      ';': 3,\n",
       "                      ',': 1,\n",
       "                      '\"': 2,\n",
       "                      '.': 3,\n",
       "                      'to': 1,\n",
       "                      'using': 1}),\n",
       "             ('-',): Counter({'a': 1,\n",
       "                      'complete': 2,\n",
       "                      'probability': 1,\n",
       "                      'svd': 1,\n",
       "                      'flop': 1,\n",
       "                      'dual': 2,\n",
       "                      '94': 1,\n",
       "                      'learning': 1,\n",
       "                      'shot': 2,\n",
       "                      'ofdm': 1,\n",
       "                      'order': 1,\n",
       "                      '2001': 1,\n",
       "                      'based': 2,\n",
       "                      'constrained': 1,\n",
       "                      'forward': 1,\n",
       "                      'einstein': 1,\n",
       "                      'oriented': 1,\n",
       "                      'phoneme': 1,\n",
       "                      'armed': 1,\n",
       "                      'blog': 2,\n",
       "                      '18': 1,\n",
       "                      'resolution': 3,\n",
       "                      'validation': 2,\n",
       "                      'one': 1,\n",
       "                      'out': 1,\n",
       "                      'passing': 1}),\n",
       "             ('brief',): Counter({'history': 1}),\n",
       "             ('history',): Counter({';': 1, '.': 1, 'of': 2}),\n",
       "             ('introduction',): Counter({'to': 4, 'and': 1}),\n",
       "             ('and',): Counter({'their': 2,\n",
       "                      'body': 1,\n",
       "                      'utility': 1,\n",
       "                      'lev': 1,\n",
       "                      'problems': 1,\n",
       "                      'dictionary': 1,\n",
       "                      'k': 1,\n",
       "                      'pearl': 2,\n",
       "                      'challenge': 1,\n",
       "                      'annotation': 1,\n",
       "                      'latin': 1,\n",
       "                      'control': 1,\n",
       "                      'practice': 1,\n",
       "                      'suggests': 1,\n",
       "                      'a': 1,\n",
       "                      'characterization': 1,\n",
       "                      'instantaneously': 1,\n",
       "                      'some': 1,\n",
       "                      '2': 1,\n",
       "                      'the': 2,\n",
       "                      'language': 1,\n",
       "                      'game': 1,\n",
       "                      'schemes': 1,\n",
       "                      'disadvantages': 1,\n",
       "                      'related': 1,\n",
       "                      'adversarial': 1,\n",
       "                      'regret': 1,\n",
       "                      'humans': 1,\n",
       "                      'information': 1,\n",
       "                      'ending': 1,\n",
       "                      'prolog': 2,\n",
       "                      'global': 1,\n",
       "                      'orbit': 1,\n",
       "                      'not': 1,\n",
       "                      'heterogeneous': 1,\n",
       "                      'show': 1,\n",
       "                      'inference': 1,\n",
       "                      'music': 2,\n",
       "                      'case': 1,\n",
       "                      'formats': 1,\n",
       "                      'discussed': 1,\n",
       "                      'dropout': 1,\n",
       "                      'demonstrate': 1,\n",
       "                      'shape': 1,\n",
       "                      'propose': 1,\n",
       "                      'semantics': 1}),\n",
       "             ('their',): Counter({'history': 1,\n",
       "                      'meaning': 1,\n",
       "                      'advantages': 1}),\n",
       "             ('statistical',): Counter({'physics': 1}),\n",
       "             ('physics',): Counter({'for': 1}),\n",
       "             ('natural',): Counter({'language': 3}),\n",
       "             ('processing',): Counter({';': 2, '.': 1}),\n",
       "             ('withdrawn',): Counter({'by': 12, '.': 2, '_EOS_': 1, 'due': 1}),\n",
       "             ('author',): Counter({'.': 1,\n",
       "                      'ali': 2,\n",
       "                      'due': 4,\n",
       "                      'because': 1,\n",
       "                      'for': 1,\n",
       "                      'uses': 1}),\n",
       "             ('complex',): Counter({'networks': 4}),\n",
       "             ('special',): Counter({'issue': 3}),\n",
       "             ('issue',): Counter({'on': 1, ';': 1, '_EOS_': 1}),\n",
       "             (',',): Counter({'artificial': 1,\n",
       "                      'intelligence': 1,\n",
       "                      'mind': 1,\n",
       "                      'not': 1,\n",
       "                      'v': 1,\n",
       "                      'version': 1,\n",
       "                      'may': 2,\n",
       "                      'computing': 1,\n",
       "                      'mainly': 1,\n",
       "                      'we': 3,\n",
       "                      'convexity': 1,\n",
       "                      'and': 5,\n",
       "                      'philosophy': 1,\n",
       "                      'their': 1,\n",
       "                      'mirror': 1,\n",
       "                      'i': 1,\n",
       "                      'starting': 1,\n",
       "                      'using': 1,\n",
       "                      'to': 1,\n",
       "                      'group': 1,\n",
       "                      'evolutionary': 1,\n",
       "                      'action': 1,\n",
       "                      'the': 1,\n",
       "                      'joint': 1,\n",
       "                      'anchorage': 1,\n",
       "                      'us': 1,\n",
       "                      '2017': 2,\n",
       "                      'held': 1,\n",
       "                      'california': 1,\n",
       "                      'usa': 1,\n",
       "                      'which': 1,\n",
       "                      'monotone': 1,\n",
       "                      'submodular': 1,\n",
       "                      '0711': 2,\n",
       "                      'it': 1,\n",
       "                      'such': 1}),\n",
       "             ('journal',): Counter({'.': 1}),\n",
       "             ('serious',): Counter({'flaws': 1}),\n",
       "             ('flaws',): Counter({'in': 1}),\n",
       "             ('korf',): Counter({'et': 1}),\n",
       "             ('et',): Counter({'al': 1}),\n",
       "             ('al',): Counter({\".'\": 1}),\n",
       "             (\".'\",): Counter({'s': 1}),\n",
       "             ('s',): Counter({'analysis': 1,\n",
       "                      'postulates': 1,\n",
       "                      'assumption': 1}),\n",
       "             ('analysis',): Counter({'on': 1, 'for': 2, 'tools': 1, ';': 2}),\n",
       "             ('time',): Counter({'complexity': 1, 'hopping': 1, 'in': 1}),\n",
       "             ('complexity',): Counter({'of': 1}),\n",
       "             ('*',): Counter({';': 1}),\n",
       "             ('preprocessing',): Counter({':': 1}),\n",
       "             ('step',): Counter({'in': 1}),\n",
       "             ('automating',): Counter({'early': 1}),\n",
       "             ('early',): Counter({'detection': 1}),\n",
       "             ('detection',): Counter({'of': 1, 'tools': 1}),\n",
       "             ('cervical',): Counter({'cancer': 1}),\n",
       "             ('cancer',): Counter({';': 1}),\n",
       "             ('liquid',): Counter({'state': 1}),\n",
       "             ('state',): Counter({'machines': 1,\n",
       "                      'information': 1,\n",
       "                      'interactions': 2}),\n",
       "             ('machines',): Counter({'in': 1, 'concerning': 1}),\n",
       "             ('adbiatic',): Counter({'quantum': 1}),\n",
       "             ('quantum',): Counter({'computers': 1,\n",
       "                      'evolution': 1,\n",
       "                      'computing': 1}),\n",
       "             ('computers',): Counter({'for': 1, '?': 1}),\n",
       "             ('general',): Counter({'computation': 1,\n",
       "                      'family': 1,\n",
       "                      'class': 1}),\n",
       "             ('computation',): Counter({';': 1, 'of': 1}),\n",
       "             ('major',): Counter({'mistakes': 1, 'rewriting': 1}),\n",
       "             ('mistakes',): Counter({'do': 1}),\n",
       "             ('do',): Counter({'not': 1}),\n",
       "             ('not',): Counter({'read': 1,\n",
       "                      'noticed': 1,\n",
       "                      'genuinely': 2,\n",
       "                      'alphabetic': 1,\n",
       "                      'robust': 1,\n",
       "                      'secure': 1,\n",
       "                      'have': 1,\n",
       "                      'apply': 1}),\n",
       "             ('read',): Counter({'_EOS_': 1}),\n",
       "             ('mining',): Counter({'for': 2}),\n",
       "             ('trees',): Counter({'in': 2, 'construction': 1}),\n",
       "             ('graph',): Counter({'is': 2}),\n",
       "             ('complete',): Counter({';': 1, '.': 1, 'computer': 1, 'for': 1}),\n",
       "             ('shown',): Counter({'to': 1, 'that': 1}),\n",
       "             ('towards',): Counter({'a': 1}),\n",
       "             ('hierarchical',): Counter({'model': 1}),\n",
       "             ('model',): Counter({'of': 4, 'for': 1}),\n",
       "             ('consciousness',): Counter({',': 1}),\n",
       "             ('intelligence',): Counter({',': 1, 'require': 2, ';': 1}),\n",
       "             ('mind',): Counter({'and': 1}),\n",
       "             ('body',): Counter({';': 1}),\n",
       "             ('article',): Counter({'is': 2, 'aims': 1, ',': 1, 'has': 1}),\n",
       "             ('taken',): Counter({'out': 1}),\n",
       "             ('out',): Counter({'.': 1, 'of': 1, 'cross': 1}),\n",
       "             ('notation',): Counter({'for': 2, ';': 1, '.': 1}),\n",
       "             ('markov',): Counter({'decision': 2}),\n",
       "             ('decision',): Counter({'processes': 2, 'under': 1}),\n",
       "             ('processes',): Counter({';': 1, '.': 1, 'where': 1}),\n",
       "             ('specifies',): Counter({'a': 1}),\n",
       "             ('icon',): Counter({'challenge': 2}),\n",
       "             ('challenge',): Counter({'on': 2, '2017': 2, 'participants': 1}),\n",
       "             ('algorithm',): Counter({'selection': 2,\n",
       "                      \"'\": 3,\n",
       "                      'of': 1,\n",
       "                      '.': 1,\n",
       "                      'for': 1}),\n",
       "             ('selection',): Counter({';': 1, '.': 1}),\n",
       "             ('present',): Counter({'the': 1, 'our': 1, 'propositional': 1}),\n",
       "             ('recognition',): Counter({'of': 1,\n",
       "                      ';': 1,\n",
       "                      'challenge': 1,\n",
       "                      '.': 1,\n",
       "                      'from': 2}),\n",
       "             ('regular',): Counter({'shapes': 1}),\n",
       "             ('shapes',): Counter({'in': 1}),\n",
       "             ('satelite',): Counter({'images': 1}),\n",
       "             ('images',): Counter({';': 2}),\n",
       "             ('ali',): Counter({'pourmohammad': 2}),\n",
       "             ('pourmohammad',): Counter({'.': 2}),\n",
       "             ('glottochronologic',): Counter({'retrognostic': 2}),\n",
       "             ('retrognostic',): Counter({'of': 2}),\n",
       "             ('proposed',): Counter({'_EOS_': 1, '.': 1, 'methods': 1}),\n",
       "             ('evolution',): Counter({';': 2}),\n",
       "             ('due',): Counter({'to': 6}),\n",
       "             ('extremely',): Counter({'unscientific': 1}),\n",
       "             ('unscientific',): Counter({'errors': 1}),\n",
       "             ('errors',): Counter({'.': 2}),\n",
       "             ('utility',): Counter({'-': 1, 'functions': 1}),\n",
       "             ('probability',): Counter({'duality': 1,\n",
       "                      'distributions': 1,\n",
       "                      'measures': 2,\n",
       "                      'function': 1}),\n",
       "             ('duality',): Counter({';': 1, 'between': 1}),\n",
       "             ('presents',): Counter({'duality': 1, 'some': 1, 'an': 1}),\n",
       "             ('between',): Counter({'probability': 1,\n",
       "                      'arabic': 1,\n",
       "                      'logic': 1,\n",
       "                      'dolphins': 1,\n",
       "                      'the': 1}),\n",
       "             ('distributions',): Counter({'and': 1}),\n",
       "             ('functions',): Counter({'.': 1, 'for': 1, 'are': 1}),\n",
       "             ('temporized',): Counter({'equilibria': 1}),\n",
       "             ('equilibria',): Counter({';': 1}),\n",
       "             ('crucial',): Counter({'error': 1, 'sign': 1}),\n",
       "             ('error',): Counter({'in': 3, 'found': 1}),\n",
       "             ('submission',): Counter({'action': 1,\n",
       "                      'contains': 1,\n",
       "                      '(': 1,\n",
       "                      'has': 1}),\n",
       "             ('action',): Counter({'.': 1, 'and': 1}),\n",
       "             ('backpropagation',): Counter({'in': 1}),\n",
       "             ('matrix',): Counter({'notation': 2, 'satisfying': 1}),\n",
       "             ('note',): Counter({'we': 2, 'on': 3, 'discusses': 1}),\n",
       "             ('calculate',): Counter({'the': 2, 'distance': 1}),\n",
       "             ('gradient',): Counter({'of': 1}),\n",
       "             ('network',): Counter({'function': 1,\n",
       "                      'motifs': 1,\n",
       "                      'to': 1,\n",
       "                      'inspired': 1,\n",
       "                      'learning': 1,\n",
       "                      'building': 1}),\n",
       "             ('function',): Counter({'in': 1, 'that': 1}),\n",
       "             ('random',): Counter({'dfas': 1}),\n",
       "             ('dfas',): Counter({'are': 1}),\n",
       "             ('efficiently',): Counter({'pac': 1}),\n",
       "             ('pac',): Counter({'learnable': 1}),\n",
       "             ('learnable',): Counter({';': 1}),\n",
       "             ('found',): Counter({'by': 1}),\n",
       "             ('dana',): Counter({'angluin': 1}),\n",
       "             ('angluin',): Counter({'and': 1}),\n",
       "             ('lev',): Counter({'reyzin': 1}),\n",
       "             ('reyzin',): Counter({'.': 1}),\n",
       "             ('motifs',): Counter({'in': 1}),\n",
       "             ('music',): Counter({'sequences': 1, ';': 1, ',': 1}),\n",
       "             ('sequences',): Counter({';': 1}),\n",
       "             ('because',): Counter({'it': 2, 'the': 1}),\n",
       "             ('it',): Counter({'needs': 1,\n",
       "                      'is': 4,\n",
       "                      '_EOS_': 1,\n",
       "                      'obtains': 1,\n",
       "                      'could': 1}),\n",
       "             ('needs',): Counter({'a': 1}),\n",
       "             ('methodological',): Counter({'revision': 1}),\n",
       "             ('revision',): Counter({'.': 1, '_EOS_': 1}),\n",
       "             ('glottochronology',): Counter({'and': 1}),\n",
       "             ('problems',): Counter({'of': 1, ',': 1, '.': 1}),\n",
       "             ('protolanguage',): Counter({'reconstruction': 1}),\n",
       "             ('method',): Counter({'of': 2,\n",
       "                      'in': 1,\n",
       "                      'for': 1,\n",
       "                      ';': 1,\n",
       "                      'and': 1}),\n",
       "             ('languages',): Counter({'genealogical': 1,\n",
       "                      ';': 1,\n",
       "                      '.': 1,\n",
       "                      'for': 1}),\n",
       "             ('genealogical',): Counter({'trees': 1}),\n",
       "             ('construction',): Counter({'is': 1}),\n",
       "             ('using',): Counter({'slp': 1,\n",
       "                      'sets': 1,\n",
       "                      'grammatical': 1,\n",
       "                      'particle': 1,\n",
       "                      'video': 2,\n",
       "                      'with': 1}),\n",
       "             ('slp',): Counter({'neural': 1}),\n",
       "             ('persian',): Counter({'handwritten': 1}),\n",
       "             ('handwritten',): Counter({'digits': 1}),\n",
       "             ('digits',): Counter({'recognition': 1}),\n",
       "             ('hopping',): Counter({'technique': 1}),\n",
       "             ('technique',): Counter({'for': 1, 'to': 1}),\n",
       "             ('faster',): Counter({'reinforcement': 1}),\n",
       "             ('reinforcement',): Counter({'learning': 1}),\n",
       "             ('learning',): Counter({'in': 1,\n",
       "                      'framework': 1,\n",
       "                      'low': 1,\n",
       "                      ';': 2,\n",
       "                      'and': 4,\n",
       "                      'problems': 1,\n",
       "                      'model': 1,\n",
       "                      ',': 1,\n",
       "                      'large': 1,\n",
       "                      'states': 1,\n",
       "                      'a': 1}),\n",
       "             ('simulations',): Counter({';': 1}),\n",
       "             ('preprint',): Counter({'has': 1}),\n",
       "             ('convolutional',): Counter({'matching': 1}),\n",
       "             ('matching',): Counter({'pursuit': 2}),\n",
       "             ('pursuit',): Counter({'and': 2}),\n",
       "             ('dictionary',): Counter({'training': 1, 'models': 1}),\n",
       "             ('training',): Counter({';': 1, 'data': 1}),\n",
       "             ('k',): Counter({'-': 1, '.': 2}),\n",
       "             ('svd',): Counter({'is': 1}),\n",
       "             ('demonstrated',): Counter({'in': 1}),\n",
       "             ('translation',): Counter({'invariant': 1}),\n",
       "             ('invariant',): Counter({'setting': 1}),\n",
       "             ('setting',): Counter({'_EOS_': 1}),\n",
       "             ('fitness',): Counter({'landscape': 1}),\n",
       "             ('landscape',): Counter({'analysis': 1}),\n",
       "             ('dynamic',): Counter({'resource': 1}),\n",
       "             ('resource',): Counter({'allocation': 2}),\n",
       "             ('allocation',): Counter({'in': 1, 'of': 1}),\n",
       "             ('multiuser',): Counter({'ofdm': 1}),\n",
       "             ('ofdm',): Counter({'based': 2}),\n",
       "             ('based',): Counter({'cognitive': 2,\n",
       "                      'on': 5,\n",
       "                      'capacity': 1,\n",
       "                      'convergence': 1,\n",
       "                      'ai': 1}),\n",
       "             ('cognitive',): Counter({'radio': 2}),\n",
       "             ('radio',): Counter({'systems': 2}),\n",
       "             ('systems',): Counter({';': 1, 'under': 1}),\n",
       "             ('darwiche',): Counter({'and': 2}),\n",
       "             ('pearl',): Counter({';': 1, \"'\": 1}),\n",
       "             ('that',): Counter({'darwiche': 1,\n",
       "                      'there': 1,\n",
       "                      'should': 1,\n",
       "                      'for': 1,\n",
       "                      'it': 2,\n",
       "                      'defensive': 1,\n",
       "                      'a': 1,\n",
       "                      'selects': 1}),\n",
       "             ('postulates',): Counter({'imply': 1}),\n",
       "             ('imply',): Counter({'an': 1}),\n",
       "             ('interesting',): Counter({'property': 1}),\n",
       "             ('property',): Counter({',': 1}),\n",
       "             ('noticed',): Counter({'by': 1}),\n",
       "             ('authors',): Counter({'.': 1, 'due': 1}),\n",
       "             ('flip',): Counter({'-': 1}),\n",
       "             ('flop',): Counter({'sublinear': 1}),\n",
       "             ('sublinear',): Counter({'models': 2}),\n",
       "             ('models',): Counter({'for': 1,\n",
       "                      'on': 1,\n",
       "                      'and': 1,\n",
       "                      ';': 1,\n",
       "                      'of': 1}),\n",
       "             ('graphs',): Counter({':': 1, '.': 1}),\n",
       "             ('proof',): Counter({'of': 1, 'and': 1}),\n",
       "             ('theorem',): Counter({'1': 1}),\n",
       "             ('1',): Counter({';': 1, '.': 3, 'will': 1, '_EOS_': 1}),\n",
       "             ('prove',): Counter({'that': 1}),\n",
       "             ('there',): Counter({'is': 1}),\n",
       "             ('no',): Counter({'class': 1, 'more': 1}),\n",
       "             ('class',): Counter({'-': 1, 'of': 1}),\n",
       "             ('dual',): Counter({'for': 1, 'message': 1}),\n",
       "             ('almost',): Counter({'all': 1}),\n",
       "             ('all',): Counter({'sublinear': 1, 'of': 2, 'near': 1}),\n",
       "             ('autonomous',): Counter({'perceptron': 1}),\n",
       "             ('perceptron',): Counter({'neural': 1, ',': 1}),\n",
       "             ('inspired',): Counter({'from': 1}),\n",
       "             ('from',): Counter({'quantum': 1,\n",
       "                      'bilingual': 1,\n",
       "                      '3d': 2,\n",
       "                      'further': 1,\n",
       "                      'an': 1}),\n",
       "             ('computing',): Counter({';': 1, 'and': 1}),\n",
       "             ('abstract',): Counter({'will': 1}),\n",
       "             ('modified',): Counter({'after': 1}),\n",
       "             ('after',): Counter({'correcting': 1}),\n",
       "             ('correcting',): Counter({'the': 1}),\n",
       "             ('minor',): Counter({'error': 1}),\n",
       "             ('eq',): Counter({'.(': 1}),\n",
       "             ('.(',): Counter({'2': 1}),\n",
       "             ('2',): Counter({')': 1, '.': 1, '$': 1, '$)': 1}),\n",
       "             (')',): Counter({'_EOS_': 2,\n",
       "                      'new': 1,\n",
       "                      'quantified': 1,\n",
       "                      'was': 1,\n",
       "                      'optimal': 1,\n",
       "                      'is': 1}),\n",
       "             ('sets',): Counter({'of': 2}),\n",
       "             ('measures',): Counter({'to': 1, 'as': 1}),\n",
       "             ('represent',): Counter({'uncertainty': 1}),\n",
       "             ('uncertainty',): Counter({';': 2, '.': 2}),\n",
       "             ('i',): Counter({'explore': 1, 'discuss': 1}),\n",
       "             ('explore',): Counter({'the': 1}),\n",
       "             ('use',): Counter({'of': 2,\n",
       "                      'the': 1,\n",
       "                      'group': 1,\n",
       "                      'rmse': 1,\n",
       "                      'marker': 1}),\n",
       "             ('representation',): Counter({'of': 4, 'space': 1}),\n",
       "             ('comment',): Counter({'on': 3}),\n",
       "             ('argumentation',): Counter({';': 1, '.': 1}),\n",
       "             ('theory',): Counter({'of': 3, '.': 3, ',': 1}),\n",
       "             ('defaults',): Counter({'and': 1}),\n",
       "             ('meaning',): Counter({'of': 1, '.': 1}),\n",
       "             ('[',): Counter({'gs16': 1, 'arxiv': 1, 'under': 1}),\n",
       "             ('gs16',): Counter({']': 1}),\n",
       "             (']',): Counter({'to': 1, 'is': 1, 'graduate': 1}),\n",
       "             ('develop',): Counter({'(': 1, 'a': 1}),\n",
       "             ('(',): Counter({'the': 1,\n",
       "                      'ccca': 1,\n",
       "                      'original': 1,\n",
       "                      'constant': 1,\n",
       "                      '1934': 1,\n",
       "                      'nearly': 1,\n",
       "                      'spf': 1}),\n",
       "             ('outline',): Counter({'of': 1}),\n",
       "             ('activitynet',): Counter({'challenge': 1, 'large': 1}),\n",
       "             ('2017',): Counter({'summary': 2, '_EOS_': 2, 'symposium': 2}),\n",
       "             ('summary',): Counter({';': 1, ':': 1}),\n",
       "             ('large',): Counter({'scale': 3}),\n",
       "             ('scale',): Counter({'activity': 1,\n",
       "                      'graphical': 1,\n",
       "                      'structured': 1}),\n",
       "             ('activity',): Counter({'recognition': 1}),\n",
       "             ('participants',): Counter({'papers': 1}),\n",
       "             ('papers',): Counter({'.': 1}),\n",
       "             ('yahoo',): Counter({'query': 1, 'webscope': 1}),\n",
       "             ('query',): Counter({'treebank': 2}),\n",
       "             ('treebank',): Counter({',': 2}),\n",
       "             ('v',): Counter({'.': 1}),\n",
       "             ('0',): Counter({';': 1, ',': 1}),\n",
       "             ('annotation',): Counter({'guidelines': 1}),\n",
       "             ('guidelines',): Counter({'for': 1}),\n",
       "             ('webscope',): Counter({'release': 1}),\n",
       "             ('release',): Counter({'of': 1}),\n",
       "             ('may',): Counter({'2016': 1, '17': 1, 'be': 1}),\n",
       "             ('2016',): Counter({'.': 1, 'shared': 1}),\n",
       "             ('under',): Counter({'uncertainty': 1, 'partial': 1, ']': 1}),\n",
       "             ('derive',): Counter({'axiomatically': 1}),\n",
       "             ('axiomatically',): Counter({'the': 1}),\n",
       "             ('should',): Counter({'be': 1}),\n",
       "             ('make',): Counter({'decisions': 1}),\n",
       "             ('decisions',): Counter({'given': 1}),\n",
       "             ('given',): Counter({'any': 1, 'and': 1}),\n",
       "             ('any',): Counter({'form': 1, 'training': 1}),\n",
       "             ('form',): Counter({'of': 1}),\n",
       "             ('underlying',): Counter({'uncertainty': 1}),\n",
       "             ('text',): Counter({'analysis': 1}),\n",
       "             ('tools',): Counter({'in': 1, 'using': 1}),\n",
       "             ('spoken',): Counter({'language': 1}),\n",
       "             ('contains',): Counter({'the': 2}),\n",
       "             ('postscript',): Counter({'of': 1}),\n",
       "             ('final',): Counter({'version': 1}),\n",
       "             ('slides',): Counter({'used': 1}),\n",
       "             ('our',): Counter({'acl': 1,\n",
       "                      'latest': 1,\n",
       "                      'system': 1,\n",
       "                      'policies': 1}),\n",
       "             ('acl',): Counter({'-': 1}),\n",
       "             ('94',): Counter({'tutorial': 1}),\n",
       "             ('tutorial',): Counter({'.': 1, 'on': 1}),\n",
       "             ('discrimination',): Counter({'between': 1}),\n",
       "             ('arabic',): Counter({'and': 1}),\n",
       "             ('latin',): Counter({'from': 1}),\n",
       "             ('bilingual',): Counter({'documents': 1}),\n",
       "             ('documents',): Counter({';': 1}),\n",
       "             ('2011',): Counter({'international': 1}),\n",
       "             ('international',): Counter({'conference': 3, 'workshop': 2}),\n",
       "             ('conference',): Counter({'on': 3}),\n",
       "             ('communications',): Counter({',': 1}),\n",
       "             ('control',): Counter({'applications': 1, 'in': 1, 'plants': 1}),\n",
       "             ('applications',): Counter({'(': 1, 'of': 1}),\n",
       "             ('ccca',): Counter({')': 1}),\n",
       "             ('machine',): Counter({'-': 1, 'learning': 3}),\n",
       "             ('framework',): Counter({'for': 2, ';': 1, '(': 1}),\n",
       "             ('design',): Counter({'for': 1}),\n",
       "             ('manufacturability',): Counter({';': 1}),\n",
       "             ('duplicate',): Counter({'submission': 1}),\n",
       "             ('original',): Counter({'is': 1}),\n",
       "             ('arxiv',): Counter({':': 3, 'administrators': 2}),\n",
       "             ('1612',): Counter({'.': 1}),\n",
       "             ('02141',): Counter({').': 1}),\n",
       "             (').',): Counter({'hence': 1}),\n",
       "             ('hence',): Counter({'want': 1}),\n",
       "             ('want',): Counter({'to': 1}),\n",
       "             ('withdraw',): Counter({'it': 1}),\n",
       "             ('experiment',): Counter({';': 1, ',': 1, 'results': 1}),\n",
       "             ('aims',): Counter({'at': 1}),\n",
       "             ('at',): Counter({'clarifying': 1, 'arxiv': 1, 'state': 1}),\n",
       "             ('clarifying',): Counter({'the': 1}),\n",
       "             ('practice',): Counter({'of': 1}),\n",
       "             ('scientific',): Counter({'experiment': 1}),\n",
       "             ('mainly',): Counter({'by': 1, 'study': 1}),\n",
       "             ('hooking',): Counter({'observability': 1}),\n",
       "             ('observability',): Counter({'on': 1}),\n",
       "             ('calculability',): Counter({'.': 1}),\n",
       "             ('minds',): Counter({'computable': 1, 'and': 1}),\n",
       "             ('computable',): Counter({'?': 1}),\n",
       "             ('explores',): Counter({'the': 1}),\n",
       "             ('limits',): Counter({'of': 1, '.': 1}),\n",
       "             ('turing',): Counter({'machines': 1}),\n",
       "             ('concerning',): Counter({'the': 1}),\n",
       "             ('modeling',): Counter({'of': 1}),\n",
       "             ('suggests',): Counter({'alternatives': 1}),\n",
       "             ('alternatives',): Counter({'to': 1}),\n",
       "             ('go',): Counter({'beyond': 1}),\n",
       "             ('beyond',): Counter({'those': 1, 'description': 1}),\n",
       "             ('those',): Counter({'limits': 1}),\n",
       "             ('extraction',): Counter({'de': 1}),\n",
       "             ('de',): Counter({'concepts': 1, 'gnes': 1}),\n",
       "             ('concepts',): Counter({'sous': 1, '.': 1}),\n",
       "             ('sous',): Counter({'contraintes': 1}),\n",
       "             ('contraintes',): Counter({'dans': 1}),\n",
       "             ('dans',): Counter({'des': 1}),\n",
       "             ('des',): Counter({'donnes': 1}),\n",
       "             ('donnes',): Counter({'d': 1}),\n",
       "             ('d',): Counter({\"'\": 1}),\n",
       "             ('expression',): Counter({'de': 1}),\n",
       "             ('gnes',): Counter({';': 1}),\n",
       "             ('propose',): Counter({'a': 4, 'to': 1}),\n",
       "             ('extract',): Counter({'constrained': 1}),\n",
       "             ('constrained',): Counter({'formal': 1, 'feed': 1}),\n",
       "             ('comments',): Counter({'on': 2}),\n",
       "             ('\"',): Counter({'a': 3,\n",
       "                      'by': 3,\n",
       "                      'approaching': 2,\n",
       "                      'in': 1,\n",
       "                      'sense': 1,\n",
       "                      'suggested': 1}),\n",
       "             ('combination',): Counter({'of': 2}),\n",
       "             ('evidence',): Counter({'based': 2}),\n",
       "             ('compromise',): Counter({'\"': 1, \"''\": 1}),\n",
       "             ('yamada',): Counter({';': 1, '_EOS_': 1}),\n",
       "             ('``',): Counter({'a': 1}),\n",
       "             (\"''\",): Counter({'by': 1}),\n",
       "             ('low',): Counter({'-': 1}),\n",
       "             ('shot',): Counter({'facial': 1, 'face': 1}),\n",
       "             ('facial',): Counter({'representations': 1}),\n",
       "             ('representations',): Counter({'via': 1, 'in': 1}),\n",
       "             ('2d',): Counter({'warping': 2}),\n",
       "             ('warping',): Counter({';': 1, 'module': 1}),\n",
       "             ('work',): Counter({',': 1, '.': 1, 'is': 1}),\n",
       "             ('study',): Counter({'the': 2, ';': 1}),\n",
       "             ('influence',): Counter({'of': 1}),\n",
       "             ('module',): Counter({'for': 1}),\n",
       "             ('one',): Counter({'-': 2}),\n",
       "             ('face',): Counter({'recognition': 1, 'of': 1}),\n",
       "             ('automatic',): Counter({'generation': 1,\n",
       "                      'liver': 1,\n",
       "                      'segmentation': 1}),\n",
       "             ('generation',): Counter({'of': 1}),\n",
       "             ('benchmarks',): Counter({'for': 1}),\n",
       "             ('plagiarism',): Counter({'detection': 1}),\n",
       "             ('grammatical',): Counter({'evolution': 1}),\n",
       "             ('rewriting',): Counter({'.': 1}),\n",
       "             ('mu',): Counter({'-': 1}),\n",
       "             ('partial',): Counter({'channel': 1, 'observations': 1}),\n",
       "             ('channel',): Counter({'state': 1}),\n",
       "             ('information',): Counter({';': 1, 'theory': 1, 'for': 1}),\n",
       "             ('some',): Counter({'errors': 1,\n",
       "                      'properties': 3,\n",
       "                      'exceptionally': 1,\n",
       "                      'of': 1}),\n",
       "             ('advances',): Counter({'in': 2}),\n",
       "             ('require',): Counter({'progress': 2}),\n",
       "             ('progress',): Counter({'across': 2}),\n",
       "             ('across',): Counter({'all': 2}),\n",
       "             ('computer',): Counter({'science': 3,\n",
       "                      'oriented': 1,\n",
       "                      '-': 1,\n",
       "                      'model': 2}),\n",
       "             ('science',): Counter({';': 1, '.': 1, 'and': 1}),\n",
       "             ('exploration',): Counter({'of': 1}),\n",
       "             ('object',): Counter({'recognition': 2, 'in': 2}),\n",
       "             ('3d',): Counter({'point': 2}),\n",
       "             ('point',): Counter({'cloud': 2}),\n",
       "             ('cloud',): Counter({';': 1, 'data': 1}),\n",
       "             ('latest',): Counter({'experiment': 1}),\n",
       "             ('data',): Counter({'collected': 1,\n",
       "                      'gathering': 1,\n",
       "                      ';': 1,\n",
       "                      '.': 1}),\n",
       "             ('collected',): Counter({'through': 1}),\n",
       "             ('through',): Counter({'moving': 1}),\n",
       "             ('moving',): Counter({'car': 1}),\n",
       "             ('car',): Counter({'.': 1, ',': 2}),\n",
       "             ('quantified',): Counter({'conditional': 2}),\n",
       "             ('conditional',): Counter({'logics': 1, 'logic': 1}),\n",
       "             ('logics',): Counter({'are': 1}),\n",
       "             ('fragments',): Counter({'of': 1}),\n",
       "             ('hol',): Counter({';': 1}),\n",
       "             ('semantic',): Counter({'embedding': 1, 'parsing': 2}),\n",
       "             ('embedding',): Counter({'of': 1}),\n",
       "             ('constant',): Counter({'domain': 1}),\n",
       "             ('domain',): Counter({')': 1}),\n",
       "             ('logic',): Counter({'in': 1,\n",
       "                      'is': 1,\n",
       "                      'programming': 5,\n",
       "                      ',': 1,\n",
       "                      'programs': 1}),\n",
       "             ('classical',): Counter({'higher': 1}),\n",
       "             ('higher',): Counter({'-': 1, 'order': 2}),\n",
       "             ('order',): Counter({'logic': 1, 'rue': 3}),\n",
       "             ('presented',): Counter({'.': 1, 'as': 1}),\n",
       "             ('memoriam',): Counter({'maurice': 1}),\n",
       "             ('maurice',): Counter({'gross': 2}),\n",
       "             ('gross',): Counter({';': 1, '(': 1}),\n",
       "             ('1934',): Counter({'-': 1}),\n",
       "             ('2001',): Counter({')': 1}),\n",
       "             ('was',): Counter({'both': 1, 'incorrect': 1}),\n",
       "             ('both',): Counter({'a': 1}),\n",
       "             ('great',): Counter({'linguist': 1}),\n",
       "             ('linguist',): Counter({'and': 1}),\n",
       "             ('pioneer',): Counter({'in': 1}),\n",
       "             ('written',): Counter({'in': 1}),\n",
       "             ('homage',): Counter({'to': 1}),\n",
       "             ('his',): Counter({'memory': 1}),\n",
       "             ('memory',): Counter({'_EOS_': 1}),\n",
       "             ('26th',): Counter({'international': 2}),\n",
       "             ('programming',): Counter({'special': 2,\n",
       "                      'paradigm': 1,\n",
       "                      'and': 1,\n",
       "                      'languages': 1,\n",
       "                      '.': 1,\n",
       "                      ';': 2,\n",
       "                      'intended': 1,\n",
       "                      'classes': 1}),\n",
       "             ('preface',): Counter({'to': 1}),\n",
       "             ('approaching',): Counter({'human': 2}),\n",
       "             ('human',): Counter({'language': 3, 'brain': 1}),\n",
       "             ('with',): Counter({'complex': 2,\n",
       "                      'syntax': 1,\n",
       "                      'the': 1,\n",
       "                      'imperative': 1,\n",
       "                      'external': 1,\n",
       "                      'ijcnn': 1,\n",
       "                      'extrue': 1,\n",
       "                      'cross': 1,\n",
       "                      'sequential': 1}),\n",
       "             ('cong',): Counter({'&': 2}),\n",
       "             ('&',): Counter({'liu': 2}),\n",
       "             ('liu',): Counter({';': 1, '_EOS_': 1}),\n",
       "             ('norm',): Counter({'-': 2}),\n",
       "             ('capacity',): Counter({'control': 1, ',': 1}),\n",
       "             ('investigate',): Counter({'the': 2}),\n",
       "             ('convexity',): Counter({'and': 1}),\n",
       "             ('characterization',): Counter({'of': 1}),\n",
       "             ('family',): Counter({'of': 1}),\n",
       "             ('feed',): Counter({'-': 1}),\n",
       "             ('forward',): Counter({'networks': 1}),\n",
       "             ('compression',): Counter({'of': 1}),\n",
       "             ('vocabulary',): Counter({'in': 1}),\n",
       "             ('oriented',): Counter({'languages': 2}),\n",
       "             ('uses',): Counter({'the': 1}),\n",
       "             ('entropy',): Counter({'of': 3, 'is': 1}),\n",
       "             ('ideal',): Counter({'bose': 1}),\n",
       "             ('bose',): Counter({'-': 1}),\n",
       "             ('einstein',): Counter({'gas': 1}),\n",
       "             ('gas',): Counter({'to': 1}),\n",
       "             ('minimize',): Counter({'losses': 1}),\n",
       "             ('losses',): Counter({'in': 1}),\n",
       "             ('unary',): Counter({'coding': 2}),\n",
       "             ('coding',): Counter({'for': 1, 'of': 1}),\n",
       "             ('properties',): Counter({'of': 3}),\n",
       "             ('significance',): Counter({'for': 1}),\n",
       "             ('biological',): Counter({'learning': 1}),\n",
       "             ('instantaneously',): Counter({'trained': 1}),\n",
       "             ('trained',): Counter({'neural': 1}),\n",
       "             ('ukrainian',): Counter({'writing': 1, 'and': 1, 'version': 1}),\n",
       "             ('writing',): Counter({'system': 1}),\n",
       "             ('grapheme',): Counter({'-': 1}),\n",
       "             ('phoneme',): Counter({'relation': 1}),\n",
       "             ('relation',): Counter({'in': 1}),\n",
       "             ('cyrillic',): Counter({'alphabet': 1}),\n",
       "             ('alphabet',): Counter({'.': 1}),\n",
       "             ('convex',): Counter({'multiview': 1, 'online': 1}),\n",
       "             ('multiview',): Counter({'fisher': 1}),\n",
       "             ('fisher',): Counter({'discriminant': 1}),\n",
       "             ('discriminant',): Counter({'analysis': 1}),\n",
       "             ('section',): Counter({'1': 1}),\n",
       "             ('3',): Counter({'was': 1}),\n",
       "             ('incorrect',): Counter({',': 1}),\n",
       "             ('removed',): Counter({'from': 1}),\n",
       "             ('further',): Counter({'submissions': 1}),\n",
       "             ('submissions',): Counter({'.': 1}),\n",
       "             ('rewritten',): Counter({'version': 1}),\n",
       "             ('posted',): Counter({'in': 1, 'at': 1}),\n",
       "             ('future',): Counter({'.': 2, 'value': 1}),\n",
       "             ('why',): Counter({'bother': 1, \"'\": 2}),\n",
       "             ('bother',): Counter({'with': 1}),\n",
       "             ('syntax',): Counter({'?': 1, 'vs': 1, 'and': 1}),\n",
       "             ('discusses',): Counter({'the': 1}),\n",
       "             ('role',): Counter({'of': 1}),\n",
       "             ('vs',): Counter({'.': 1}),\n",
       "             ('semantics',): Counter({'and': 1, 'of': 2}),\n",
       "             ('interplay',): Counter({'between': 1}),\n",
       "             ('philosophy',): Counter({',': 1, 'in': 1}),\n",
       "             ('game',): Counter({'theory': 2, ';': 1}),\n",
       "             ('gsa',): Counter({':': 2}),\n",
       "             ('gravitational',): Counter({'search': 2}),\n",
       "             ('search',): Counter({'algorithm': 2, 'heuristics': 1}),\n",
       "             ('genuinely',): Counter({'based': 2}),\n",
       "             ('law',): Counter({'of': 2}),\n",
       "             ('gravity',): Counter({';': 1, '_EOS_': 1}),\n",
       "             ('neurocontrol',): Counter({'methods': 1}),\n",
       "             ('methods',): Counter({'review': 1, 'of': 1, 'and': 1, 'to': 1}),\n",
       "             ('review',): Counter({';': 1, 'of': 1}),\n",
       "             ('applying',): Counter({'neural': 1}),\n",
       "             ('plants',): Counter({'are': 1}),\n",
       "             ('considered',): Counter({'.': 1}),\n",
       "             ('schemes',): Counter({'are': 1}),\n",
       "             ('advantages',): Counter({'and': 1}),\n",
       "             ('disadvantages',): Counter({'are': 1}),\n",
       "             ('discussed',): Counter({'.': 3}),\n",
       "             ('universality',): Counter({'of': 1}),\n",
       "             ('online',): Counter({'mirror': 1, 'learning': 1}),\n",
       "             ('mirror',): Counter({'descent': 2}),\n",
       "             ('descent',): Counter({';': 1, 'can': 1}),\n",
       "             ('show',): Counter({'that': 4, 'applications': 1, 'how': 1}),\n",
       "             ('can',): Counter({'always': 1}),\n",
       "             ('always',): Counter({'achieve': 1}),\n",
       "             ('achieve',): Counter({'a': 1}),\n",
       "             ('nearly',): Counter({')': 1}),\n",
       "             ('optimal',): Counter({'regret': 1}),\n",
       "             ('regret',): Counter({'guarantee': 1, 'bound': 1}),\n",
       "             ('guarantee',): Counter({'.': 1}),\n",
       "             ('possibility',): Counter({'of': 1}),\n",
       "             ('making',): Counter({'the': 1}),\n",
       "             ('brain',): Counter({';': 1}),\n",
       "             ('development',): Counter({'of': 1}),\n",
       "             ('building',): Counter({'by': 1}),\n",
       "             ('corresponding',): Counter({'parts': 1, 'recent': 1}),\n",
       "             ('parts',): Counter({'of': 1}),\n",
       "             ('dna',): Counter({'code': 1}),\n",
       "             ('code',): Counter({'is': 1}),\n",
       "             ('discuss',): Counter({'how': 1}),\n",
       "             ('how',): Counter({'the': 1, 'evolutionary': 1, 'to': 2}),\n",
       "             ('ai',): Counter({'community': 1, 'and': 1, 'perspective': 1}),\n",
       "             ('community',): Counter({'views': 1}),\n",
       "             ('views',): Counter({'concerns': 1}),\n",
       "             ('concerns',): Counter({'about': 1}),\n",
       "             ('emergence',): Counter({'of': 1}),\n",
       "             ('superintelligent',): Counter({'ai': 1}),\n",
       "             ('related',): Counter({'philosophical': 1}),\n",
       "             ('issues',): Counter({'.': 1}),\n",
       "             ('survey',): Counter({'on': 1, 'we': 1, 'of': 1}),\n",
       "             ('contextual',): Counter({'multi': 1, 'bandit': 1}),\n",
       "             ('multi',): Counter({'-': 1}),\n",
       "             ('armed',): Counter({'bandits': 1}),\n",
       "             ('bandits',): Counter({';': 1}),\n",
       "             ('cover',): Counter({'a': 1}),\n",
       "             ('few',): Counter({'stochastic': 1}),\n",
       "             ('stochastic',): Counter({'and': 1}),\n",
       "             ('adversarial',): Counter({'contextual': 1, 'examples': 1}),\n",
       "             ('bandit',): Counter({'algorithms': 1}),\n",
       "             ('algorithms',): Counter({'.': 1, ',': 1}),\n",
       "             ('analyze',): Counter({'each': 1, 'the': 1}),\n",
       "             ('each',): Counter({'algorithm': 1}),\n",
       "             ('assumption',): Counter({'and': 1}),\n",
       "             ('bound',): Counter({'.': 1}),\n",
       "             ('parallels',): Counter({'of': 1}),\n",
       "             ('behavior',): Counter({'of': 1, '.': 1}),\n",
       "             ('bottlenose',): Counter({'dolphins': 1}),\n",
       "             ('dolphins',): Counter({';': 1, 'and': 1}),\n",
       "             ('similarities',): Counter({'between': 1}),\n",
       "             ('humans',): Counter({'with': 1}),\n",
       "             ('help',): Counter({'of': 1}),\n",
       "             ('quantitative',): Counter({'linguistics': 1}),\n",
       "             ('linguistics',): Counter({'and': 1}),\n",
       "             ('metaheuristics',): Counter({';': 1, 'in': 1}),\n",
       "             ('chapter',): Counter({'describes': 1}),\n",
       "             ('describes',): Counter({'the': 1, 'our': 1}),\n",
       "             ('five',): Counter({'distinct': 1}),\n",
       "             ('distinct',): Counter({'periods': 1}),\n",
       "             ('periods',): Counter({',': 1}),\n",
       "             ('starting',): Counter({'long': 1}),\n",
       "             ('long',): Counter({'before': 1, 'time': 1, 'beach': 1}),\n",
       "             ('before',): Counter({'the': 1}),\n",
       "             ('first',): Counter({'use': 1, 'international': 2, 'order': 1}),\n",
       "             ('term',): Counter({'and': 1}),\n",
       "             ('ending',): Counter({'a': 1}),\n",
       "             ('energy',): Counter({'efficient': 1}),\n",
       "             ('efficient',): Counter({'scheme': 1, 'deep': 1}),\n",
       "             ('scheme',): Counter({'for': 1}),\n",
       "             ('gathering',): Counter({'in': 1}),\n",
       "             ('wireless',): Counter({'sensor': 1}),\n",
       "             ('sensor',): Counter({'networks': 1}),\n",
       "             ('particle',): Counter({'swarm': 1}),\n",
       "             ('swarm',): Counter({'optimization': 1}),\n",
       "             ('optimization',): Counter({';': 3, 'problems': 1}),\n",
       "             ('sign',): Counter({'error': 1}),\n",
       "             ('equation',): Counter({'1': 1}),\n",
       "             ('bengali',): Counter({'readability': 1, 'language': 1}),\n",
       "             ('readability',): Counter({'score': 1, 'of': 1}),\n",
       "             ('score',): Counter({';': 1}),\n",
       "             ('have',): Counter({'proposed': 1, 'got': 1, 'the': 1}),\n",
       "             ('texts',): Counter({'.': 2, 'with': 1}),\n",
       "             ('got',): Counter({'some': 1}),\n",
       "             ('exceptionally',): Counter({'good': 1}),\n",
       "             ('good',): Counter({'results': 1}),\n",
       "             ('experiments',): Counter({'.': 1}),\n",
       "             ('paradigm',): Counter({'and': 1}),\n",
       "             ('prolog',): Counter({';': 1, 'appropriate': 1}),\n",
       "             ('appropriate',): Counter({'for': 1}),\n",
       "             ('course',): Counter({'on': 1}),\n",
       "             ('students',): Counter({'familiar': 1, 'taking': 1}),\n",
       "             ('familiar',): Counter({'with': 1}),\n",
       "             ('imperative',): Counter({'programming': 1}),\n",
       "             ('distance',): Counter({'to': 2, ';': 1, 'in': 1}),\n",
       "             ('area',): Counter({'where': 1, 'of': 1}),\n",
       "             ('where',): Counter({'car': 1, 'only': 1}),\n",
       "             ('video',): Counter({'analysis': 1, 'cameras': 1}),\n",
       "             ('cameras',): Counter({'installed': 1}),\n",
       "             ('installed',): Counter({'on': 1}),\n",
       "             ('its',): Counter({'area': 1, 'meaning': 1}),\n",
       "             ('movement',): Counter({'.': 1}),\n",
       "             ('group',): Counter({'theory': 1, 'actions': 1, ',': 1}),\n",
       "             ('actions',): Counter({',': 1}),\n",
       "             ('evolutionary',): Counter({'algorithms': 1, 'solve': 1}),\n",
       "             ('global',): Counter({'optimization': 1}),\n",
       "             ('orbit',): Counter({'to': 1}),\n",
       "             ('understand',): Counter({'how': 1}),\n",
       "             ('solve',): Counter({'nonconvex': 1}),\n",
       "             ('nonconvex',): Counter({'optimization': 1}),\n",
       "             ('telugu',): Counter({';': 1, 'script': 1}),\n",
       "             ('investigation',): Counter({'of': 1}),\n",
       "             ('script',): Counter({'.': 1, 'is': 1}),\n",
       "             ('since',): Counter({'this': 1}),\n",
       "             ('syllabic',): Counter({',': 1}),\n",
       "             ('alphabetic',): Counter({',': 1}),\n",
       "             ('somewhat',): Counter({'complicated': 1}),\n",
       "             ('complicated',): Counter({'.': 1}),\n",
       "             ('word',): Counter({'segmentation': 2}),\n",
       "             ('segmentation',): Counter({'on': 2, 'method': 1, 'of': 1}),\n",
       "             ('micro',): Counter({'-': 2}),\n",
       "             ('blog',): Counter({'texts': 2}),\n",
       "             ('external',): Counter({'lexicon': 1}),\n",
       "             ('lexicon',): Counter({'and': 1}),\n",
       "             ('heterogeneous',): Counter({'data': 1}),\n",
       "             ('designed',): Counter({'for': 1}),\n",
       "             ('nlpcc',): Counter({'2016': 1}),\n",
       "             ('shared',): Counter({'task': 1}),\n",
       "             ('task',): Counter({'on': 1}),\n",
       "             ('guarded',): Counter({'resolution': 1}),\n",
       "             ('resolution',): Counter({'for': 1,\n",
       "                      'rule': 1,\n",
       "                      'with': 1,\n",
       "                      'does': 1,\n",
       "                      'approach': 1}),\n",
       "             ('answer',): Counter({'set': 3}),\n",
       "             ('set',): Counter({'programming': 3}),\n",
       "             ('describe',): Counter({'a': 1}),\n",
       "             ('variant',): Counter({'of': 1}),\n",
       "             ('rule',): Counter({'of': 1}),\n",
       "             ('stable',): Counter({'semantics': 1}),\n",
       "             ('programs',): Counter({'.': 1}),\n",
       "             ('result',): Counter({'.': 1}),\n",
       "             ('cornell',): Counter({'spf': 1, 'semantic': 2}),\n",
       "             ('spf',): Counter({':': 1, ')': 1}),\n",
       "             ('parsing',): Counter({'framework': 2}),\n",
       "             ('inference',): Counter({'framework': 1}),\n",
       "             ('mapping',): Counter({'natural': 1}),\n",
       "             ('semistability',): Counter({'-': 1}),\n",
       "             ('convergence',): Counter({'analysis': 1}),\n",
       "             ('paracontracting',): Counter({'multiagent': 1}),\n",
       "             ('multiagent',): Counter({'coordination': 1}),\n",
       "             ('coordination',): Counter({'optimization': 1}),\n",
       "             ('sequential',): Counter({'technical': 1, 'processes': 1}),\n",
       "             ('technical',): Counter({'report': 2}),\n",
       "             ('report',): Counter({'extends': 1, ':': 1}),\n",
       "             ('extends',): Counter({'some': 1}),\n",
       "             ('previous',): Counter({'results': 1}),\n",
       "             ('1306',): Counter({'.': 1}),\n",
       "             ('0225',): Counter({'.': 1}),\n",
       "             ('proceedings',): Counter({'of': 4}),\n",
       "             ('workshop',): Counter({'on': 2}),\n",
       "             ('joint',): Counter({'with': 1}),\n",
       "             ('ijcnn',): Counter({',': 1}),\n",
       "             ('anchorage',): Counter({',': 1}),\n",
       "             ('17',): Counter({'-': 1}),\n",
       "             ('18',): Counter({',': 1}),\n",
       "             ('attack',): Counter({'rmse': 1}),\n",
       "             ('rmse',): Counter({'leaderboard': 1, 'for': 1}),\n",
       "             ('leaderboard',): Counter({':': 1}),\n",
       "             ('case',): Counter({'study': 1}),\n",
       "             ('manuscript',): Counter({',': 1}),\n",
       "             ('briefly',): Counter({'introduce': 1}),\n",
       "             ('introduce',): Counter({'several': 1}),\n",
       "             ('several',): Counter({'tricks': 1}),\n",
       "             ('tricks',): Counter({'to': 1}),\n",
       "             ('climb',): Counter({'the': 1}),\n",
       "             ('leaderboards',): Counter({'which': 1}),\n",
       "             ('which',): Counter({'use': 1, 'is': 1, 'policies': 1}),\n",
       "             ('evaluation',): Counter({'without': 1}),\n",
       "             ('without',): Counter({'exploiting': 1}),\n",
       "             ('exploiting',): Counter({'any': 1}),\n",
       "             ('standardization',): Counter({'of': 1}),\n",
       "             ('lexical',): Counter({'information': 1}),\n",
       "             ('nlp',): Counter({';': 1}),\n",
       "             ('formats',): Counter({'is': 1}),\n",
       "             ('well',): Counter({'as': 1}),\n",
       "             ('presentation',): Counter({'of': 1}),\n",
       "             ('standardisation',): Counter({'activities': 1}),\n",
       "             ('activities',): Counter({'.': 1}),\n",
       "             ('stock',): Counter({'market': 2, 'or': 1}),\n",
       "             ('market',): Counter({'prediction': 2}),\n",
       "             ('prediction',): Counter({';': 1, 'is': 1, 'for': 1, '\".': 1}),\n",
       "             ('act',): Counter({'of': 1}),\n",
       "             ('trying',): Counter({'to': 1}),\n",
       "             ('determine',): Counter({'the': 1}),\n",
       "             ('value',): Counter({'of': 1}),\n",
       "             ('company',): Counter({'stock': 1}),\n",
       "             ('or',): Counter({'other': 1, 'logic': 1}),\n",
       "             ('other',): Counter({'financial': 1}),\n",
       "             ('financial',): Counter({'instrument': 1, 'exchange': 1}),\n",
       "             ('instrument',): Counter({'traded': 1}),\n",
       "             ('traded',): Counter({'on': 1}),\n",
       "             ('exchange',): Counter({'.': 1}),\n",
       "             ('defensive',): Counter({'distillation': 2}),\n",
       "             ('distillation',): Counter({'is': 2}),\n",
       "             ('robust',): Counter({'to': 1}),\n",
       "             ('examples',): Counter({';': 1}),\n",
       "             ('secure',): Counter({':': 1}),\n",
       "             ('more',): Counter({'resistant': 1, 'efficient': 1}),\n",
       "             ('resistant',): Counter({'to': 1}),\n",
       "             ('targeted',): Counter({'misclassification': 1}),\n",
       "             ('misclassification',): Counter({'attacks': 1}),\n",
       "             ('attacks',): Counter({'than': 1}),\n",
       "             ('than',): Counter({'unprotected': 1}),\n",
       "             ('unprotected',): Counter({'neural': 1}),\n",
       "             ('nips',): Counter({'2017': 2}),\n",
       "             ('symposium',): Counter({'on': 2}),\n",
       "             ('interpretable',): Counter({'machine': 2}),\n",
       "             ('held',): Counter({'in': 1}),\n",
       "             ('beach',): Counter({',': 1}),\n",
       "             ('california',): Counter({',': 1}),\n",
       "             ('usa',): Counter({'on': 1}),\n",
       "             ('december',): Counter({'7': 1}),\n",
       "             ('7',): Counter({',': 1}),\n",
       "             ('piecewise',): Counter({'linear': 2}),\n",
       "             ('linear',): Counter({'activation': 1, 'multilayer': 1}),\n",
       "             ('activation',): Counter({'functions': 1}),\n",
       "             ('administrators',): Counter({'because': 2}),\n",
       "             ('intentionally',): Counter({'incomplete': 1}),\n",
       "             ('incomplete',): Counter({',': 1}),\n",
       "             ('violation',): Counter({'of': 1}),\n",
       "             ('policies',): Counter({'.': 1, 'may': 1}),\n",
       "             ('triangle',): Counter({'inequality': 2}),\n",
       "             ('inequality',): Counter({'for': 2}),\n",
       "             ('jaccard',): Counter({'distance': 2}),\n",
       "             ('two',): Counter({'simple': 1}),\n",
       "             ('simple',): Counter({'proofs': 1}),\n",
       "             ('proofs',): Counter({'of': 1, 'for': 1}),\n",
       "             ('terms',): Counter({'of': 1}),\n",
       "             ('nonnegative',): Counter({',': 1}),\n",
       "             ('monotone',): Counter({',': 1}),\n",
       "             ('submodular',): Counter({'functions': 1}),\n",
       "             ('realize',): Counter({'\"': 1}),\n",
       "             ('sense',): Counter({'of': 2}),\n",
       "             ('humour',): Counter({'\"': 2}),\n",
       "             ('suggested',): Counter({'previously': 1}),\n",
       "             ('previously',): Counter({'[': 1}),\n",
       "             ('0711',): Counter({'.': 3}),\n",
       "             ('2058',): Counter({',': 1}),\n",
       "             ('2061',): Counter({',': 1}),\n",
       "             ('2270',): Counter({']': 1}),\n",
       "             ('raised',): Counter({'to': 1}),\n",
       "             ('level',): Counter({'of': 1}),\n",
       "             ('realistic',): Counter({'algorithm': 1}),\n",
       "             ('multilayer',): Counter({'perceptrons': 1, 'perceptron': 1}),\n",
       "             ('perceptrons',): Counter({'and': 1}),\n",
       "             ('dropout',): Counter({';': 1}),\n",
       "             ('type',): Counter({'of': 1}),\n",
       "             ('hidden',): Counter({'layer': 1}),\n",
       "             ('layer',): Counter({'for': 1}),\n",
       "             ('demonstrate',): Counter({'that': 1}),\n",
       "             ('obtains',): Counter({'the': 1}),\n",
       "             ('best',): Counter({'reported': 1}),\n",
       "             ('reported',): Counter({'performance': 1}),\n",
       "             ('performance',): Counter({'for': 1}),\n",
       "             ('mlp',): Counter({'on': 1}),\n",
       "             ('mnist',): Counter({'dataset': 1}),\n",
       "             ('dataset',): Counter({'.': 1}),\n",
       "             ('measuring',): Counter({'prosodic': 1, 'predictive': 1}),\n",
       "             ('prosodic',): Counter({'accommodation': 1}),\n",
       "             ('accommodation',): Counter({';': 1}),\n",
       "             ('submitter',): Counter({'did': 1}),\n",
       "             ('did',): Counter({'not': 1}),\n",
       "             ('legal',): Counter({'authority': 1}),\n",
       "             ('authority',): Counter({'to': 1}),\n",
       "             ('grant',): Counter({'the': 1}),\n",
       "             ('license',): Counter({'applied': 1}),\n",
       "             ('applied',): Counter({'to': 1}),\n",
       "             ('remark',): Counter({'on': 1}),\n",
       "             ('rue',): Counter({'-': 3}),\n",
       "             ('extrue',): Counter({';': 1, '.': 1}),\n",
       "             ('prominent',): Counter({'counterexample': 1}),\n",
       "             ('counterexample',): Counter({'for': 1}),\n",
       "             ('completeness',): Counter({'of': 1}),\n",
       "             ('apply',): Counter({'to': 1}),\n",
       "             ('sat',): Counter({'as': 1, '.': 1}),\n",
       "             ('funny',): Counter({'representation': 1}),\n",
       "             ('while',): Counter({'the': 1}),\n",
       "             ('primary',): Counter({'interest': 1}),\n",
       "             ('interest',): Counter({'is': 1}),\n",
       "             ('propositional',): Counter({'satisfiability': 1}),\n",
       "             ('satisfiability',): Counter({'in': 1}),\n",
       "             ('playful',): Counter({'way': 1}),\n",
       "             ('way',): Counter({'for': 1}),\n",
       "             ('pedagogical',): Counter({'purposes': 1}),\n",
       "             ('purposes',): Counter({',': 1}),\n",
       "             ('could',): Counter({'also': 1}),\n",
       "             ('also',): Counter({'inspire': 1}),\n",
       "             ('inspire',): Counter({'new': 1}),\n",
       "             ('heuristics',): Counter({'.': 1}),\n",
       "             ('adjusting',): Counter({'$': 1}),\n",
       "             ('$',): Counter({'r': 1, 'for': 1}),\n",
       "             ('r',): Counter({'^': 2}),\n",
       "             ('^',): Counter({'2': 2}),\n",
       "             ('cross',): Counter({'-': 2}),\n",
       "             ('validation',): Counter({';': 1, '.': 1}),\n",
       "             ('adjust',): Counter({'the': 1}),\n",
       "             ('coefficient',): Counter({'of': 1}),\n",
       "             ('determination',): Counter({'($': 1}),\n",
       "             ('($',): Counter({'r': 1}),\n",
       "             ('$)',): Counter({'when': 1}),\n",
       "             ('when',): Counter({'used': 1}),\n",
       "             ('predictive',): Counter({'accuracy': 1}),\n",
       "             ('accuracy',): Counter({'via': 1}),\n",
       "             ('leave',): Counter({'-': 1}),\n",
       "             ('approximated',): Counter({'structured': 1, 'large': 1}),\n",
       "             ('structured',): Counter({'prediction': 2}),\n",
       "             ('graphical',): Counter({'models': 1}),\n",
       "             ('manuscripts',): Counter({'contains': 1}),\n",
       "             ('primal',): Counter({'-': 1}),\n",
       "             ('message',): Counter({'-': 1}),\n",
       "             ('passing',): Counter({'algorithm': 1}),\n",
       "             ('\".',): Counter({'_EOS_': 1}),\n",
       "             ('liver',): Counter({'segmentation': 1, 'based': 1, '.': 1}),\n",
       "             ('ct',): Counter({'images': 1}),\n",
       "             ('aim',): Counter({'of': 1}),\n",
       "             ('priori',): Counter({'knowledge': 1}),\n",
       "             ('knowledge',): Counter({'of': 1}),\n",
       "             ('image',): Counter({',': 1}),\n",
       "             ('such',): Counter({'as': 1}),\n",
       "             ('location',): Counter({'and': 1}),\n",
       "             ('shape',): Counter({'of': 1}),\n",
       "             ('existence',): Counter({'of': 3}),\n",
       "             ('projective',): Counter({'reconstruction': 2}),\n",
       "             ('connection',): Counter({'between': 1}),\n",
       "             ('fundamental',): Counter({'matrix': 1}),\n",
       "             ('satisfying',): Counter({'the': 1}),\n",
       "             ('epipolar',): Counter({'constraints': 1}),\n",
       "             ('constraints',): Counter({'.': 1}),\n",
       "             ('solving',): Counter({'traveling': 2}),\n",
       "             ('traveling',): Counter({'salesman': 2}),\n",
       "             ('salesman',): Counter({'problem': 2}),\n",
       "             ('marker',): Counter({'method': 2}),\n",
       "             ('mutation',): Counter({'operator': 1}),\n",
       "             ('operator',): Counter({'that': 1}),\n",
       "             ('selects',): Counter({'the': 1}),\n",
       "             ('nearest',): Counter({'neighbor': 1}),\n",
       "             ('neighbor',): Counter({'among': 1}),\n",
       "             ('among',): Counter({'all': 1}),\n",
       "             ('near',): Counter({'neighbors': 1}),\n",
       "             ('neighbors',): Counter({'solving': 1}),\n",
       "             ('primer',): Counter({'on': 1}),\n",
       "             ('intended',): Counter({'as': 1}),\n",
       "             ('handout',): Counter({'to': 1}),\n",
       "             ('graduate',): Counter({'students': 1}),\n",
       "             ('taking',): Counter({'artificial': 1}),\n",
       "             ('intlligence',): Counter({'or': 1}),\n",
       "             ('classes',): Counter({'.': 1}),\n",
       "             ('agent',): Counter({'models': 1, 'based': 1}),\n",
       "             ('political',): Counter({'interactions': 1}),\n",
       "             ('interactions',): Counter({';': 1, 'from': 1, 'as': 1}),\n",
       "             ('looks',): Counter({'at': 1}),\n",
       "             ('perspective',): Counter({'to': 1}),\n",
       "             ('see',): Counter({'state': 1}),\n",
       "             ('example',): Counter({'of': 1}),\n",
       "             ('emergent',): Counter({'intelligent': 1}),\n",
       "             ('intelligent',): Counter({'behavior': 1}),\n",
       "             ('exposes',): Counter({'basic': 1}),\n",
       "             ('basic',): Counter({'principles': 1}),\n",
       "             ('principles',): Counter({'of': 1}),\n",
       "             ('states',): Counter({'representations': 1}),\n",
       "             ('pomdp',): Counter({';': 1}),\n",
       "             ('deal',): Counter({'with': 1}),\n",
       "             ('only',): Counter({'partial': 1}),\n",
       "             ('observations',): Counter({'are': 1}),\n",
       "             ('available',): Counter({'by': 1}),\n",
       "             ('latent',): Counter({'representation': 1}),\n",
       "             ('space',): Counter({'on': 1}),\n",
       "             ('accurately',): Counter({'learned': 1}),\n",
       "             ('learned',): Counter({'.': 1})})"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_lm.counts_['counts_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {('_UNK_',): 78.0,\n",
       "  ('differential',): 1,\n",
       "  ('contrastive',): 1,\n",
       "  ('divergence',): 1,\n",
       "  (';',): 28.0,\n",
       "  ('this',): 17.0,\n",
       "  ('paper',): 6.0,\n",
       "  ('has',): 1.0,\n",
       "  ('been',): 2.0,\n",
       "  ('retracted',): 1,\n",
       "  ('.',): 19.0,\n",
       "  ('what',): 1,\n",
       "  ('does',): 2,\n",
       "  ('artificial',): 3.0,\n",
       "  ('life',): 2,\n",
       "  ('tell',): 1,\n",
       "  ('us',): 2,\n",
       "  ('about',): 3,\n",
       "  ('death',): 1,\n",
       "  ('?',): 1.0,\n",
       "  ('short',): 3,\n",
       "  ('philosophical',): 2,\n",
       "  ('essay',): 2,\n",
       "  ('p',): 2.0,\n",
       "  ('=',): 1.0,\n",
       "  ('np',): 4.0,\n",
       "  ('we',): 17.0,\n",
       "  ('claim',): 1,\n",
       "  ('to',): 34.0,\n",
       "  ('resolve',): 1,\n",
       "  ('the',): 94.0,\n",
       "  ('=?',): 1,\n",
       "  ('problem',): 3,\n",
       "  ('via',): 3,\n",
       "  ('a',): 63.0,\n",
       "  ('formal',): 3.0,\n",
       "  ('argument',): 1,\n",
       "  ('for',): 36.0,\n",
       "  ('computational',): 1,\n",
       "  ('geometry',): 1,\n",
       "  ('column',): 1,\n",
       "  ('38',): 1,\n",
       "  ('recent',): 2,\n",
       "  ('results',): 5.0,\n",
       "  ('on',): 26.0,\n",
       "  ('curve',): 1,\n",
       "  ('reconstruction',): 3.0,\n",
       "  ('are',): 8.0,\n",
       "  ('described',): 2,\n",
       "  ('weak',): 1,\n",
       "  ('evolvability',): 2,\n",
       "  ('equals',): 1,\n",
       "  ('strong',): 1,\n",
       "  ('an',): 10,\n",
       "  ('updated',): 1,\n",
       "  ('version',): 3.0,\n",
       "  ('will',): 1.0,\n",
       "  ('be',): 7,\n",
       "  ('uploaded',): 1,\n",
       "  ('later',): 1,\n",
       "  ('creating',): 1.0,\n",
       "  ('new',): 7.0,\n",
       "  ('ontology',): 1.0,\n",
       "  (':',): 9.0,\n",
       "  ('modular',): 1.0,\n",
       "  ('approach',): 3,\n",
       "  ('defeasible',): 2,\n",
       "  ('reasoning',): 1,\n",
       "  ('in',): 33.0,\n",
       "  ('oscar',): 2,\n",
       "  ('is',): 20.0,\n",
       "  ('system',): 4.0,\n",
       "  ('description',): 5,\n",
       "  ('reasoner',): 1,\n",
       "  ('essence',): 1.0,\n",
       "  (\"'\",): 6.0,\n",
       "  ('of',): 72.0,\n",
       "  ('language',): 8.0,\n",
       "  ('as',): 5.0,\n",
       "  ('used',): 4,\n",
       "  ('by',): 8.0,\n",
       "  ('tool',): 2,\n",
       "  ('savile',): 1,\n",
       "  ('row',): 1,\n",
       "  ('deep',): 4.0,\n",
       "  ('neural',): 2.0,\n",
       "  ('networks',): 8.0,\n",
       "  ('-',): 26.0,\n",
       "  ('brief',): 1,\n",
       "  ('history',): 3.0,\n",
       "  ('introduction',): 2.0,\n",
       "  ('and',): 46.0,\n",
       "  ('their',): 3,\n",
       "  ('statistical',): 1,\n",
       "  ('physics',): 1,\n",
       "  ('natural',): 1.0,\n",
       "  ('processing',): 2.0,\n",
       "  ('withdrawn',): 4.0,\n",
       "  ('author',): 6.0,\n",
       "  ('complex',): 1.0,\n",
       "  ('special',): 1.0,\n",
       "  ('issue',): 3,\n",
       "  (',',): 36.0,\n",
       "  ('journal',): 1,\n",
       "  ('serious',): 1,\n",
       "  ('flaws',): 1,\n",
       "  ('korf',): 1,\n",
       "  ('et',): 1,\n",
       "  ('al',): 1,\n",
       "  (\".'\",): 1,\n",
       "  ('s',): 3,\n",
       "  ('analysis',): 4.0,\n",
       "  ('time',): 3,\n",
       "  ('complexity',): 1,\n",
       "  ('*',): 1,\n",
       "  ('preprocessing',): 1,\n",
       "  ('step',): 1,\n",
       "  ('automating',): 1,\n",
       "  ('early',): 1,\n",
       "  ('detection',): 2,\n",
       "  ('cervical',): 1,\n",
       "  ('cancer',): 1,\n",
       "  ('liquid',): 1,\n",
       "  ('state',): 3.0,\n",
       "  ('machines',): 2,\n",
       "  ('adbiatic',): 1,\n",
       "  ('quantum',): 3,\n",
       "  ('computers',): 2,\n",
       "  ('general',): 3,\n",
       "  ('computation',): 2,\n",
       "  ('major',): 2,\n",
       "  ('mistakes',): 1,\n",
       "  ('do',): 1,\n",
       "  ('not',): 8.0,\n",
       "  ('read',): 1,\n",
       "  ('mining',): 1.0,\n",
       "  ('trees',): 2.0,\n",
       "  ('graph',): 1.0,\n",
       "  ('complete',): 4,\n",
       "  ('shown',): 2,\n",
       "  ('towards',): 1,\n",
       "  ('hierarchical',): 1,\n",
       "  ('model',): 2.0,\n",
       "  ('consciousness',): 1,\n",
       "  ('intelligence',): 3.0,\n",
       "  ('mind',): 1,\n",
       "  ('body',): 1,\n",
       "  ('article',): 4.0,\n",
       "  ('taken',): 1,\n",
       "  ('out',): 3,\n",
       "  ('notation',): 3.0,\n",
       "  ('markov',): 1.0,\n",
       "  ('decision',): 2.0,\n",
       "  ('processes',): 3,\n",
       "  ('specifies',): 1,\n",
       "  ('icon',): 1.0,\n",
       "  ('challenge',): 3.0,\n",
       "  ('algorithm',): 5.0,\n",
       "  ('selection',): 2,\n",
       "  ('present',): 3,\n",
       "  ('recognition',): 5.0,\n",
       "  ('regular',): 1,\n",
       "  ('shapes',): 1,\n",
       "  ('satelite',): 1,\n",
       "  ('images',): 1.0,\n",
       "  ('ali',): 1.0,\n",
       "  ('pourmohammad',): 1.0,\n",
       "  ('glottochronologic',): 1.0,\n",
       "  ('retrognostic',): 1.0,\n",
       "  ('proposed',): 3,\n",
       "  ('evolution',): 1.0,\n",
       "  ('due',): 1.0,\n",
       "  ('extremely',): 1,\n",
       "  ('unscientific',): 1,\n",
       "  ('errors',): 1.0,\n",
       "  ('utility',): 2,\n",
       "  ('probability',): 4.0,\n",
       "  ('duality',): 2,\n",
       "  ('presents',): 3,\n",
       "  ('between',): 5,\n",
       "  ('distributions',): 1,\n",
       "  ('functions',): 3,\n",
       "  ('temporized',): 1,\n",
       "  ('equilibria',): 1,\n",
       "  ('crucial',): 2,\n",
       "  ('error',): 2.0,\n",
       "  ('submission',): 4,\n",
       "  ('action',): 2,\n",
       "  ('backpropagation',): 1,\n",
       "  ('matrix',): 2.0,\n",
       "  ('note',): 3.0,\n",
       "  ('calculate',): 2.0,\n",
       "  ('gradient',): 1,\n",
       "  ('network',): 6,\n",
       "  ('function',): 2,\n",
       "  ('random',): 1,\n",
       "  ('dfas',): 1,\n",
       "  ('efficiently',): 1,\n",
       "  ('pac',): 1,\n",
       "  ('learnable',): 1,\n",
       "  ('found',): 1,\n",
       "  ('dana',): 1,\n",
       "  ('angluin',): 1,\n",
       "  ('lev',): 1,\n",
       "  ('reyzin',): 1,\n",
       "  ('motifs',): 1,\n",
       "  ('music',): 3,\n",
       "  ('sequences',): 1,\n",
       "  ('because',): 2.0,\n",
       "  ('it',): 5.0,\n",
       "  ('needs',): 1,\n",
       "  ('methodological',): 1,\n",
       "  ('revision',): 2,\n",
       "  ('glottochronology',): 1,\n",
       "  ('problems',): 3,\n",
       "  ('protolanguage',): 1,\n",
       "  ('method',): 5.0,\n",
       "  ('languages',): 4,\n",
       "  ('genealogical',): 1,\n",
       "  ('construction',): 1,\n",
       "  ('using',): 6.0,\n",
       "  ('slp',): 1,\n",
       "  ('persian',): 1,\n",
       "  ('handwritten',): 1,\n",
       "  ('digits',): 1,\n",
       "  ('hopping',): 1,\n",
       "  ('technique',): 2,\n",
       "  ('faster',): 1,\n",
       "  ('reinforcement',): 1,\n",
       "  ('learning',): 11.0,\n",
       "  ('simulations',): 1,\n",
       "  ('preprint',): 1,\n",
       "  ('convolutional',): 1,\n",
       "  ('matching',): 1.0,\n",
       "  ('pursuit',): 1.0,\n",
       "  ('dictionary',): 2,\n",
       "  ('training',): 2,\n",
       "  ('k',): 2.0,\n",
       "  ('svd',): 1,\n",
       "  ('demonstrated',): 1,\n",
       "  ('translation',): 1,\n",
       "  ('invariant',): 1,\n",
       "  ('setting',): 1,\n",
       "  ('fitness',): 1,\n",
       "  ('landscape',): 1,\n",
       "  ('dynamic',): 1,\n",
       "  ('resource',): 1.0,\n",
       "  ('allocation',): 2,\n",
       "  ('multiuser',): 1,\n",
       "  ('ofdm',): 1.0,\n",
       "  ('based',): 5.0,\n",
       "  ('cognitive',): 1.0,\n",
       "  ('radio',): 1.0,\n",
       "  ('systems',): 2,\n",
       "  ('darwiche',): 1.0,\n",
       "  ('pearl',): 2,\n",
       "  ('that',): 8.0,\n",
       "  ('postulates',): 1,\n",
       "  ('imply',): 1,\n",
       "  ('interesting',): 1,\n",
       "  ('property',): 1,\n",
       "  ('noticed',): 1,\n",
       "  ('authors',): 2,\n",
       "  ('flip',): 1,\n",
       "  ('flop',): 1,\n",
       "  ('sublinear',): 1.0,\n",
       "  ('models',): 5,\n",
       "  ('graphs',): 2,\n",
       "  ('proof',): 2,\n",
       "  ('theorem',): 1,\n",
       "  ('1',): 4.0,\n",
       "  ('prove',): 1,\n",
       "  ('there',): 1,\n",
       "  ('no',): 2,\n",
       "  ('class',): 2,\n",
       "  ('dual',): 2,\n",
       "  ('almost',): 1,\n",
       "  ('all',): 3.0,\n",
       "  ('autonomous',): 1,\n",
       "  ('perceptron',): 2,\n",
       "  ('inspired',): 1,\n",
       "  ('from',): 5.0,\n",
       "  ('computing',): 2,\n",
       "  ('abstract',): 1,\n",
       "  ('modified',): 1,\n",
       "  ('after',): 1,\n",
       "  ('correcting',): 1,\n",
       "  ('minor',): 1,\n",
       "  ('eq',): 1,\n",
       "  ('.(',): 1,\n",
       "  ('2',): 4,\n",
       "  (')',): 6.0,\n",
       "  ('sets',): 1.0,\n",
       "  ('measures',): 2,\n",
       "  ('represent',): 1,\n",
       "  ('uncertainty',): 2.0,\n",
       "  ('i',): 2,\n",
       "  ('explore',): 1,\n",
       "  ('use',): 5.0,\n",
       "  ('representation',): 2.0,\n",
       "  ('comment',): 1.0,\n",
       "  ('argumentation',): 2,\n",
       "  ('theory',): 3.0,\n",
       "  ('defaults',): 1,\n",
       "  ('meaning',): 2,\n",
       "  ('[',): 3,\n",
       "  ('gs16',): 1,\n",
       "  (']',): 3,\n",
       "  ('develop',): 2,\n",
       "  ('(',): 7,\n",
       "  ('outline',): 1,\n",
       "  ('activitynet',): 2,\n",
       "  ('2017',): 3.0,\n",
       "  ('summary',): 2,\n",
       "  ('large',): 1.0,\n",
       "  ('scale',): 3,\n",
       "  ('activity',): 1,\n",
       "  ('participants',): 1,\n",
       "  ('papers',): 1,\n",
       "  ('yahoo',): 2,\n",
       "  ('query',): 1.0,\n",
       "  ('treebank',): 1.0,\n",
       "  ('v',): 1,\n",
       "  ('0',): 2,\n",
       "  ('annotation',): 1,\n",
       "  ('guidelines',): 1,\n",
       "  ('webscope',): 1,\n",
       "  ('release',): 1,\n",
       "  ('may',): 3,\n",
       "  ('2016',): 2,\n",
       "  ('under',): 3,\n",
       "  ('derive',): 1,\n",
       "  ('axiomatically',): 1,\n",
       "  ('should',): 1,\n",
       "  ('make',): 1,\n",
       "  ('decisions',): 1,\n",
       "  ('given',): 2,\n",
       "  ('any',): 2,\n",
       "  ('form',): 1,\n",
       "  ('underlying',): 1,\n",
       "  ('text',): 1,\n",
       "  ('tools',): 2,\n",
       "  ('spoken',): 1,\n",
       "  ('contains',): 1.0,\n",
       "  ('postscript',): 1,\n",
       "  ('final',): 1,\n",
       "  ('slides',): 1,\n",
       "  ('our',): 4,\n",
       "  ('acl',): 1,\n",
       "  ('94',): 1,\n",
       "  ('tutorial',): 2,\n",
       "  ('discrimination',): 1,\n",
       "  ('arabic',): 1,\n",
       "  ('latin',): 1,\n",
       "  ('bilingual',): 1,\n",
       "  ('documents',): 1,\n",
       "  ('2011',): 1,\n",
       "  ('international',): 2.0,\n",
       "  ('conference',): 1.0,\n",
       "  ('communications',): 1,\n",
       "  ('control',): 3,\n",
       "  ('applications',): 2,\n",
       "  ('ccca',): 1,\n",
       "  ('machine',): 2.0,\n",
       "  ('framework',): 3.0,\n",
       "  ('design',): 1,\n",
       "  ('manufacturability',): 1,\n",
       "  ('duplicate',): 1,\n",
       "  ('original',): 1,\n",
       "  ('arxiv',): 2.0,\n",
       "  ('1612',): 1,\n",
       "  ('02141',): 1,\n",
       "  (').',): 1,\n",
       "  ('hence',): 1,\n",
       "  ('want',): 1,\n",
       "  ('withdraw',): 1,\n",
       "  ('experiment',): 3,\n",
       "  ('aims',): 1,\n",
       "  ('at',): 3,\n",
       "  ('clarifying',): 1,\n",
       "  ('practice',): 1,\n",
       "  ('scientific',): 1,\n",
       "  ('mainly',): 2,\n",
       "  ('hooking',): 1,\n",
       "  ('observability',): 1,\n",
       "  ('calculability',): 1,\n",
       "  ('minds',): 2,\n",
       "  ('computable',): 1,\n",
       "  ('explores',): 1,\n",
       "  ('limits',): 2,\n",
       "  ('turing',): 1,\n",
       "  ('concerning',): 1,\n",
       "  ('modeling',): 1,\n",
       "  ('suggests',): 1,\n",
       "  ('alternatives',): 1,\n",
       "  ('go',): 1,\n",
       "  ('beyond',): 2,\n",
       "  ('those',): 1,\n",
       "  ('extraction',): 1,\n",
       "  ('de',): 2,\n",
       "  ('concepts',): 2,\n",
       "  ('sous',): 1,\n",
       "  ('contraintes',): 1,\n",
       "  ('dans',): 1,\n",
       "  ('des',): 1,\n",
       "  ('donnes',): 1,\n",
       "  ('d',): 1,\n",
       "  ('expression',): 1,\n",
       "  ('gnes',): 1,\n",
       "  ('propose',): 2.0,\n",
       "  ('extract',): 1,\n",
       "  ('constrained',): 2,\n",
       "  ('comments',): 1.0,\n",
       "  ('\"',): 6.0,\n",
       "  ('combination',): 1.0,\n",
       "  ('evidence',): 1.0,\n",
       "  ('compromise',): 2,\n",
       "  ('yamada',): 2,\n",
       "  ('``',): 1,\n",
       "  (\"''\",): 1,\n",
       "  ('low',): 1,\n",
       "  ('shot',): 2,\n",
       "  ('facial',): 1,\n",
       "  ('representations',): 2,\n",
       "  ('2d',): 1.0,\n",
       "  ('warping',): 2,\n",
       "  ('work',): 3,\n",
       "  ('study',): 2.0,\n",
       "  ('influence',): 1,\n",
       "  ('module',): 1,\n",
       "  ('one',): 1.0,\n",
       "  ('face',): 2,\n",
       "  ('automatic',): 3,\n",
       "  ('generation',): 1,\n",
       "  ('benchmarks',): 1,\n",
       "  ('plagiarism',): 1,\n",
       "  ('grammatical',): 1,\n",
       "  ('rewriting',): 1,\n",
       "  ('mu',): 1,\n",
       "  ('partial',): 2,\n",
       "  ('channel',): 1,\n",
       "  ('information',): 3,\n",
       "  ('some',): 4.0,\n",
       "  ('advances',): 1.0,\n",
       "  ('require',): 1.0,\n",
       "  ('progress',): 1.0,\n",
       "  ('across',): 1.0,\n",
       "  ('computer',): 4.0,\n",
       "  ('science',): 3,\n",
       "  ('exploration',): 1,\n",
       "  ('object',): 2.0,\n",
       "  ('3d',): 1.0,\n",
       "  ('point',): 1.0,\n",
       "  ('cloud',): 2,\n",
       "  ('latest',): 1,\n",
       "  ('data',): 4,\n",
       "  ('collected',): 1,\n",
       "  ('through',): 1,\n",
       "  ('moving',): 1,\n",
       "  ('car',): 2.0,\n",
       "  ('quantified',): 1.0,\n",
       "  ('conditional',): 2,\n",
       "  ('logics',): 1,\n",
       "  ('fragments',): 1,\n",
       "  ('hol',): 1,\n",
       "  ('semantic',): 2.0,\n",
       "  ('embedding',): 1,\n",
       "  ('constant',): 1,\n",
       "  ('domain',): 1,\n",
       "  ('logic',): 5.0,\n",
       "  ('classical',): 1,\n",
       "  ('higher',): 2.0,\n",
       "  ('order',): 2.0,\n",
       "  ('presented',): 2,\n",
       "  ('memoriam',): 1,\n",
       "  ('maurice',): 1.0,\n",
       "  ('gross',): 2,\n",
       "  ('1934',): 1,\n",
       "  ('2001',): 1,\n",
       "  ('was',): 2,\n",
       "  ('both',): 1,\n",
       "  ('great',): 1,\n",
       "  ('linguist',): 1,\n",
       "  ('pioneer',): 1,\n",
       "  ('written',): 1,\n",
       "  ('homage',): 1,\n",
       "  ('his',): 1,\n",
       "  ('memory',): 1,\n",
       "  ('26th',): 1.0,\n",
       "  ('programming',): 8.0,\n",
       "  ('preface',): 1,\n",
       "  ('approaching',): 1.0,\n",
       "  ('human',): 2.0,\n",
       "  ('with',): 9.0,\n",
       "  ('cong',): 1.0,\n",
       "  ('&',): 1.0,\n",
       "  ('liu',): 2,\n",
       "  ('norm',): 1.0,\n",
       "  ('capacity',): 2,\n",
       "  ('investigate',): 1.0,\n",
       "  ('convexity',): 1,\n",
       "  ('characterization',): 1,\n",
       "  ('family',): 1,\n",
       "  ('feed',): 1,\n",
       "  ('forward',): 1,\n",
       "  ('compression',): 1,\n",
       "  ('vocabulary',): 1,\n",
       "  ('oriented',): 1.0,\n",
       "  ('uses',): 1,\n",
       "  ('entropy',): 2.0,\n",
       "  ('ideal',): 1,\n",
       "  ('bose',): 1,\n",
       "  ('einstein',): 1,\n",
       "  ('gas',): 1,\n",
       "  ('minimize',): 1,\n",
       "  ('losses',): 1,\n",
       "  ('unary',): 1.0,\n",
       "  ('coding',): 2,\n",
       "  ('properties',): 1.0,\n",
       "  ('significance',): 1,\n",
       "  ('biological',): 1,\n",
       "  ('instantaneously',): 1,\n",
       "  ('trained',): 1,\n",
       "  ('ukrainian',): 3,\n",
       "  ('writing',): 1,\n",
       "  ('grapheme',): 1,\n",
       "  ('phoneme',): 1,\n",
       "  ('relation',): 1,\n",
       "  ('cyrillic',): 1,\n",
       "  ('alphabet',): 1,\n",
       "  ('convex',): 2,\n",
       "  ('multiview',): 1,\n",
       "  ('fisher',): 1,\n",
       "  ('discriminant',): 1,\n",
       "  ('section',): 1,\n",
       "  ('3',): 1,\n",
       "  ('incorrect',): 1,\n",
       "  ('removed',): 1,\n",
       "  ('further',): 1,\n",
       "  ('submissions',): 1,\n",
       "  ('rewritten',): 1,\n",
       "  ('posted',): 2,\n",
       "  ('future',): 2.0,\n",
       "  ('why',): 2.0,\n",
       "  ('bother',): 1,\n",
       "  ('syntax',): 3,\n",
       "  ('discusses',): 1,\n",
       "  ('role',): 1,\n",
       "  ('vs',): 1,\n",
       "  ('semantics',): 2.0,\n",
       "  ('interplay',): 1,\n",
       "  ('philosophy',): 2,\n",
       "  ('game',): 2.0,\n",
       "  ('gsa',): 1.0,\n",
       "  ('gravitational',): 1.0,\n",
       "  ('search',): 2.0,\n",
       "  ('genuinely',): 1.0,\n",
       "  ('law',): 1.0,\n",
       "  ('gravity',): 2,\n",
       "  ('neurocontrol',): 1,\n",
       "  ('methods',): 4,\n",
       "  ('review',): 2,\n",
       "  ('applying',): 1,\n",
       "  ('plants',): 1,\n",
       "  ('considered',): 1,\n",
       "  ('schemes',): 1,\n",
       "  ('advantages',): 1,\n",
       "  ('disadvantages',): 1,\n",
       "  ('discussed',): 1.0,\n",
       "  ('universality',): 1,\n",
       "  ('online',): 2,\n",
       "  ('mirror',): 1.0,\n",
       "  ('descent',): 2,\n",
       "  ('show',): 3.0,\n",
       "  ('can',): 1,\n",
       "  ('always',): 1,\n",
       "  ('achieve',): 1,\n",
       "  ('nearly',): 1,\n",
       "  ('optimal',): 1,\n",
       "  ('regret',): 2,\n",
       "  ('guarantee',): 1,\n",
       "  ('possibility',): 1,\n",
       "  ('making',): 1,\n",
       "  ('brain',): 1,\n",
       "  ('development',): 1,\n",
       "  ('building',): 1,\n",
       "  ('corresponding',): 2,\n",
       "  ('parts',): 1,\n",
       "  ('dna',): 1,\n",
       "  ('code',): 1,\n",
       "  ('discuss',): 1,\n",
       "  ('how',): 3.0,\n",
       "  ('ai',): 3,\n",
       "  ('community',): 1,\n",
       "  ('views',): 1,\n",
       "  ('concerns',): 1,\n",
       "  ('emergence',): 1,\n",
       "  ('superintelligent',): 1,\n",
       "  ('related',): 1,\n",
       "  ('issues',): 1,\n",
       "  ('survey',): 3,\n",
       "  ('contextual',): 2,\n",
       "  ('multi',): 1,\n",
       "  ('armed',): 1,\n",
       "  ('bandits',): 1,\n",
       "  ('cover',): 1,\n",
       "  ('few',): 1,\n",
       "  ('stochastic',): 1,\n",
       "  ('adversarial',): 2,\n",
       "  ('bandit',): 1,\n",
       "  ('algorithms',): 2,\n",
       "  ('analyze',): 2,\n",
       "  ('each',): 1,\n",
       "  ('assumption',): 1,\n",
       "  ('bound',): 1,\n",
       "  ('parallels',): 1,\n",
       "  ('behavior',): 2,\n",
       "  ('bottlenose',): 1,\n",
       "  ('dolphins',): 2,\n",
       "  ('similarities',): 1,\n",
       "  ('humans',): 1,\n",
       "  ('help',): 1,\n",
       "  ('quantitative',): 1,\n",
       "  ('linguistics',): 1,\n",
       "  ('metaheuristics',): 2,\n",
       "  ('chapter',): 1,\n",
       "  ('describes',): 2,\n",
       "  ('five',): 1,\n",
       "  ('distinct',): 1,\n",
       "  ('periods',): 1,\n",
       "  ('starting',): 1,\n",
       "  ('long',): 3,\n",
       "  ('before',): 1,\n",
       "  ('first',): 3.0,\n",
       "  ('term',): 1,\n",
       "  ('ending',): 1,\n",
       "  ('energy',): 1,\n",
       "  ('efficient',): 2,\n",
       "  ('scheme',): 1,\n",
       "  ('gathering',): 1,\n",
       "  ('wireless',): 1,\n",
       "  ('sensor',): 1,\n",
       "  ('particle',): 1,\n",
       "  ('swarm',): 1,\n",
       "  ('optimization',): 2.0,\n",
       "  ('sign',): 1,\n",
       "  ('equation',): 1,\n",
       "  ('bengali',): 2,\n",
       "  ('readability',): 2,\n",
       "  ('score',): 1,\n",
       "  ('have',): 3,\n",
       "  ('texts',): 2.0,\n",
       "  ('got',): 1,\n",
       "  ('exceptionally',): 1,\n",
       "  ('good',): 1,\n",
       "  ('experiments',): 1,\n",
       "  ('paradigm',): 1,\n",
       "  ('prolog',): 2,\n",
       "  ('appropriate',): 1,\n",
       "  ('course',): 1,\n",
       "  ('students',): 2,\n",
       "  ('familiar',): 1,\n",
       "  ('imperative',): 1,\n",
       "  ('distance',): 3.0,\n",
       "  ('area',): 2,\n",
       "  ('where',): 2,\n",
       "  ('video',): 2,\n",
       "  ('cameras',): 1,\n",
       "  ('installed',): 1,\n",
       "  ('its',): 2,\n",
       "  ('movement',): 1,\n",
       "  ('group',): 3,\n",
       "  ('actions',): 1,\n",
       "  ('evolutionary',): 2,\n",
       "  ('global',): 1,\n",
       "  ('orbit',): 1,\n",
       "  ('understand',): 1,\n",
       "  ('solve',): 1,\n",
       "  ('nonconvex',): 1,\n",
       "  ('telugu',): 2,\n",
       "  ('investigation',): 1,\n",
       "  ('script',): 2,\n",
       "  ('since',): 1,\n",
       "  ('syllabic',): 1,\n",
       "  ('alphabetic',): 1,\n",
       "  ('somewhat',): 1,\n",
       "  ('complicated',): 1,\n",
       "  ('word',): 1.0,\n",
       "  ('segmentation',): 3.0,\n",
       "  ('micro',): 1.0,\n",
       "  ('blog',): 1.0,\n",
       "  ('external',): 1,\n",
       "  ('lexicon',): 1,\n",
       "  ('heterogeneous',): 1,\n",
       "  ('designed',): 1,\n",
       "  ('nlpcc',): 1,\n",
       "  ('shared',): 1,\n",
       "  ('task',): 1,\n",
       "  ('guarded',): 1,\n",
       "  ('resolution',): 5,\n",
       "  ('answer',): 1.0,\n",
       "  ('set',): 1.0,\n",
       "  ('describe',): 1,\n",
       "  ('variant',): 1,\n",
       "  ('rule',): 1,\n",
       "  ('stable',): 1,\n",
       "  ('programs',): 1,\n",
       "  ('result',): 1,\n",
       "  ('cornell',): 2.0,\n",
       "  ('spf',): 2,\n",
       "  ('parsing',): 1.0,\n",
       "  ('inference',): 1,\n",
       "  ('mapping',): 1,\n",
       "  ('semistability',): 1,\n",
       "  ('convergence',): 1,\n",
       "  ('paracontracting',): 1,\n",
       "  ('multiagent',): 1,\n",
       "  ('coordination',): 1,\n",
       "  ('sequential',): 2,\n",
       "  ('technical',): 1.0,\n",
       "  ('report',): 2,\n",
       "  ('extends',): 1,\n",
       "  ('previous',): 1,\n",
       "  ('1306',): 1,\n",
       "  ('0225',): 1,\n",
       "  ('proceedings',): 1.0,\n",
       "  ('workshop',): 1.0,\n",
       "  ('joint',): 1,\n",
       "  ('ijcnn',): 1,\n",
       "  ('anchorage',): 1,\n",
       "  ('17',): 1,\n",
       "  ('18',): 1,\n",
       "  ('attack',): 1,\n",
       "  ('rmse',): 2,\n",
       "  ('leaderboard',): 1,\n",
       "  ('case',): 1,\n",
       "  ('manuscript',): 1,\n",
       "  ('briefly',): 1,\n",
       "  ('introduce',): 1,\n",
       "  ('several',): 1,\n",
       "  ('tricks',): 1,\n",
       "  ('climb',): 1,\n",
       "  ('leaderboards',): 1,\n",
       "  ('which',): 3,\n",
       "  ('evaluation',): 1,\n",
       "  ('without',): 1,\n",
       "  ('exploiting',): 1,\n",
       "  ('standardization',): 1,\n",
       "  ('lexical',): 1,\n",
       "  ('nlp',): 1,\n",
       "  ('formats',): 1,\n",
       "  ('well',): 1,\n",
       "  ('presentation',): 1,\n",
       "  ('standardisation',): 1,\n",
       "  ('activities',): 1,\n",
       "  ('stock',): 2.0,\n",
       "  ('market',): 1.0,\n",
       "  ('prediction',): 4,\n",
       "  ('act',): 1,\n",
       "  ('trying',): 1,\n",
       "  ('determine',): 1,\n",
       "  ('value',): 1,\n",
       "  ('company',): 1,\n",
       "  ('or',): 2,\n",
       "  ('other',): 1,\n",
       "  ('financial',): 2,\n",
       "  ('instrument',): 1,\n",
       "  ('traded',): 1,\n",
       "  ('exchange',): 1,\n",
       "  ('defensive',): 1.0,\n",
       "  ('distillation',): 1.0,\n",
       "  ('robust',): 1,\n",
       "  ('examples',): 1,\n",
       "  ('secure',): 1,\n",
       "  ('more',): 2,\n",
       "  ('resistant',): 1,\n",
       "  ('targeted',): 1,\n",
       "  ('misclassification',): 1,\n",
       "  ('attacks',): 1,\n",
       "  ('than',): 1,\n",
       "  ('unprotected',): 1,\n",
       "  ('nips',): 1.0,\n",
       "  ('symposium',): 1.0,\n",
       "  ('interpretable',): 1.0,\n",
       "  ('held',): 1,\n",
       "  ('beach',): 1,\n",
       "  ('california',): 1,\n",
       "  ('usa',): 1,\n",
       "  ('december',): 1,\n",
       "  ('7',): 1,\n",
       "  ('piecewise',): 1.0,\n",
       "  ('linear',): 2,\n",
       "  ('activation',): 1,\n",
       "  ('administrators',): 1.0,\n",
       "  ('intentionally',): 1,\n",
       "  ('incomplete',): 1,\n",
       "  ('violation',): 1,\n",
       "  ('policies',): 2,\n",
       "  ('triangle',): 1.0,\n",
       "  ('inequality',): 1.0,\n",
       "  ('jaccard',): 1.0,\n",
       "  ('two',): 1,\n",
       "  ('simple',): 1,\n",
       "  ('proofs',): 2,\n",
       "  ('terms',): 1,\n",
       "  ('nonnegative',): 1,\n",
       "  ('monotone',): 1,\n",
       "  ('submodular',): 1,\n",
       "  ('realize',): 1,\n",
       "  ('sense',): 1.0,\n",
       "  ('humour',): 1.0,\n",
       "  ('suggested',): 1,\n",
       "  ('previously',): 1,\n",
       "  ('0711',): 1.0,\n",
       "  ('2058',): 1,\n",
       "  ('2061',): 1,\n",
       "  ('2270',): 1,\n",
       "  ('raised',): 1,\n",
       "  ('level',): 1,\n",
       "  ('realistic',): 1,\n",
       "  ('multilayer',): 2,\n",
       "  ('perceptrons',): 1,\n",
       "  ('dropout',): 1,\n",
       "  ('type',): 1,\n",
       "  ('hidden',): 1,\n",
       "  ('layer',): 1,\n",
       "  ('demonstrate',): 1,\n",
       "  ('obtains',): 1,\n",
       "  ('best',): 1,\n",
       "  ('reported',): 1,\n",
       "  ('performance',): 1,\n",
       "  ('mlp',): 1,\n",
       "  ('mnist',): 1,\n",
       "  ('dataset',): 1,\n",
       "  ('measuring',): 2,\n",
       "  ('prosodic',): 1,\n",
       "  ('accommodation',): 1,\n",
       "  ('submitter',): 1,\n",
       "  ('did',): 1,\n",
       "  ('legal',): 1,\n",
       "  ('authority',): 1,\n",
       "  ('grant',): 1,\n",
       "  ('license',): 1,\n",
       "  ('applied',): 1,\n",
       "  ('remark',): 1,\n",
       "  ('rue',): 1.0,\n",
       "  ('extrue',): 2,\n",
       "  ('prominent',): 1,\n",
       "  ('counterexample',): 1,\n",
       "  ('completeness',): 1,\n",
       "  ('apply',): 1,\n",
       "  ('sat',): 2,\n",
       "  ('funny',): 1,\n",
       "  ('while',): 1,\n",
       "  ('primary',): 1,\n",
       "  ('interest',): 1,\n",
       "  ('propositional',): 1,\n",
       "  ('satisfiability',): 1,\n",
       "  ('playful',): 1,\n",
       "  ('way',): 1,\n",
       "  ('pedagogical',): 1,\n",
       "  ('purposes',): 1,\n",
       "  ('could',): 1,\n",
       "  ('also',): 1,\n",
       "  ('inspire',): 1,\n",
       "  ('heuristics',): 1,\n",
       "  ('adjusting',): 1,\n",
       "  ('$',): 2,\n",
       "  ('r',): 1.0,\n",
       "  ('^',): 1.0,\n",
       "  ('cross',): 1.0,\n",
       "  ('validation',): 2,\n",
       "  ('adjust',): 1,\n",
       "  ('coefficient',): 1,\n",
       "  ('determination',): 1,\n",
       "  ('($',): 1,\n",
       "  ('$)',): 1,\n",
       "  ('when',): 1,\n",
       "  ('predictive',): 1,\n",
       "  ('accuracy',): 1,\n",
       "  ('leave',): 1,\n",
       "  ('approximated',): 2,\n",
       "  ('structured',): 1.0,\n",
       "  ('graphical',): 1,\n",
       "  ('manuscripts',): 1,\n",
       "  ('primal',): 1,\n",
       "  ('message',): 1,\n",
       "  ('passing',): 1,\n",
       "  ('\".',): 1,\n",
       "  ('liver',): 3,\n",
       "  ('ct',): 1,\n",
       "  ('aim',): 1,\n",
       "  ('priori',): 1,\n",
       "  ('knowledge',): 1,\n",
       "  ('image',): 1,\n",
       "  ('such',): 1,\n",
       "  ('location',): 1,\n",
       "  ('shape',): 1,\n",
       "  ('existence',): 1.0,\n",
       "  ('projective',): 1.0,\n",
       "  ('connection',): 1,\n",
       "  ('fundamental',): 1,\n",
       "  ('satisfying',): 1,\n",
       "  ('epipolar',): 1,\n",
       "  ('constraints',): 1,\n",
       "  ('solving',): 1.0,\n",
       "  ('traveling',): 1.0,\n",
       "  ('salesman',): 1.0,\n",
       "  ('marker',): 1.0,\n",
       "  ('mutation',): 1,\n",
       "  ('operator',): 1,\n",
       "  ('selects',): 1,\n",
       "  ('nearest',): 1,\n",
       "  ('neighbor',): 1,\n",
       "  ('among',): 1,\n",
       "  ('near',): 1,\n",
       "  ('neighbors',): 1,\n",
       "  ('primer',): 1,\n",
       "  ('intended',): 1,\n",
       "  ('handout',): 1,\n",
       "  ('graduate',): 1,\n",
       "  ('taking',): 1,\n",
       "  ('intlligence',): 1,\n",
       "  ('classes',): 1,\n",
       "  ('agent',): 2,\n",
       "  ('political',): 1,\n",
       "  ('interactions',): 3,\n",
       "  ('looks',): 1,\n",
       "  ('perspective',): 1,\n",
       "  ('see',): 1,\n",
       "  ('example',): 1,\n",
       "  ('emergent',): 1,\n",
       "  ('intelligent',): 1,\n",
       "  ('exposes',): 1,\n",
       "  ('basic',): 1,\n",
       "  ('principles',): 1,\n",
       "  ('states',): 1,\n",
       "  ('pomdp',): 1,\n",
       "  ('deal',): 1,\n",
       "  ('only',): 1,\n",
       "  ('observations',): 1,\n",
       "  ('available',): 1,\n",
       "  ('latent',): 1,\n",
       "  ('space',): 1,\n",
       "  ('accurately',): 1,\n",
       "  ('learned',): 1}}"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_lm.lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([line.split(' ')[0] for line in dummy_lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dummy_lm.prob_kn_[2][('_UNK_',)].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_lm = KneserNeyLanguageModel(dummy_lines, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "I told you not to break anything! :)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-436-9c30506bb8dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdummy_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKneserNeyLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_token_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_token_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I told you not to break anything! :)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: I told you not to break anything! :)"
     ]
    }
   ],
   "source": [
    "dummy_lm = KneserNeyLanguageModel(dummy_lines, n=2)\n",
    "print(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]))\n",
    "assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "cellId": "lsk91832qbmdt7x1q0a8z4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999999999999\n",
      "19.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "I told you not to break anything! :)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-459-47ec452971db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdummy_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKneserNeyLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_token_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_token_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I told you not to break anything! :)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: I told you not to break anything! :)"
     ]
    }
   ],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = KneserNeyLanguageModel(dummy_lines, n=n)\n",
    "    print(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]))\n",
    "    assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "cellId": "pp3jtkk9annp1qkou58x1b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-264-91263a57f5af>:21: RuntimeWarning: divide by zero encountered in log\n",
      "  log_line_perplexity += max(np.log(lm.get_next_token_prob(prefix=' '.join(tokens[:i]), next_token=tokens[i])), min_logprob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 1832.23136\n",
      "N = 2, Perplexity = 85653987.28543\n",
      "N = 3, Perplexity = 61999196239911532363776.00000\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = KneserNeyLanguageModel(train_lines, n=n, smoothing=<...>)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sudoku382",
   "language": "python",
   "name": "sudoku382"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "notebookId": "53997d2d-afb8-4477-8874-b6d46299f06c",
  "notebookPath": "seminar.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "d0587c7178d23fdc1e13efa6acd505f6da0d8713690c90cf011b327ffb8b049b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
