{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework: going neural (6 pts)\n",
    "\n",
    "We've checked out statistical approaches to language models in the last notebook. Now let's go find out what deep learning has to offer.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/expanding_mind_lm_kn_3.png' width=300px>\n",
    "\n",
    "We're gonna use the same dataset as before, except this time we build a language model that's character-level, not word level. Before you go:\n",
    "* If you haven't done seminar already, use `seminar.ipynb` to download the data.\n",
    "* This homework uses TensorFlow v2.0: this is [how you install it](https://www.tensorflow.org/beta); and that's [how you use it](https://colab.research.google.com/drive/1YtfbZGgzKr7fpBTqkdEQtu4vUALoTv8A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on character level means that we don't need to deal with large vocabulary or missing words. Heck, we can even keep uppercase words in text! The downside, however, is that all our sequences just got a lot longer.\n",
    "\n",
    "However, we still need special tokens:\n",
    "* Begin Of Sequence  (__BOS__) - this token is at the start of each sequence. We use it so that we always have non-empty input to our neural network. $P(x_t) = P(x_1 | BOS)$\n",
    "* End Of Sequence (__EOS__) - you guess it... this token is at the end of each sequence. The catch is that it should __not__ occur anywhere else except at the very end. If our model produces this token, the sequence is over.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS, EOS = ' ', '\\n'\n",
    "\n",
    "data = pd.read_json(\"./resource/arxivData.json\")\n",
    "lines = data.apply(lambda row: (row['title'] + ' ; ' + row['summary'])[:512], axis=1) \\\n",
    "            .apply(lambda line: BOS + line.replace(EOS, ' ') + EOS) \\\n",
    "            .tolist()\n",
    "\n",
    "# if you missed the seminar, download data here - https://yadi.sk/d/_nGyU2IajjR9-w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is __building char-level vocabulary__. Put simply, you need to assemble a list of all unique tokens in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41000\n",
      "[' Dual Recurrent Attention Units for Visual Question Answering ; We propose an architecture for VQA which utilizes recurrent layers to generate visual and textual attention. The memory characteristic of the proposed recurrent attention units offers a rich joint embedding of visual and textual features and enables the model to reason relations between several parts of the image and question. Our single model outperforms the first place winner on the VQA 1.0 dataset, performs within margin to the current state-\\n', ' Sequential Short-Text Classification with Recurrent and Convolutional   Neural Networks ; Recent approaches based on artificial neural networks (ANNs) have shown promising results for short-text classification. However, many short texts occur in sequences (e.g., sentences in a document or utterances in a dialog), and most existing ANN-based systems do not leverage the preceding short texts when classifying a subsequent one. In this work, we present a model based on recurrent neural networks and convolutiona\\n']\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))\n",
    "print(lines[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  136\n"
     ]
    }
   ],
   "source": [
    "# get all unique characters from lines (including capital letters and symbols)\n",
    "tokens = set()\n",
    "for line in lines:\n",
    "    tokens.update(line)\n",
    "tokens = sorted(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "assert 100 < n_tokens < 150\n",
    "assert BOS in tokens, EOS in tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assign each character with it's index in tokens list. This way we can encode a string into a TF-friendly integer vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of character -> its identifier (index in tokens list)\n",
    "token_to_id = { token:i for i,token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final step is to assemble several strings in a integet matrix `[batch_size, text_length]`. \n",
    "\n",
    "The only problem is that each sequence has a different length. We can work around that by padding short sequences with extra _EOS_ or cropping long sequences. Here's how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(lines, max_len=None, pad=token_to_id[EOS], dtype='int32'):\n",
    "    \"\"\"Casts a list of lines into tf-digestable matrix\"\"\"\n",
    "    max_len = max_len or max(map(len, lines))\n",
    "    lines_ix = np.full([len(lines), max_len], pad, dtype=dtype)\n",
    "#     print(lines_ix)\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.get, lines[i][:max_len]))\n",
    "        lines_ix[i, :len(line_ix)] = line_ix\n",
    "    return lines_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 66 67 68  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 66 68 66 67 66  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 68 18 19 20 21 22 23 24 25 26 17  0]]\n"
     ]
    }
   ],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "dummy_lines = [\n",
    "    ' abc\\n',\n",
    "    ' abacaba\\n',\n",
    "    ' abc1234567890\\n',\n",
    "]\n",
    "print(to_matrix(dummy_lines))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Language Model (2 points including training)\n",
    "\n",
    "Just like for N-gram LMs, we want to estimate probability of text as a joint probability of tokens (symbols this time).\n",
    "\n",
    "$$P(X) = \\prod_t P(x_t \\mid x_0, \\dots, x_{t-1}).$$ \n",
    "\n",
    "Instead of counting all possible statistics, we want to train a neural network with parameters $\\theta$ that estimates the conditional probabilities:\n",
    "\n",
    "$$ P(x_t \\mid x_0, \\dots, x_{t-1}) \\approx p(x_t \\mid x_0, \\dots, x_{t-1}, \\theta) $$\n",
    "\n",
    "\n",
    "But before we optimize, we need to define our neural network. Let's start with a fixed-window (aka convolutional) architecture:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/fixed_window_lm.jpg' width=400px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "keras, L = tf.keras, tf.keras.layers\n",
    "assert tf.__version__.startswith('2'), \"Current tf version: {}; required: 2.0.*\".format(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_ix, n_tokens=n_tokens, emb_size=16, hid_size=64):\n",
    "\n",
    "    filter_size, strides = 5,1\n",
    "    \n",
    "    input_ = layers.Input(shape=[None], name='input')\n",
    "    emb1 = layers.Embedding(n_tokens, emb_size, name='emb1')(input_)\n",
    "    pad1= layers.ZeroPadding1D(padding=(strides*(filter_size-1),0), name='pad1')(emb1)\n",
    "    conv1 = layers.Conv1D(filters=16, kernel_size=filter_size, strides=strides,\n",
    "                          activation='relu',padding='valid',name='conv1')(pad1)\n",
    "\n",
    "    dense1 = layers.Dense(units=64, activation='relu')\n",
    "    dense2 = layers.Dense(units=32, activation='relu')\n",
    "    dense3 = layers.Dense(units=16, activation='relu')\n",
    "    output_ = layers.Dense(units=n_tokens)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_], outputs=[output_])\n",
    "    model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedWindowLanguageModel2(tf.keras.Model):\n",
    "    def __init__(self, n_tokens=n_tokens, emb_size=16, hid_size=64):\n",
    "        \"\"\" \n",
    "        A fixed window model that looks on at least 5 previous symbols.\n",
    "        \n",
    "        Note: fixed window LM is effectively performing a convolution over a sequence of words.\n",
    "        This convolution only looks on current and previous words.\n",
    "        Such convolution can be represented as a sequence of 2 operations:\n",
    "        - pad input vectors by {strides * (filter_size - 1)} zero vectors on the \"left\", do not pad right\n",
    "        - perform regular convolution with {filter_size} and {strides}\n",
    "        - If you're absolutely lost, here's a hint: use ZeroPadding1D and Conv1D from keras.layers\n",
    "        You can stack several convolutions at once\n",
    "        \"\"\"\n",
    "        super().__init__() # initialize base class to track sub-layers, trainable variables, etc.\n",
    "        \n",
    "        #YOUR CODE - create layers/variables and any metadata you want, e.g. self.emb = L.Embedding(...)\n",
    "        \n",
    "        filter_size, strides = 5,1\n",
    "        self.emb = L.Embedding(n_tokens, emb_size) # batch*input -> batch*input*16\n",
    "        self.pad1 = L.ZeroPadding1D(padding=(strides*(filter_size-1),0)) #batch*input -> batch*{input+strides*(filter_size-1)}*16\n",
    "        self.conv1 = L.Conv1D(filters=16, kernel_size=filter_size, strides=strides, activation='relu',padding='valid') #batch*{input+strides*(filter_size-1)}*16\n",
    "        \n",
    "        self.dense1 = L.Dense(units=64, activation='relu') #batch*{input+strides*(filter_size-1)}*64\n",
    "        self.dense2 = L.Dense(units=32, activation='relu') #batch*{input+strides*(filter_size-1)}*32\n",
    "        self.dense3 = L.Dense(units=16, activation='relu') ##batch*{input+strides*(filter_size-1)}*16\n",
    "        self.output_layer = L.Dense(units=n_tokens) #batch*{input+strides*(filter_size-1)}*n_tokens\n",
    "        \n",
    "        #END OF YOUR CODE\n",
    "    \n",
    "    def __call__(self, input_ix):\n",
    "        \"\"\"\n",
    "        compute language model logits given input tokens\n",
    "        :param input_ix: batch of sequences with token indices, tf tensor: int32[batch_size, sequence_length]\n",
    "        :returns: pre-softmax linear outputs of language model [batch_size, sequence_length, n_tokens]\n",
    "            these outputs will be used as logits to compute P(x_t | x_0, ..., x_{t - 1})\n",
    "        \"\"\"\n",
    "        # YOUR CODE - apply layers, see docstring above\n",
    "        input_ = tf.Variable(input_ix)\n",
    "        emb = self.emb(input_)\n",
    "        pad1 = self.pad1(emb)\n",
    "        conv1 = self.conv1(pad1)\n",
    "        dense1 = self.dense1(conv1)\n",
    "        dense2 = self.dense2(dense1)\n",
    "        dense3 = self.dense3(dense2)\n",
    "        output = self.output_layer(dense3)\n",
    "\n",
    "#         print(output.shape)\n",
    "        return output\n",
    "    \n",
    "    def get_possible_next_tokens(self, prefix=BOS, temperature=1.0, max_len=100):\n",
    "        \"\"\" :returns: probabilities of next token, dict {token : prob} for all tokens \"\"\"\n",
    "        prefix_ix = tf.convert_to_tensor(to_matrix([prefix]), tf.int32)\n",
    "        probs = tf.nn.softmax(self(prefix_ix)[0, -1]).numpy()  # shape: [n_tokens]\n",
    "        return dict(zip(tokens, probs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.FixedWindowLanguageModel2 at 0x293642ec0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = FixedWindowLanguageModel2()\n",
    "\n",
    "dummy_input_ix = tf.constant(to_matrix(dummy_lines))\n",
    "dummy_logits = model2(dummy_input_ix)\n",
    "\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 15])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_input_ix_ = tf.reshape(dummy_input_ix,[1,3,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_logits = model2(dummy_input_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[182], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/basicenv/lib/python3.10/site-packages/keras/src/engine/training.py:3403\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[1;32m   3372\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[1;32m   3373\u001b[0m \n\u001b[1;32m   3374\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3400\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[1;32m   3401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m-> 3403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3404\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3405\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3407\u001b[0m     )\n\u001b[1;32m   3408\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[1;32m   3409\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3410\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3415\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[1;32m   3416\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedWindowLanguageModel(L.Layer):\n",
    "    def __init__(self, n_tokens=n_tokens, emb_size=16, hid_size=64):\n",
    "        \"\"\" \n",
    "        A fixed window model that looks on at least 5 previous symbols.\n",
    "        \n",
    "        Note: fixed window LM is effectively performing a convolution over a sequence of words.\n",
    "        This convolution only looks on current and previous words.\n",
    "        Such convolution can be represented as a sequence of 2 operations:\n",
    "        - pad input vectors by {strides * (filter_size - 1)} zero vectors on the \"left\", do not pad right\n",
    "        - perform regular convolution with {filter_size} and {strides}\n",
    "        - If you're absolutely lost, here's a hint: use ZeroPadding1D and Conv1D from keras.layers\n",
    "        You can stack several convolutions at once\n",
    "        \"\"\"\n",
    "        super().__init__() # initialize base class to track sub-layers, trainable variables, etc.\n",
    "        \n",
    "        #YOUR CODE - create layers/variables and any metadata you want, e.g. self.emb = L.Embedding(...)\n",
    "        \n",
    "        filter_size, strides = 5,1\n",
    "        self.emb = L.Embedding(n_tokens, emb_size) # batch*input -> batch*input*16\n",
    "        self.pad1 = L.ZeroPadding1D(padding=(strides*(filter_size-1),0)) #batch*input -> batch*{input+strides*(filter_size-1)}*16\n",
    "        self.conv1 = L.Conv1D(filters=16, kernel_size=filter_size, strides=strides, activation='relu',padding='valid') #batch*{input+strides*(filter_size-1)}*16\n",
    "        \n",
    "        self.dense1 = L.Dense(units=64, activation='relu') #batch*{input+strides*(filter_size-1)}*64\n",
    "        self.dense2 = L.Dense(units=32, activation='relu') #batch*{input+strides*(filter_size-1)}*32\n",
    "        self.dense3 = L.Dense(units=16, activation='relu') ##batch*{input+strides*(filter_size-1)}*16\n",
    "        self.output_layer = L.Dense(units=n_tokens) #batch*{input+strides*(filter_size-1)}*n_tokens\n",
    "        \n",
    "        #END OF YOUR CODE\n",
    "    \n",
    "    def __call__(self, input_ix):\n",
    "        \"\"\"\n",
    "        compute language model logits given input tokens\n",
    "        :param input_ix: batch of sequences with token indices, tf tensor: int32[batch_size, sequence_length]\n",
    "        :returns: pre-softmax linear outputs of language model [batch_size, sequence_length, n_tokens]\n",
    "            these outputs will be used as logits to compute P(x_t | x_0, ..., x_{t - 1})\n",
    "        \"\"\"\n",
    "        # YOUR CODE - apply layers, see docstring above\n",
    "        input_ = tf.Variable(input_ix)\n",
    "        emb = self.emb(input_)\n",
    "        pad1 = self.pad1(emb)\n",
    "        conv1 = self.conv1(pad1)\n",
    "        dense1 = self.dense1(conv1)\n",
    "        dense2 = self.dense2(dense1)\n",
    "        dense3 = self.dense3(dense2)\n",
    "        output = self.output_layer(dense3)\n",
    "\n",
    "#         print(output.shape)\n",
    "        return output\n",
    "    \n",
    "    def get_possible_next_tokens(self, prefix=BOS, temperature=1.0, max_len=100):\n",
    "        \"\"\" :returns: probabilities of next token, dict {token : prob} for all tokens \"\"\"\n",
    "        prefix_ix = tf.convert_to_tensor(to_matrix([prefix]), tf.int32)\n",
    "        probs = tf.nn.softmax(self(prefix_ix)[0, -1]).numpy()  # shape: [n_tokens]\n",
    "        return dict(zip(tokens, probs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: ('embedding_40/embeddings:0', 'conv1d_40/kernel:0', 'conv1d_40/bias:0', 'dense_160/kernel:0', 'dense_160/bias:0', 'dense_161/kernel:0', 'dense_161/bias:0', 'dense_162/kernel:0', 'dense_162/bias:0', 'dense_163/kernel:0', 'dense_163/bias:0')\n",
      "Shapes: (TensorShape([136, 16]), TensorShape([5, 16, 16]), TensorShape([16]), TensorShape([16, 64]), TensorShape([64]), TensorShape([64, 32]), TensorShape([32]), TensorShape([32, 16]), TensorShape([16]), TensorShape([16, 136]), TensorShape([136]))\n"
     ]
    }
   ],
   "source": [
    "model = FixedWindowLanguageModel()\n",
    "\n",
    "# note: tensorflow and keras layers create variables only after they're first applied (called)\n",
    "dummy_input_ix = tf.constant(to_matrix(dummy_lines))\n",
    "dummy_logits = model(dummy_input_ix)\n",
    "\n",
    "print('Weights:', tuple(w.name for w in model.trainable_variables))\n",
    "print('Shapes:', tuple(w.shape for w in model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(dummy_logits, tf.Tensor)\n",
    "assert dummy_logits.shape == (len(dummy_lines), max(map(len, dummy_lines)), n_tokens), \"please check output shape\"\n",
    "assert np.all(np.isfinite(dummy_logits)), \"inf/nan encountered\"\n",
    "assert not np.allclose(dummy_logits.numpy().sum(-1), 1), \"please predict linear outputs, don't use softmax (maybe you've just got unlucky)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 15)\n",
      "(3, 15, 136)\n"
     ]
    }
   ],
   "source": [
    "# test for lookahead\n",
    "dummy_input_ix_2 = tf.constant(to_matrix([line[:3] + 'e' * (len(line) - 3) for line in dummy_lines]))\n",
    "dummy_logits_2 = model(dummy_input_ix_2)\n",
    "print(dummy_input_ix_2.shape)\n",
    "print(dummy_logits_2.shape)\n",
    "\n",
    "assert np.allclose(dummy_logits[:, :3] - dummy_logits_2[:, :3], 0), \"your model's predictions depend on FUTURE tokens. \" \\\n",
    "    \" Make sure you don't allow any layers to look ahead of current token.\" \\\n",
    "    \" You can also get this error if your model is not deterministic (e.g. dropout). Disable it for this test.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now tune our network's parameters to minimize categorical crossentropy over training dataset $D$:\n",
    "\n",
    "$$ L = {\\frac1{|D|}} \\sum_{X \\in D} \\sum_{x_i \\in X} - \\log p(x_t \\mid x_1, \\dots, x_{t-1}, \\theta) $$\n",
    "\n",
    "As usual with with neural nets, this optimization is performed via stochastic gradient descent with backprop.  One can also note that minimizing crossentropy is equivalent to minimizing model __perplexity__, KL-divergence or maximizng log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix:\n",
      " [[ 1 66 67 68  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 66 68 66 67 66  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 68 18 19 20 21 22 23 24 25 26 17  0]]\n",
      "lengths: [ 5  9 15]\n"
     ]
    }
   ],
   "source": [
    "def compute_lengths(input_ix, eos_ix=token_to_id[EOS]):\n",
    "    \"\"\" compute length of each line in input ix (incl. first EOS), int32 vector of shape [batch_size] \"\"\"\n",
    "    count_eos = tf.cumsum(tf.cast(tf.equal(input_ix, eos_ix), tf.int32), axis=1, exclusive=True)\n",
    "    lengths = tf.reduce_sum(tf.cast(tf.equal(count_eos, 0), tf.int32), axis=1)\n",
    "    return lengths\n",
    "\n",
    "print('matrix:\\n', dummy_input_ix.numpy())\n",
    "print('lengths:', compute_lengths(dummy_input_ix).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, input_ix):\n",
    "    \n",
    "    cce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    input_ix = to_matrix(dummy_lines, max_len=15)\n",
    "    input_ix = tf.convert_to_tensor(input_ix, dtype=tf.int32)\n",
    "    logits = model(input_ix[:, :-1])\n",
    "\n",
    "    # print(type(logits))\n",
    "\n",
    "    # Apply softmax operation to get the predicted probability\n",
    "    softmax_output = tf.nn.softmax(logits)\n",
    "    reference_answers = input_ix[:, 1:]\n",
    "    \n",
    "    # Get the \"valid\" length of each line\n",
    "    lengths = compute_lengths(reference_answers)\n",
    "    \n",
    "    ttt = tf.stack(\n",
    "        [tf.sequence_mask(lengths, logits.shape[1])]*logits.shape[2], axis=-1, name='stack'\n",
    "    )\n",
    "    ans_class = tf.where(ttt,softmax_output,[1])\n",
    "\n",
    "# print(cce(reference_answers, softmax_output))\n",
    "\n",
    "    # Matrix for label, only the label class would be 1\n",
    "#     ans_class = np.zeros(logits.shape)\n",
    "\n",
    "#     for index, batch_length in enumerate(lengths):\n",
    "#         for item in range(batch_length):\n",
    "#             ans_class[index,item,reference_answers[index,item]]=1\n",
    "            \n",
    "#     print(reference_answers.shape, ans_class.shape)\n",
    "\n",
    "    return cce(reference_answers, ans_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss2(model, input_ix):\n",
    "    \"\"\"\n",
    "    :param model: language model that can compute next token logits given token indices\n",
    "    :param input ix: int32 matrix of tokens, shape: [batch_size, length]; padded with eos_ix\n",
    "    \"\"\"\n",
    "\n",
    "    # Your task: implement loss function as per formula above\n",
    "    # your loss should only be computed on actual tokens, excluding padding\n",
    "    # predicting actual tokens and first EOS do count. Subsequent EOS-es don't\n",
    "    # you will likely need to use compute_lengths and/or tf.sequence_mask to get it right.\n",
    "    input_ix = to_matrix(dummy_lines, max_len=15)\n",
    "    input_ix = tf.convert_to_tensor(input_ix, dtype=tf.int32)\n",
    "    logits = model(input_ix[:, :-1])\n",
    "\n",
    "    # print(\"input tensor shape:\", input_ix.shape)\n",
    "    # print('output tensor shape:', logits.shape)\n",
    "    \n",
    "    # Apply softmax operation to get the predicted probability\n",
    "    softmax_output = tf.nn.softmax(logits)\n",
    "    # print('softmax output tensor shape:', softmax_output.shape)\n",
    "    reference_answers = input_ix[:, 1:]\n",
    "    # print('lable shape:', reference_answers.shape)\n",
    "    \n",
    "    # Get the \"valid\" length of each line\n",
    "    lengths = compute_lengths(reference_answers)\n",
    "\n",
    "    ttt = tf.stack(\n",
    "        [tf.sequence_mask(lengths, logits.shape[1])]*logits.shape[2], axis=-1, name='stack'\n",
    "    )\n",
    "    # print('ttt shape:', ttt.shape, ttt.dtype)\n",
    "    ans_class = tf.where(ttt, softmax_output,[1])  \n",
    "    # print(ans_class.shape, ans_class.dtype)\n",
    "    \n",
    "    # Matrix for label, only the label class would be 1\n",
    "#     ans_class = np.zeros(logits.shape)\n",
    "\n",
    "#     for index, batch_length in enumerate(lengths):\n",
    "#         for item in range(batch_length):\n",
    "#             ans_class[index,item,reference_answers[index,item]]=1\n",
    "\n",
    "    ######\n",
    "    ans=tf.Variable(0, dtype=tf.float32)\n",
    "    for index, batch_length in enumerate(lengths):\n",
    "        for item in range(batch_length):\n",
    "            ans = ans - np.log(ans_class[index,item,reference_answers[index,item]])\n",
    "            # ans = ans + ans_class[index, item, reference_answers[index,item]]\n",
    "\n",
    "    # return ans\n",
    "    return ans / len(lengths)\n",
    "    ######\n",
    "    \n",
    "\n",
    "    # Compute the loss\n",
    "    # ans=tf.Variable(0)\n",
    "    # for index, batch_length in enumerate(lengths):\n",
    "    #     for item in range(batch_length):\n",
    "    #         ans = ans - np.log(np.tensordot(softmax_output[index,item], ans_class[index,item], axes=1))\n",
    "    \n",
    "#     return tf.convert_to_tensor(ans/len(lengths))\n",
    "    # return ans / len(lengths)\n",
    "#     return ans/len(lengths)\n",
    "    \n",
    "#     return <YOUR CODE: return scalar loss>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 14, 136])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 4,  8, 14], dtype=int32)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = to_matrix(dummy_lines, max_len=15)\n",
    "reference_answers = input_ix[:, 1:]\n",
    "lengths = compute_lengths(reference_answers)\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.4506261, shape=(), dtype=float32) tf.Tensor(2.4506261, shape=(), dtype=float32) <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "loss_1 = compute_loss(model, to_matrix(dummy_lines, max_len=15))\n",
    "loss_2 = compute_loss(model, to_matrix(dummy_lines, max_len=16))\n",
    "print(loss_1, loss_2, type(loss_1))\n",
    "assert (np.ndim(loss_1) == 0) and (0 < loss_1 < 100), \"loss must be a positive scalar\"\n",
    "assert np.allclose(loss_1, loss_2), 'do not include  AFTER first EOS into loss. '\\\n",
    "    'Hint: use tf.sequence_mask. Beware +/-1 errors. And be careful when averaging!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4.9132457, shape=(), dtype=float32) tf.Tensor(4.9132457, shape=(), dtype=float32) <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "loss_1 = compute_loss(model, to_matrix(dummy_lines, max_len=15))\n",
    "loss_2 = compute_loss(model, to_matrix(dummy_lines, max_len=16))\n",
    "print(loss_1, loss_2, type(loss_1))\n",
    "assert (np.ndim(loss_1) == 0) and (0 < loss_1 < 100), \"loss must be a positive scalar\"\n",
    "assert np.allclose(loss_1, loss_2), 'do not include  AFTER first EOS into loss. '\\\n",
    "    'Hint: use tf.sequence_mask. Beware +/-1 errors. And be careful when averaging!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42.575596, shape=(), dtype=float32) tf.Tensor(42.575596, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = FixedWindowLanguageModel()\n",
    "loss_1 = compute_loss2(model, to_matrix(dummy_lines, max_len=15))\n",
    "loss_2 = compute_loss2(model, to_matrix(dummy_lines, max_len=16))\n",
    "print(loss_1, loss_2)\n",
    "assert (np.ndim(loss_1) == 0) and (0 < loss_1 < 100), \"loss must be a positive scalar\"\n",
    "assert np.allclose(loss_1, loss_2), 'do not include  AFTER first EOS into loss. '\\\n",
    "    'Hint: use tf.sequence_mask. Beware +/-1 errors. And be careful when averaging!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 15)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'> (3, 14, 136)\n",
      "tf.Tensor(4.9131002, shape=(), dtype=float32)\n",
      "42.57629378636678 <class 'numpy.float64'> tf.Tensor([42.57629379], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "model = FixedWindowLanguageModel()\n",
    "cce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "input_ix = to_matrix(dummy_lines, max_len=15)\n",
    "input_ix = tf.convert_to_tensor(input_ix, dtype=tf.int32)\n",
    "print(input_ix.shape)\n",
    "logits = model(input_ix[:, :-1])\n",
    "\n",
    "print(type(logits), logits.shape)\n",
    "\n",
    "# Apply softmax operation to get the predicted probability\n",
    "softmax_output = tf.nn.softmax(logits)\n",
    "reference_answers = input_ix[:, 1:]\n",
    "# Get the \"valid\" length of each line\n",
    "lengths = compute_lengths(reference_answers)\n",
    "\n",
    "ttt = tf.stack(\n",
    "    [tf.sequence_mask(lengths, 14)]*136, axis=-1, name='stack'\n",
    ")\n",
    "ans_class = tf.where(ttt,softmax_output,[1]) \n",
    "\n",
    "print(cce(reference_answers, softmax_output))\n",
    "\n",
    "# Matrix for label, only the label class would be 1\n",
    "# ans_class = np.zeros(logits.shape)\n",
    "\n",
    "# for index, batch_length in enumerate(lengths):\n",
    "#     for item in range(batch_length):\n",
    "#         ans_class[index,item,reference_answers[index,item]]=1\n",
    "        \n",
    "# Compute the loss\n",
    "ans=0\n",
    "for index, batch_length in enumerate(lengths):\n",
    "    for item in range(batch_length):\n",
    "        ans+= -np.log(np.tensordot(softmax_output[index,item], ans_class[index,item], axes=1))\n",
    "print(ans/len(lengths), type(ans),tf.convert_to_tensor(np.array([ans/len(lengths)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(34.666666666666664, shape=(), dtype=float64) tf.Tensor(34.666666666666664, shape=(), dtype=float64) <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "loss_1 = compute_loss(model, to_matrix(dummy_lines, max_len=15))\n",
    "loss_2 = compute_loss(model, to_matrix(dummy_lines, max_len=16))\n",
    "print(loss_1, loss_2,type(loss_1))\n",
    "assert (np.ndim(loss_1) == 0) and (0 < loss_1 < 100), \"loss must be a positive scalar\"\n",
    "assert np.allclose(loss_1, loss_2), 'do not include  AFTER first EOS into loss. '\\\n",
    "    'Hint: use tf.sequence_mask. Beware +/-1 errors. And be careful when averaging!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "You will need two functions: one to compute test loss and another to generate samples. For your convenience, we implemented them both in your stead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_lines(model, dev_lines, batch_size):\n",
    "    \"\"\" computes average loss over the entire dataset \"\"\"\n",
    "    dev_loss_num, dev_loss_len = 0., 0.\n",
    "    for i in range(0, len(dev_lines), batch_size):\n",
    "        batch_ix = to_matrix(dev_lines[i: i + batch_size])\n",
    "        dev_loss_num += compute_loss(model, batch_ix) * len(batch_ix)\n",
    "        dev_loss_len += len(batch_ix)\n",
    "    return dev_loss_num / dev_loss_len\n",
    "\n",
    "def generate(model, prefix=BOS, temperature=1.0, max_len=100):\n",
    "    \"\"\"\n",
    "    Samples output sequence from probability distribution obtained by model\n",
    "    :param temperature: samples proportionally to model probabilities ^ temperature\n",
    "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        token_probs = model.get_possible_next_tokens(prefix)\n",
    "#         print(token_probs)\n",
    "        tokens, probs = zip(*token_probs.items())\n",
    "        if temperature == 0:\n",
    "            next_token = tokens[np.argmax(probs)]\n",
    "        else:\n",
    "            probs = np.array([p ** (1. / temperature) for p in probs])\n",
    "            probs /= sum(probs)\n",
    "            next_token = np.random.choice(tokens, p=probs)\n",
    "        \n",
    "        prefix += next_token\n",
    "        if next_token == EOS or len(prefix) > max_len: break\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Finally, let's train our model on minibatches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample before training: Bridging$-ωDá+*é\\vYÖ0/MHôõ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, dev_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
    "model = FixedWindowLanguageModel()\n",
    "\n",
    "batch_size = 256\n",
    "score_dev_every = 250\n",
    "train_history, dev_history = [], []\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "# score untrained model\n",
    "dev_history.append((0, score_lines(model, dev_lines, batch_size)))\n",
    "print(\"Sample before training:\", generate(model, 'Bridging'))\n",
    "# print(\"Sample before training:\", generate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated examples (tau=0.5):\n",
      " abc\n",
      "\n",
      " abacaba\n",
      "\n",
      " abc1234567890\n",
      "\n",
      "Scoring dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 58.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#999 Dev loss: 1.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "from tqdm import trange\n",
    "\n",
    "for i in trange(len(train_history), 1000):\n",
    "    batch = to_matrix(sample(train_lines, batch_size))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "#         tape.watch(model.trainable_variables)\n",
    "        loss_i = compute_loss(model, batch)\n",
    "#         print(loss_i)\n",
    "        \n",
    "    grads = tape.gradient(loss_i, model.trainable_variables)\n",
    "#     grads = tape.gradient(tf.convert_to_tensor(loss_i), model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    train_history.append((i, loss_i.numpy()))\n",
    "    \n",
    "    if (i + 1) % 50 == 0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(*zip(*train_history), alpha=0.1, label='train_loss')\n",
    "        if len(dev_history):\n",
    "            plt.plot(*zip(*dev_history), color='red', label='dev_loss')\n",
    "        plt.legend(); plt.grid(); plt.show()\n",
    "        print(\"Generated examples (tau=0.5):\")\n",
    "        for _ in range(3):\n",
    "            print(generate(model, temperature=0.5))\n",
    "    \n",
    "    if (i + 1) % score_dev_every == 0:\n",
    "        print(\"Scoring dev...\")\n",
    "        dev_history.append((i, score_lines(model, dev_lines, batch_size)))\n",
    "        print('#%i Dev loss: %.3f' % dev_history[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dev loss: tf.Tensor(1.950132, shape=(), dtype=float32)\n",
      " abc\n",
      "\n",
      " abacaba\n",
      "\n",
      " abc\n",
      "\n",
      " abc\n",
      "\n",
      " abc\n",
      "\n",
      " abc1234567890\n",
      "\n",
      " abc\n",
      "\n",
      " abc\n",
      "\n",
      " abacaba\n",
      "\n",
      " abc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert np.mean(train_history[:10], axis=0)[1] > np.mean(train_history[-10:], axis=0)[1], \"The model didn't converge.\"\n",
    "print(\"Final dev loss:\", dev_history[-1][-1])\n",
    "\n",
    "for i in range(10):\n",
    "    print(generate(model, temperature=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Language Models (3 points including training)\n",
    "\n",
    "Fixed-size architectures are reasonably good when capturing short-term dependencies, but their design prevents them from capturing any signal outside their window. We can mitigate this problem by using a __recurrent neural network__:\n",
    "\n",
    "$$ h_0 = \\vec 0 ; \\quad h_{t+1} = RNN(x_t, h_t) $$\n",
    "\n",
    "$$ p(x_t \\mid x_0, \\dots, x_{t-1}, \\theta) = dense_{softmax}(h_{t-1}) $$\n",
    "\n",
    "Such model processes one token at a time, left to right, and maintains a hidden state vector between them. Theoretically, it can learn arbitrarily long temporal dependencies given large enough hidden size.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/rnn_lm.jpg' width=480px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLanguageModel(L.Layer):\n",
    "    def __init__(self, n_tokens=n_tokens, emb_size=16, hid_size=256):\n",
    "        \"\"\" \n",
    "        Build a recurrent language model.\n",
    "        You are free to choose anything you want, but the recommended architecture is\n",
    "        - token embeddings\n",
    "        - one or more LSTM/GRU layers with hid size\n",
    "        - linear layer to predict logits\n",
    "        \"\"\"\n",
    "        super().__init__() # initialize base class to track sub-layers, trainable variables, etc.\n",
    "        \n",
    "        # YOUR CODE - create layers/variables/etc\n",
    "        \n",
    "        filter_size, strides = 5,1\n",
    "        self.emb = L.Embedding(n_tokens, emb_size) # batch*input -> batch*input*emb_size\n",
    "        self.rnn1 = L.GRU(hid_size, return_sequences=True) # batch*input*emb_size -> batch*input*hid_size\n",
    "        self.rnn2 = L.GRU(hid_size, return_sequences=True) # batch*input*hid_size -> batch*input*hid_size\n",
    "        self.output_layer = L.Dense(n_tokens) # batch*input*hid_size-> batch*input*n_token\n",
    "        \n",
    "        \n",
    "#         self.pad1 = L.ZeroPadding1D(padding=(strides*(filter_size-1),0)) #batch*input -> batch*{input+strides*(filter_size-1)}*16\n",
    "#         self.conv1 = L.Conv1D(filters=16, kernel_size=filter_size, strides=strides, activation='relu',padding='valid') #batch*{input+strides*(filter_size-1)}*16\n",
    "        \n",
    "#         self.dense1 = L.Dense(units=64, activation='relu') #batch*{input+strides*(filter_size-1)}*64\n",
    "#         self.dense2 = L.Dense(units=32, activation='relu') #batch*{input+strides*(filter_size-1)}*32\n",
    "#         self.dense3 = L.Dense(units=16, activation='relu') ##batch*{input+strides*(filter_size-1)}*16\n",
    "#         self.output_layer = L.Dense(units=n_tokens) #batch*{input+strides*(filter_size-1)}*n_tokens\n",
    "        \n",
    "        #END OF YOUR CODE\n",
    "    \n",
    "    def __call__(self, input_ix):\n",
    "        \"\"\"\n",
    "        compute language model logits given input tokens\n",
    "        :param input_ix: batch of sequences with token indices, tf tensor: int32[batch_size, sequence_length]\n",
    "        :returns: pre-softmax linear outputs of language model [batch_size, sequence_length, n_tokens]\n",
    "            these outputs will be used as logits to compute P(x_t | x_0, ..., x_{t - 1})\n",
    "        \"\"\"\n",
    "        input_ = tf.Variable(input_ix)\n",
    "        emb = self.emb(input_)\n",
    "        rnn1 = self.rnn1(emb)\n",
    "        rnn2 = self.rnn2(rnn1)\n",
    "        output = self.output_layer(rnn2)\n",
    "                                    \n",
    "#         pad1 = self.pad1(emb)\n",
    "#         conv1 = self.conv1(pad1)\n",
    "#         dense1 = self.dense1(conv1)\n",
    "#         dense2 = self.dense2(dense1)\n",
    "#         dense3 = self.dense3(dense2)\n",
    "#         output = self.output_layer(dense3)\n",
    "\n",
    "#         print(output.shape)\n",
    "        return output\n",
    "#         return <...>\n",
    "    \n",
    "    def get_possible_next_tokens(self, prefix=BOS, temperature=1.0, max_len=100):\n",
    "        \"\"\" :returns: probabilities of next token, dict {token : prob} for all tokens \"\"\"\n",
    "        prefix_ix = tf.convert_to_tensor(to_matrix([prefix]), tf.int32)\n",
    "        probs = tf.nn.softmax(self(prefix_ix)[0, -1]).numpy()  # shape: [n_tokens]\n",
    "        return dict(zip(tokens, probs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: ('embedding_7/embeddings:0', 'gru/gru_cell/kernel:0', 'gru/gru_cell/recurrent_kernel:0', 'gru/gru_cell/bias:0', 'gru_1/gru_cell_1/kernel:0', 'gru_1/gru_cell_1/recurrent_kernel:0', 'gru_1/gru_cell_1/bias:0', 'dense_28/kernel:0', 'dense_28/bias:0')\n"
     ]
    }
   ],
   "source": [
    "model = RNNLanguageModel()\n",
    "\n",
    "# note: tensorflow and keras layers create variables only after they're first applied (called)\n",
    "dummy_input_ix = tf.constant(to_matrix(dummy_lines))\n",
    "dummy_logits = model(dummy_input_ix)\n",
    "\n",
    "assert isinstance(dummy_logits, tf.Tensor)\n",
    "assert dummy_logits.shape == (len(dummy_lines), max(map(len, dummy_lines)), n_tokens), \"please check output shape\"\n",
    "assert np.all(np.isfinite(dummy_logits)), \"inf/nan encountered\"\n",
    "assert not np.allclose(dummy_logits.numpy().sum(-1), 1), \"please predict linear outputs, don't use softmax (maybe you've just got unlucky)\"\n",
    "print('Weights:', tuple(w.name for w in model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for lookahead\n",
    "dummy_input_ix_2 = tf.constant(to_matrix([line[:3] + 'e' * (len(line) - 3) for line in dummy_lines]))\n",
    "dummy_logits_2 = model(dummy_input_ix_2)\n",
    "\n",
    "assert np.allclose(dummy_logits[:, :3] - dummy_logits_2[:, :3], 0), \"your model's predictions depend on FUTURE tokens. \" \\\n",
    "    \" Make sure you don't allow any layers to look ahead of current token.\" \\\n",
    "    \" You can also get this error if your model is not deterministic (e.g. dropout). Disable it for this test.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN training\n",
    "\n",
    "Our RNN language model should optimize the same loss function as fixed-window model. But there's a catch. Since RNN recurrently multiplies gradients through many time-steps, gradient values may explode, [ruining](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/nan.jpg) your model.\n",
    "The common solution to that problem is to clip gradients either [individually](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/clip_by_value) or [globally](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/clip_by_global_norm).\n",
    "\n",
    "Your task here is to prepare tensorflow graph that would minimize the same loss function. If you encounter large loss fluctuations during training, please add gradient clipping using urls above.\n",
    "\n",
    "_Note: gradient clipping is not exclusive to RNNs. Convolutional networks with enough depth often suffer from the same issue._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample before training: Bridging-nωçΩGi4R~TχsBIr:awsμPolçn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64         # <-- please tune batch size to fit your CPU/GPU configuration\n",
    "score_dev_every = 250\n",
    "train_history, dev_history = [], []\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "# score untrained model\n",
    "dev_history.append((0, score_lines(model, dev_lines, batch_size)))\n",
    "print(\"Sample before training:\", generate(model, 'Bridging'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated examples (tau=0.5):\n",
      " abc\n",
      "\n",
      " abc\n",
      "\n",
      " abc\n",
      "\n",
      "Scoring dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 937/937 [01:34<00:00,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#999 Dev loss: 0.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in trange(len(train_history), 1000):\n",
    "    batch = to_matrix(sample(train_lines, batch_size))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_i = compute_loss(model, batch)\n",
    "        \n",
    "    grads = tape.gradient(loss_i, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    train_history.append((i, loss_i.numpy()))\n",
    "    \n",
    "    if (i + 1) % 50 == 0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(*zip(*train_history), alpha=0.1, label='train_loss')\n",
    "        if len(dev_history):\n",
    "            plt.plot(*zip(*dev_history), color='red', label='dev_loss')\n",
    "        plt.legend(); plt.grid(); plt.show()\n",
    "        print(\"Generated examples (tau=0.5):\")\n",
    "        for _ in range(3):\n",
    "            print(generate(model, temperature=0.5))\n",
    "    \n",
    "    if (i + 1) % score_dev_every == 0:\n",
    "        print(\"Scoring dev...\")\n",
    "        dev_history.append((i, score_lines(model, dev_lines, batch_size)))\n",
    "        print('#%i Dev loss: %.3f' % dev_history[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dev loss: tf.Tensor(0.07890152, shape=(), dtype=float32)\n",
      " abc\n",
      "\n",
      " abacaba\n",
      "\n",
      " abc1234567890\n",
      "\n",
      " abc\n",
      "\n",
      " abc\n",
      "\n",
      " abc\n",
      "\n",
      " abc\n",
      "\n",
      " abc\n",
      "\n",
      " abc1234567890\n",
      "\n",
      " abacaba\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert np.mean(train_history[:10], axis=0)[1] > np.mean(train_history[-10:], axis=0)[1], \"The model didn't converge.\"\n",
    "print(\"Final dev loss:\", dev_history[-1][-1])\n",
    "for i in range(10):\n",
    "    print(generate(model, temperature=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative sampling strategies (1 point)\n",
    "\n",
    "So far we've sampled tokens from the model in proportion with their probability.\n",
    "However, this approach can sometimes generate nonsense words due to the fact that softmax probabilities of these words are never exactly zero. This issue can be somewhat mitigated with sampling temperature, but low temperature harms sampling diversity. Can we remove the nonsense words without sacrificing diversity? __Yes, we can!__ But it takes a different sampling strategy.\n",
    "\n",
    "__Top-k sampling:__ on each step, sample the next token from __k most likely__ candidates from the language model.\n",
    "\n",
    "Suppose $k=3$ and the token probabilities are $p=[0.1, 0.35, 0.05, 0.2, 0.3]$. You first need to select $k$ most likely words and set the probability of the rest to zero: $\\hat p=[0.0, 0.35, 0.0, 0.2, 0.3]$ and re-normalize: \n",
    "$p^*\\approx[0.0, 0.412, 0.0, 0.235, 0.353]$.\n",
    "\n",
    "__Nucleus sampling:__ similar to top-k sampling, but this time we select $k$ dynamically. In nucleous sampling, we sample from top-__N%__ fraction of the probability mass.\n",
    "\n",
    "Using the same  $p=[0.1, 0.35, 0.05, 0.2, 0.3]$ and nucleous N=0.9, the nucleous words consist of:\n",
    "1. most likely token $w_2$, because $p(w_2) < N$\n",
    "2. second most likely token $w_5$, $p(w_2) + p(w_5) = 0.65 < N$\n",
    "3. third most likely token $w_4$ because $p(w_2) + p(w_5) + p(w_4) = 0.85 < N$\n",
    "\n",
    "And thats it, because the next most likely word would overflow: $p(w_2) + p(w_5) + p(w_4) + p(w_1) = 0.95 > N$.\n",
    "\n",
    "After you've selected the nucleous words, you need to re-normalize them as in top-k sampling and generate the next token.\n",
    "\n",
    "__Your task__ is to implement nucleus sampling variant and see if its any good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nucleus(model, prefix=BOS, nucleus=0.9, max_len=100):\n",
    "    \"\"\"\n",
    "    Generate a sequence with nucleous sampling\n",
    "    :param prefix: a string containing space-separated previous tokens\n",
    "    :param nucleus: N from the formulae above, N \\in [0, 1]\n",
    "    :param max_len: generate sequences with at most this many tokens, including prefix\n",
    "    \n",
    "    :note: make sure that nucleous always contains at least one word, even if p(w*) > nucleus\n",
    "    \n",
    "    \"\"\"\n",
    "    while True:\n",
    "        token_probs = model.get_possible_next_tokens(prefix)\n",
    "        tokens, probs = zip(*token_probs.items())\n",
    "        \n",
    "\n",
    "        <YOUR CODE HERE>\n",
    "        \n",
    "        prefix += <YOUR CODE>\n",
    "        if next_token == EOS or len(prefix) > max_len: break\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(generate_nucleous(model, nucleous_size=PLAY_WITH_ME_SENPAI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus quest I: Beam Search (2 pts incl. samples)\n",
    "\n",
    "At times, you don't really want the model to generate diverse outputs as much as you want a __single most likely hypothesis.__ A single best translation, most likely continuation of the search query given prefix, etc. Except, you can't get it. \n",
    "\n",
    "In order to find the exact most likely sequence containing 10 tokens, you would need to enumerate all $|V|^{10}$ possible hypotheses. In practice, 9 times out of 10 you will instead find an approximate most likely output using __beam search__.\n",
    "\n",
    "Here's how it works:\n",
    "0. Initial `beam` = [prefix], max beam_size = k\n",
    "1. for T steps:\n",
    "2. ` ... ` generate all possible next tokens for all hypotheses in beam, formulate `len(beam) * len(vocab)` candidates\n",
    "3. ` ... ` select beam_size best for all candidates as new `beam`\n",
    "4. Select best hypothesis (-es?) from beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        <title>Bokeh Plot</title>\n",
       "        \n",
       "<link rel=\"stylesheet\" href=\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\" type=\"text/css\" />\n",
       "        \n",
       "<script type=\"text/javascript\" src=\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.js\"></script>\n",
       "<script type=\"text/javascript\">\n",
       "    Bokeh.set_log_level(\"info\");\n",
       "</script>\n",
       "        <style>\n",
       "          html {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "          }\n",
       "          body {\n",
       "            width: 90%;\n",
       "            height: 100%;\n",
       "            margin: auto;\n",
       "          }\n",
       "        </style>\n",
       "    </head>\n",
       "    <body>\n",
       "        \n",
       "        <div class=\"bk-root\">\n",
       "            <div class=\"bk-plotdiv\" id=\"ff8c3f31-952d-4c2f-8b58-13e7cec51b58\"></div>\n",
       "        </div>\n",
       "        \n",
       "        <script type=\"text/javascript\">\n",
       "            (function() {\n",
       "          var fn = function() {\n",
       "            Bokeh.safely(function() {\n",
       "              var docs_json = {\"ba84f797-d201-498d-a731-5adafa5447b7\":{\"roots\":{\"references\":[{\"attributes\":{\"plot\":null,\"text\":\"Beam search\"},\"id\":\"5af81591-5793-4721-a459-e0a4ca700855\",\"type\":\"Title\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"size\":{\"units\":\"screen\",\"value\":24},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"43ae4eb3-d229-4335-a758-a5d18149bd65\",\"type\":\"Circle\"},{\"attributes\":{\"bounds\":[-10.0,20.0],\"callback\":null,\"end\":12,\"js_property_callbacks\":{\"change:end\":[{\"id\":\"eab13fb4-9405-4d14-8bf6-46c6f698b4bb\",\"type\":\"CustomJS\"}]},\"start\":-1},\"id\":\"14e9976c-9458-4bce-be96-da2f3c304cec\",\"type\":\"Range1d\"},{\"attributes\":{\"source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"}},\"id\":\"2e9dcf01-3f79-4337-b7dd-26f0525180b9\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"08bbcb52-00b5-4803-9e7a-9252db09708d\",\"type\":\"Text\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"tokens\",\"nonselection_glyph\":{\"id\":\"3621fd59-3cb3-4305-8802-6f7f75a23fd6\",\"type\":\"Text\"},\"selection_glyph\":null,\"view\":{\"id\":\"ddf587aa-019f-43a1-af8c-52144e732785\",\"type\":\"CDSView\"}},\"id\":\"a2ab1853-0966-4519-874f-956f801f1c72\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"id\",\"parent_id\",\"children_ids\",\"is_best\",\"depth\",\"hypo_i\",\"token\",\"token_id\",\"x\",\"y\",\"circle_fill_color\",\"line_color\",\"line_width\",\"edge_xx\",\"edge_yy\",\"token_text\",\"token_font_size\",\"hypo_i_text\",\"hypo_i_offset\",\"_on_hover_token\",\"_on_hover_token_id\",\"_on_hover_score\"],\"data\":{\"_on_hover_score\":[\"-4.7282\",\"-4.2071\",\"-4.8782\",\"-1.3577\",\"-4.0420\",\"-4.2097\",\"-4.5624\",\"-3.2410\",\"-6.9225\",\"-4.6717\",\"-2.8497\",\"-3.8023\",\"-4.1460\",\"-3.6443\",\"-4.3135\",\"-4.7070\",\"-3.1373\",\"-4.5105\",\"-6.1526\",\"-3.0974\",\"-3.7421\",\"-3.4956\",\"0.0000\",\"-5.2694\",\"-4.4104\",\"-6.1752\",\"-3.7617\",\"-4.6281\",\"-6.5626\",\"-3.7175\",\"-0.7384\",\"-4.5439\",\"-5.2967\",\"-3.6831\",\"-5.2153\",\"-3.7830\",\"-3.1335\",\"-0.8716\",\"-3.7312\",\"-3.8895\",\"-6.5984\"],\"_on_hover_token\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"_on_hover_token_id\":[1,780,25,2482,15356,2482,1879,3,17084,25,13862,5,1,7691,1,15356,25,15328,4255,11685,11,3487,-1,21342,15356,4,21342,11,1781,30,3622,3,25,1078,1,5093,26478,11,2451,13862,22624],\"children_ids\":[[],[[2,3]],[[10,3],[10,2],[10,1],[10,0]],[[4,3],[4,1],[4,0]],[[9,3],[9,1],[9,0]],[],[],[[6,1]],[],[[8,2]],[[5,0]],[[2,2]],[],[[4,2]],[],[[7,2]],[[6,2],[6,0]],[],[],[[5,1]],[[2,1]],[],[[1,3],[1,2],[1,1],[1,0]],[[9,2]],[[8,1]],[],[[7,3],[7,1]],[],[],[[5,2]],[[2,0]],[],[],[[8,3],[8,0]],[],[[7,0]],[],[[3,3],[3,2],[3,1],[3,0]],[[5,3]],[[6,3]],[]],\"circle_fill_color\":[\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\"],\"depth\":[7,1,9,3,8,2,6,5,10,7,4,1,9,3,8,6,5,2,10,4,1,3,0,8,7,9,6,2,10,4,1,5,8,7,9,6,3,2,4,5,10],\"edge_xx\":[[6.0,7.0],[0.0,1.0],[8.0,9.0],[2.0,3.0],[7.0,8.0],[1.0,2.0],[5.0,6.0],[4.0,5.0],[9.0,10.0],[6.0,7.0],[3.0,4.0],[0.0,1.0],[8.0,9.0],[2.0,3.0],[7.0,8.0],[5.0,6.0],[4.0,5.0],[1.0,2.0],[9.0,10.0],[3.0,4.0],[0.0,1.0],[2.0,3.0],[0.0,0.0],[7.0,8.0],[6.0,7.0],[8.0,9.0],[5.0,6.0],[1.0,2.0],[9.0,10.0],[3.0,4.0],[0.0,1.0],[4.0,5.0],[7.0,8.0],[6.0,7.0],[8.0,9.0],[5.0,6.0],[2.0,3.0],[1.0,2.0],[3.0,4.0],[4.0,5.0],[9.0,10.0]],\"edge_yy\":[[4.833333333333333,4.333333333333333],[0.0,-1.5],[3.333333333333333,3.333333333333333],[1.5,3.0],[2.833333333333333,3.333333333333333],[0.5,0.5],[4.333333333333333,3.833333333333333],[2.833333333333333,2.833333333333333],[3.333333333333333,1.833333333333333],[0.0,0.0],[3.0,4.333333333333333],[0.0,-0.5],[3.333333333333333,4.333333333333333],[1.5,0.0],[5.333333333333333,5.333333333333333],[0.0,0.0],[4.333333333333333,4.333333333333333],[-0.5,-0.5],[3.333333333333333,4.833333333333333],[3.0,2.833333333333333],[0.0,0.5],[1.5,1.0],[0.0,0.0],[0.0,0.0],[4.833333333333333,5.333333333333333],[3.333333333333333,2.333333333333333],[4.333333333333333,4.833333333333333],[-1.5,-1.5],[3.333333333333333,3.833333333333333],[0.0,0.0],[0.0,1.5],[1.8333333333333333,1.8333333333333333],[2.833333333333333,2.333333333333333],[2.833333333333333,2.833333333333333],[0.0,0.0],[2.833333333333333,2.833333333333333],[1.5,2.0],[1.5,1.5],[3.0,1.8333333333333333],[0.0,0.0],[3.333333333333333,2.833333333333333]],\"hypo_i\":[3,3,1,0,0,1,2,1,3,2,0,2,0,3,1,3,0,2,0,1,1,2,0,2,1,3,0,3,1,2,0,3,3,0,2,1,1,0,3,2,2],\"hypo_i_offset\":[-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8],\"hypo_i_text\":[\"#3\",\"#3\",\"#1\",\"#0\",\"#0\",\"#1\",\"#2\",\"#1\",\"#3\",\"#2\",\"#0\",\"#2\",\"#0\",\"#3\",\"#1\",\"#3\",\"#0\",\"#2\",\"#0\",\"#1\",\"#1\",\"#2\",\"#0\",\"#2\",\"#1\",\"#3\",\"#0\",\"#3\",\"#1\",\"#2\",\"#0\",\"#3\",\"#3\",\"#0\",\"#2\",\"#1\",\"#1\",\"#0\",\"#3\",\"#2\",\"#2\"],\"id\":[[7,3],[1,3],[9,1],[3,0],[8,0],[2,1],[6,2],[5,1],[10,3],[7,2],[4,0],[1,2],[9,0],[3,3],[8,1],[6,3],[5,0],[2,2],[10,0],[4,1],[1,1],[3,2],[0,0],[8,2],[7,1],[9,3],[6,0],[2,3],[10,1],[4,2],[1,0],[5,3],[8,3],[7,0],[9,2],[6,1],[3,1],[2,0],[4,3],[5,2],[10,2]],\"is_best\":[false,false,false,true,true,false,false,true,false,false,false,false,true,false,false,false,false,false,false,true,false,false,true,false,false,false,false,false,false,false,true,false,false,true,false,true,false,true,false,false,false],\"line_color\":[\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\"],\"line_width\":[1,1,1,3,3,1,1,3,1,1,1,1,3,1,1,1,1,1,1,3,1,1,3,1,1,1,1,1,1,1,3,1,1,3,1,3,1,3,1,1,1],\"parent_id\":[[6,0],[0,0],[8,0],[2,0],[7,0],[1,1],[5,0],[4,1],[9,1],[6,3],[3,0],[0,0],[8,0],[2,0],[7,1],[5,2],[4,0],[1,2],[9,1],[3,0],[0,0],[2,0],[0,0],[7,2],[6,0],[8,0],[5,0],[1,3],[9,1],[3,3],[0,0],[4,3],[7,0],[6,1],[8,2],[5,1],[2,0],[1,0],[3,0],[4,2],[9,1]],\"token\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"token_font_size\":[\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\"],\"token_id\":[1,780,25,2482,15356,2482,1879,3,17084,25,13862,5,1,7691,1,15356,25,15328,4255,11685,11,3487,-1,21342,15356,4,21342,11,1781,30,3622,3,25,1078,1,5093,26478,11,2451,13862,22624],\"token_text\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"x\":[7.0,1.0,9.0,3.0,8.0,2.0,6.0,5.0,10.0,7.0,4.0,1.0,9.0,3.0,8.0,6.0,5.0,2.0,10.0,4.0,1.0,3.0,0.0,8.0,7.0,9.0,6.0,2.0,10.0,4.0,1.0,5.0,8.0,7.0,9.0,6.0,3.0,2.0,4.0,5.0,10.0],\"y\":[4.333333333333333,-1.5,3.333333333333333,3.0,3.333333333333333,0.5,3.833333333333333,2.833333333333333,1.833333333333333,0.0,4.333333333333333,-0.5,4.333333333333333,0.0,5.333333333333333,0.0,4.333333333333333,-0.5,4.833333333333333,2.833333333333333,0.5,1.0,0.0,0.0,5.333333333333333,2.333333333333333,4.833333333333333,-1.5,3.833333333333333,0.0,1.5,1.8333333333333333,2.333333333333333,2.833333333333333,0.0,2.833333333333333,2.0,1.5,1.8333333333333333,0.0,2.833333333333333]}},\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":{\"id\":\"09035c87-81aa-4e21-b586-281eec2ac195\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"ca8bf926-99b6-41f8-aa58-31f717609a35\",\"type\":\"PanTool\"},{\"id\":\"0170b055-6020-406e-b0a6-9a42a9bb2816\",\"type\":\"BoxZoomTool\"},{\"id\":\"09035c87-81aa-4e21-b586-281eec2ac195\",\"type\":\"WheelZoomTool\"},{\"id\":\"e4e04654-061b-4633-a71e-1c9003f6bda9\",\"type\":\"WheelZoomTool\"},{\"id\":\"7d459b4a-fdec-48b5-bc95-828fb94c3c34\",\"type\":\"SaveTool\"},{\"id\":\"cacbfd1a-7e88-471a-a3c1-bc588c6af09c\",\"type\":\"ResetTool\"},{\"id\":\"7a2caa64-375a-466a-8caf-c9f17555b42d\",\"type\":\"HoverTool\"}]},\"id\":\"58f26099-07c1-4f46-ba5f-eec6d745dd12\",\"type\":\"Toolbar\"},{\"attributes\":{\"data_source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"dd1456df-a3c2-4dcc-a8aa-769ac1a8a3b2\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"vertices\",\"nonselection_glyph\":{\"id\":\"43ae4eb3-d229-4335-a758-a5d18149bd65\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"2e9dcf01-3f79-4337-b7dd-26f0525180b9\",\"type\":\"CDSView\"}},\"id\":\"eb321d59-0d82-41f4-966f-a84597d90781\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"}},\"id\":\"b0f21dbb-aa92-495c-9a38-9881564a3daa\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"a3e71058-805b-4461-9009-2e76107d0dad\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"eabb5e31-0740-4852-bcac-887155d4c0fc\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"}},\"id\":\"ddf587aa-019f-43a1-af8c-52144e732785\",\"type\":\"CDSView\"},{\"attributes\":{\"axis_label\":\"decoding step (aka output length)\",\"formatter\":{\"id\":\"f3857a7d-2e4f-4ce0-b897-cec5490c8436\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"327205fd-12df-449f-9614-e6816136cb23\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"859d93b7-acac-4853-be74-6f20da679d8b\",\"type\":\"SingleIntervalTicker\"}},\"id\":\"84db9569-9f28-4a47-82c8-bfa01402aeb6\",\"type\":\"LinearAxis\"},{\"attributes\":{\"text\":{\"field\":\"token_text\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"field\":\"token_font_size\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":-10}},\"id\":\"d4854422-d3bc-43fa-b7c0-a791e40b8a05\",\"type\":\"Text\"},{\"attributes\":{},\"id\":\"ca8bf926-99b6-41f8-aa58-31f717609a35\",\"type\":\"PanTool\"},{\"attributes\":{\"source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"}},\"id\":\"a931ac6d-24c6-489e-873f-3785a4f5cec4\",\"type\":\"CDSView\"},{\"attributes\":{\"bounds\":[-11.5,15.333333333333332],\"callback\":null,\"range_padding\":1.0,\"range_padding_units\":\"absolute\"},\"id\":\"b765029c-d346-49e8-b769-3c8155e12984\",\"type\":\"DataRange1d\"},{\"attributes\":{\"interval\":1},\"id\":\"859d93b7-acac-4853-be74-6f20da679d8b\",\"type\":\"SingleIntervalTicker\"},{\"attributes\":{\"text\":{\"field\":\"hypo_i_text\"},\"text_align\":\"center\",\"text_baseline\":\"middle\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12px\"},\"text_font_style\":\"bold\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"323b0eea-1d7f-4a0d-84fe-74a9d6ac6b56\",\"type\":\"Text\"},{\"attributes\":{\"below\":[{\"id\":\"13a5308f-70ad-452e-af22-43861fd0cb71\",\"type\":\"LinearAxis\"}],\"plot_width\":900,\"renderers\":[{\"id\":\"59657239-6604-4439-8bf1-83a5ab659d4a\",\"type\":\"BoxAnnotation\"},{\"id\":\"13a5308f-70ad-452e-af22-43861fd0cb71\",\"type\":\"LinearAxis\"},{\"id\":\"004b26cb-f235-4bd3-9464-2eed25a63945\",\"type\":\"Grid\"},{\"id\":\"0657e055-fa58-43fe-a3b8-b2b719174d8a\",\"type\":\"GlyphRenderer\"},{\"id\":\"eb321d59-0d82-41f4-966f-a84597d90781\",\"type\":\"GlyphRenderer\"},{\"id\":\"6ac35546-2a42-40c8-aa62-146d57d2f556\",\"type\":\"GlyphRenderer\"},{\"id\":\"5a71f9c4-4314-4eda-a1d8-25124c2b23d2\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"f04dd0c6-c641-4580-87f7-c0f878d1c0e6\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"3175d402-0679-462f-b9d4-d947ff7ad2b3\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"a5cebe80-c44b-4d0a-aae2-c2f3b9ef2475\",\"type\":\"Range1d\"},\"x_scale\":{\"id\":\"d8a43b51-3e35-4c6f-bb08-c7be8e8c3ce2\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"b765029c-d346-49e8-b769-3c8155e12984\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"a0929048-0a2d-4f8f-8d58-e4a6d0106ad1\",\"type\":\"LinearScale\"}},\"id\":\"91387928-8f01-4237-9a5d-24f1d6f93c23\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"8033ebc0-a196-49a8-acdc-dbc0ae3fcf54\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"data_source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"d4854422-d3bc-43fa-b7c0-a791e40b8a05\",\"type\":\"Text\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"tokens\",\"nonselection_glyph\":{\"id\":\"17a29716-8304-471c-9f48-6dd74ade100a\",\"type\":\"Text\"},\"selection_glyph\":null,\"view\":{\"id\":\"5d7f1257-5695-4ee0-8fe7-f29e498f83c7\",\"type\":\"CDSView\"}},\"id\":\"6ac35546-2a42-40c8-aa62-146d57d2f556\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"text\":{\"field\":\"hypo_i_text\"},\"text_align\":\"center\",\"text_alpha\":{\"value\":0.1},\"text_baseline\":\"middle\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12px\"},\"text_font_style\":\"bold\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"a10f3b4a-982e-4c44-b026-f8088199fe6f\",\"type\":\"Text\"},{\"attributes\":{\"plot\":{\"id\":\"327205fd-12df-449f-9614-e6816136cb23\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"21b07e0f-be09-4617-8f50-6b55adf59566\",\"type\":\"SingleIntervalTicker\"}},\"id\":\"d3dfd7db-0295-4068-89b6-6a86f9141772\",\"type\":\"Grid\"},{\"attributes\":{\"plot\":null,\"text\":\"Beam search\"},\"id\":\"f04dd0c6-c641-4580-87f7-c0f878d1c0e6\",\"type\":\"Title\"},{\"attributes\":{\"data_source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"323b0eea-1d7f-4a0d-84fe-74a9d6ac6b56\",\"type\":\"Text\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"hypo_i\",\"nonselection_glyph\":{\"id\":\"a10f3b4a-982e-4c44-b026-f8088199fe6f\",\"type\":\"Text\"},\"selection_glyph\":null,\"view\":{\"id\":\"b0f21dbb-aa92-495c-9a38-9881564a3daa\",\"type\":\"CDSView\"}},\"id\":\"d6b0d875-955c-493f-8f95-7f155de46db0\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"}},\"id\":\"5d7f1257-5695-4ee0-8fe7-f29e498f83c7\",\"type\":\"CDSView\"},{\"attributes\":{\"overlay\":{\"id\":\"8033ebc0-a196-49a8-acdc-dbc0ae3fcf54\",\"type\":\"BoxAnnotation\"}},\"id\":\"0170b055-6020-406e-b0a6-9a42a9bb2816\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"bounds\":[-10.0,20.0],\"callback\":null,\"end\":12,\"js_property_callbacks\":{\"change:end\":[{\"id\":\"b56f32a3-d365-46b7-9f4f-323382959b2d\",\"type\":\"CustomJS\"}]},\"start\":-1},\"id\":\"a5cebe80-c44b-4d0a-aae2-c2f3b9ef2475\",\"type\":\"Range1d\"},{\"attributes\":{\"dimensions\":\"width\"},\"id\":\"09035c87-81aa-4e21-b586-281eec2ac195\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":{\"id\":\"fbfb1ccf-b06f-43d0-93b8-b7a2feb2e51e\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"cab35414-b6a5-47d8-a8cd-55b26f7a7b54\",\"type\":\"PanTool\"},{\"id\":\"64b6f55d-2417-4701-8845-e39dd839273e\",\"type\":\"BoxZoomTool\"},{\"id\":\"fbfb1ccf-b06f-43d0-93b8-b7a2feb2e51e\",\"type\":\"WheelZoomTool\"},{\"id\":\"7a97466a-a0c3-4c9a-93bc-f7d1909c09da\",\"type\":\"WheelZoomTool\"},{\"id\":\"a8cad25e-8062-4326-b4df-8b1d1db279c7\",\"type\":\"SaveTool\"},{\"id\":\"237d0e16-242f-45d0-81da-35c5b34ecdb4\",\"type\":\"ResetTool\"},{\"id\":\"ce962e54-6eaa-4a63-b602-ab2387d43716\",\"type\":\"HoverTool\"}]},\"id\":\"3175d402-0679-462f-b9d4-d947ff7ad2b3\",\"type\":\"Toolbar\"},{\"attributes\":{\"dimensions\":\"height\"},\"id\":\"e4e04654-061b-4633-a71e-1c9003f6bda9\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"text\":{\"field\":\"hypo_i_text\"},\"text_align\":\"center\",\"text_baseline\":\"middle\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12px\"},\"text_font_style\":\"bold\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"8c80ac74-34fc-4790-a100-c62b151ded39\",\"type\":\"Text\"},{\"attributes\":{},\"id\":\"a0929048-0a2d-4f8f-8d58-e4a6d0106ad1\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"7d459b4a-fdec-48b5-bc95-828fb94c3c34\",\"type\":\"SaveTool\"},{\"attributes\":{\"text\":{\"field\":\"hypo_i_text\"},\"text_align\":\"center\",\"text_alpha\":{\"value\":0.1},\"text_baseline\":\"middle\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12px\"},\"text_font_style\":\"bold\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1aaad8cb-1c94-4061-b4ce-f70e91e33b07\",\"type\":\"Text\"},{\"attributes\":{},\"id\":\"d8a43b51-3e35-4c6f-bb08-c7be8e8c3ce2\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"cacbfd1a-7e88-471a-a3c1-bc588c6af09c\",\"type\":\"ResetTool\"},{\"attributes\":{\"data_source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"8c80ac74-34fc-4790-a100-c62b151ded39\",\"type\":\"Text\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"hypo_i\",\"nonselection_glyph\":{\"id\":\"1aaad8cb-1c94-4061-b4ce-f70e91e33b07\",\"type\":\"Text\"},\"selection_glyph\":null,\"view\":{\"id\":\"a931ac6d-24c6-489e-873f-3785a4f5cec4\",\"type\":\"CDSView\"}},\"id\":\"5a71f9c4-4314-4eda-a1d8-25124c2b23d2\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"names\":[\"vertices\"],\"tooltips\":[[\"token\",\"@_on_hover_token\"],[\"token_id\",\"@_on_hover_token_id\"],[\"score\",\"@_on_hover_score\"]]},\"id\":\"7a2caa64-375a-466a-8caf-c9f17555b42d\",\"type\":\"HoverTool\"},{\"attributes\":{\"interval\":1},\"id\":\"21b07e0f-be09-4617-8f50-6b55adf59566\",\"type\":\"SingleIntervalTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"59657239-6604-4439-8bf1-83a5ab659d4a\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"axis_label\":\"decoding step (aka output length)\",\"formatter\":{\"id\":\"e26ba807-3a3a-43be-8db2-601d280799bd\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"91387928-8f01-4237-9a5d-24f1d6f93c23\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"c0496269-9e06-46af-ab94-5438bfbff629\",\"type\":\"SingleIntervalTicker\"}},\"id\":\"13a5308f-70ad-452e-af22-43861fd0cb71\",\"type\":\"LinearAxis\"},{\"attributes\":{\"interval\":1},\"id\":\"c0496269-9e06-46af-ab94-5438bfbff629\",\"type\":\"SingleIntervalTicker\"},{\"attributes\":{\"args\":{\"source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"}},\"code\":\"\\n            var x_range = cb_obj;\\n            var font_size = Math.round(14 * 13.0 / (x_range.end - x_range.start));\\n\\n            font_size = Math.min(24, Math.max(font_size, 0));\\n            \\n            var data = source.data;\\n            var fs = data['token_font_size']\\n            \\n            for (var i = 0; i < fs.length; i++)\\n                fs[i] = font_size.toString() + \\\"px\\\";\\n            \\n            source.change.emit();\\n        \"},\"id\":\"eab13fb4-9405-4d14-8bf6-46c6f698b4bb\",\"type\":\"CustomJS\"},{\"attributes\":{},\"id\":\"cab35414-b6a5-47d8-a8cd-55b26f7a7b54\",\"type\":\"PanTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"size\":{\"units\":\"screen\",\"value\":24},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"d47ea423-d422-49a0-b24d-798a01f47236\",\"type\":\"Circle\"},{\"attributes\":{\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"xs\":{\"field\":\"edge_xx\"},\"ys\":{\"field\":\"edge_yy\"}},\"id\":\"d4677ed5-e7ac-4a9f-960d-0463a72b4947\",\"type\":\"MultiLine\"},{\"attributes\":{\"callback\":null,\"names\":[\"vertices\"],\"tooltips\":[[\"token\",\"@_on_hover_token\"],[\"token_id\",\"@_on_hover_token_id\"],[\"score\",\"@_on_hover_score\"]]},\"id\":\"ce962e54-6eaa-4a63-b602-ab2387d43716\",\"type\":\"HoverTool\"},{\"attributes\":{\"overlay\":{\"id\":\"59657239-6604-4439-8bf1-83a5ab659d4a\",\"type\":\"BoxAnnotation\"}},\"id\":\"64b6f55d-2417-4701-8845-e39dd839273e\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"xs\":{\"field\":\"edge_xx\"},\"ys\":{\"field\":\"edge_yy\"}},\"id\":\"72b704fc-ca92-4d86-89ae-f33aeb3c23a8\",\"type\":\"MultiLine\"},{\"attributes\":{\"dimensions\":\"width\"},\"id\":\"fbfb1ccf-b06f-43d0-93b8-b7a2feb2e51e\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"xs\":{\"field\":\"edge_xx\"},\"ys\":{\"field\":\"edge_yy\"}},\"id\":\"5574258e-e46b-409c-af99-02931bf42c33\",\"type\":\"MultiLine\"},{\"attributes\":{\"fill_color\":{\"field\":\"circle_fill_color\"},\"line_color\":{\"field\":\"line_color\"},\"line_width\":{\"field\":\"line_width\"},\"size\":{\"units\":\"screen\",\"value\":24},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"dd1456df-a3c2-4dcc-a8aa-769ac1a8a3b2\",\"type\":\"Circle\"},{\"attributes\":{\"dimensions\":\"height\"},\"id\":\"7a97466a-a0c3-4c9a-93bc-f7d1909c09da\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"fill_color\":{\"field\":\"circle_fill_color\"},\"line_color\":{\"field\":\"line_color\"},\"line_width\":{\"field\":\"line_width\"},\"size\":{\"units\":\"screen\",\"value\":24},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"14c2f957-8e96-40e9-8d5a-bbe84ee0131a\",\"type\":\"Circle\"},{\"attributes\":{\"args\":{\"source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"}},\"code\":\"\\n            var x_range = cb_obj;\\n            var font_size = Math.round(14 * 13.0 / (x_range.end - x_range.start));\\n\\n            font_size = Math.min(24, Math.max(font_size, 0));\\n            \\n            var data = source.data;\\n            var fs = data['token_font_size']\\n            \\n            for (var i = 0; i < fs.length; i++)\\n                fs[i] = font_size.toString() + \\\"px\\\";\\n            \\n            source.change.emit();\\n        \"},\"id\":\"b56f32a3-d365-46b7-9f4f-323382959b2d\",\"type\":\"CustomJS\"},{\"attributes\":{},\"id\":\"a8cad25e-8062-4326-b4df-8b1d1db279c7\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"237d0e16-242f-45d0-81da-35c5b34ecdb4\",\"type\":\"ResetTool\"},{\"attributes\":{\"data_source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"5574258e-e46b-409c-af99-02931bf42c33\",\"type\":\"MultiLine\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"edges\",\"nonselection_glyph\":{\"id\":\"72b704fc-ca92-4d86-89ae-f33aeb3c23a8\",\"type\":\"MultiLine\"},\"selection_glyph\":null,\"view\":{\"id\":\"95e7b794-7dda-4997-b7c6-a664964f6b5a\",\"type\":\"CDSView\"}},\"id\":\"978e683c-44ae-4bb3-b7d1-4660f2415803\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"interval\":1},\"id\":\"aaf5ec9a-6f51-45f4-a1b5-d2a8ac2cb5e0\",\"type\":\"SingleIntervalTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"14c2f957-8e96-40e9-8d5a-bbe84ee0131a\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"vertices\",\"nonselection_glyph\":{\"id\":\"d47ea423-d422-49a0-b24d-798a01f47236\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"dd940c41-87e6-4094-8be6-3dc7f22f0921\",\"type\":\"CDSView\"}},\"id\":\"cdf3b0e4-fe4f-450f-86d4-c51260c5d8c0\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"plot\":{\"id\":\"91387928-8f01-4237-9a5d-24f1d6f93c23\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"aaf5ec9a-6f51-45f4-a1b5-d2a8ac2cb5e0\",\"type\":\"SingleIntervalTicker\"}},\"id\":\"004b26cb-f235-4bd3-9464-2eed25a63945\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"}},\"id\":\"b553c853-cc22-4ae3-aea6-95ad360ad0fc\",\"type\":\"CDSView\"},{\"attributes\":{\"source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"}},\"id\":\"95e7b794-7dda-4997-b7c6-a664964f6b5a\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"id\",\"parent_id\",\"children_ids\",\"is_best\",\"depth\",\"hypo_i\",\"token\",\"token_id\",\"x\",\"y\",\"circle_fill_color\",\"line_color\",\"line_width\",\"edge_xx\",\"edge_yy\",\"token_text\",\"token_font_size\",\"hypo_i_text\",\"hypo_i_offset\",\"_on_hover_token\",\"_on_hover_token_id\",\"_on_hover_score\"],\"data\":{\"_on_hover_score\":[\"-4.7282\",\"-4.2071\",\"-4.8782\",\"-1.3577\",\"-4.0420\",\"-4.2097\",\"-4.5624\",\"-3.2410\",\"-6.9225\",\"-4.6717\",\"-2.8497\",\"-3.8023\",\"-4.1460\",\"-3.6443\",\"-4.3135\",\"-4.7070\",\"-3.1373\",\"-4.5105\",\"-6.1526\",\"-3.0974\",\"-3.7421\",\"-3.4956\",\"0.0000\",\"-5.2694\",\"-4.4104\",\"-6.1752\",\"-3.7617\",\"-4.6281\",\"-6.5626\",\"-3.7175\",\"-0.7384\",\"-4.5439\",\"-5.2967\",\"-3.6831\",\"-5.2153\",\"-3.7830\",\"-3.1335\",\"-0.8716\",\"-3.7312\",\"-3.8895\",\"-6.5984\"],\"_on_hover_token\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"_on_hover_token_id\":[1,780,25,2482,15356,2482,1879,3,17084,25,13862,5,1,7691,1,15356,25,15328,4255,11685,11,3487,-1,21342,15356,4,21342,11,1781,30,3622,3,25,1078,1,5093,26478,11,2451,13862,22624],\"children_ids\":[[],[[2,3]],[[10,3],[10,2],[10,1],[10,0]],[[4,3],[4,1],[4,0]],[[9,3],[9,1],[9,0]],[],[],[[6,1]],[],[[8,2]],[[5,0]],[[2,2]],[],[[4,2]],[],[[7,2]],[[6,2],[6,0]],[],[],[[5,1]],[[2,1]],[],[[1,3],[1,2],[1,1],[1,0]],[[9,2]],[[8,1]],[],[[7,3],[7,1]],[],[],[[5,2]],[[2,0]],[],[],[[8,3],[8,0]],[],[[7,0]],[],[[3,3],[3,2],[3,1],[3,0]],[[5,3]],[[6,3]],[]],\"circle_fill_color\":[\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\"],\"depth\":[7,1,9,3,8,2,6,5,10,7,4,1,9,3,8,6,5,2,10,4,1,3,0,8,7,9,6,2,10,4,1,5,8,7,9,6,3,2,4,5,10],\"edge_xx\":[[6.0,7.0],[0.0,1.0],[8.0,9.0],[2.0,3.0],[7.0,8.0],[1.0,2.0],[5.0,6.0],[4.0,5.0],[9.0,10.0],[6.0,7.0],[3.0,4.0],[0.0,1.0],[8.0,9.0],[2.0,3.0],[7.0,8.0],[5.0,6.0],[4.0,5.0],[1.0,2.0],[9.0,10.0],[3.0,4.0],[0.0,1.0],[2.0,3.0],[0.0,0.0],[7.0,8.0],[6.0,7.0],[8.0,9.0],[5.0,6.0],[1.0,2.0],[9.0,10.0],[3.0,4.0],[0.0,1.0],[4.0,5.0],[7.0,8.0],[6.0,7.0],[8.0,9.0],[5.0,6.0],[2.0,3.0],[1.0,2.0],[3.0,4.0],[4.0,5.0],[9.0,10.0]],\"edge_yy\":[[4.833333333333333,4.333333333333333],[0.0,-1.5],[3.333333333333333,3.333333333333333],[1.5,3.0],[2.833333333333333,3.333333333333333],[0.5,0.5],[4.333333333333333,3.833333333333333],[2.833333333333333,2.833333333333333],[3.333333333333333,1.833333333333333],[0.0,0.0],[3.0,4.333333333333333],[0.0,-0.5],[3.333333333333333,4.333333333333333],[1.5,0.0],[5.333333333333333,5.333333333333333],[0.0,0.0],[4.333333333333333,4.333333333333333],[-0.5,-0.5],[3.333333333333333,4.833333333333333],[3.0,2.833333333333333],[0.0,0.5],[1.5,1.0],[0.0,0.0],[0.0,0.0],[4.833333333333333,5.333333333333333],[3.333333333333333,2.333333333333333],[4.333333333333333,4.833333333333333],[-1.5,-1.5],[3.333333333333333,3.833333333333333],[0.0,0.0],[0.0,1.5],[1.8333333333333333,1.8333333333333333],[2.833333333333333,2.333333333333333],[2.833333333333333,2.833333333333333],[0.0,0.0],[2.833333333333333,2.833333333333333],[1.5,2.0],[1.5,1.5],[3.0,1.8333333333333333],[0.0,0.0],[3.333333333333333,2.833333333333333]],\"hypo_i\":[3,3,1,0,0,1,2,1,3,2,0,2,0,3,1,3,0,2,0,1,1,2,0,2,1,3,0,3,1,2,0,3,3,0,2,1,1,0,3,2,2],\"hypo_i_offset\":[-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8],\"hypo_i_text\":[\"#3\",\"#3\",\"#1\",\"#0\",\"#0\",\"#1\",\"#2\",\"#1\",\"#3\",\"#2\",\"#0\",\"#2\",\"#0\",\"#3\",\"#1\",\"#3\",\"#0\",\"#2\",\"#0\",\"#1\",\"#1\",\"#2\",\"#0\",\"#2\",\"#1\",\"#3\",\"#0\",\"#3\",\"#1\",\"#2\",\"#0\",\"#3\",\"#3\",\"#0\",\"#2\",\"#1\",\"#1\",\"#0\",\"#3\",\"#2\",\"#2\"],\"id\":[[7,3],[1,3],[9,1],[3,0],[8,0],[2,1],[6,2],[5,1],[10,3],[7,2],[4,0],[1,2],[9,0],[3,3],[8,1],[6,3],[5,0],[2,2],[10,0],[4,1],[1,1],[3,2],[0,0],[8,2],[7,1],[9,3],[6,0],[2,3],[10,1],[4,2],[1,0],[5,3],[8,3],[7,0],[9,2],[6,1],[3,1],[2,0],[4,3],[5,2],[10,2]],\"is_best\":[false,false,false,true,true,false,false,true,false,false,false,false,true,false,false,false,false,false,false,true,false,false,true,false,false,false,false,false,false,false,true,false,false,true,false,true,false,true,false,false,false],\"line_color\":[\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\"],\"line_width\":[1,1,1,3,3,1,1,3,1,1,1,1,3,1,1,1,1,1,1,3,1,1,3,1,1,1,1,1,1,1,3,1,1,3,1,3,1,3,1,1,1],\"parent_id\":[[6,0],[0,0],[8,0],[2,0],[7,0],[1,1],[5,0],[4,1],[9,1],[6,3],[3,0],[0,0],[8,0],[2,0],[7,1],[5,2],[4,0],[1,2],[9,1],[3,0],[0,0],[2,0],[0,0],[7,2],[6,0],[8,0],[5,0],[1,3],[9,1],[3,3],[0,0],[4,3],[7,0],[6,1],[8,2],[5,1],[2,0],[1,0],[3,0],[4,2],[9,1]],\"token\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"token_font_size\":[\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\"],\"token_id\":[1,780,25,2482,15356,2482,1879,3,17084,25,13862,5,1,7691,1,15356,25,15328,4255,11685,11,3487,-1,21342,15356,4,21342,11,1781,30,3622,3,25,1078,1,5093,26478,11,2451,13862,22624],\"token_text\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"x\":[7.0,1.0,9.0,3.0,8.0,2.0,6.0,5.0,10.0,7.0,4.0,1.0,9.0,3.0,8.0,6.0,5.0,2.0,10.0,4.0,1.0,3.0,0.0,8.0,7.0,9.0,6.0,2.0,10.0,4.0,1.0,5.0,8.0,7.0,9.0,6.0,3.0,2.0,4.0,5.0,10.0],\"y\":[4.333333333333333,-1.5,3.333333333333333,3.0,3.333333333333333,0.5,3.833333333333333,2.833333333333333,1.833333333333333,0.0,4.333333333333333,-0.5,4.333333333333333,0.0,5.333333333333333,0.0,4.333333333333333,-0.5,4.833333333333333,2.833333333333333,0.5,1.0,0.0,0.0,5.333333333333333,2.333333333333333,4.833333333333333,-1.5,3.833333333333333,0.0,1.5,1.8333333333333333,2.333333333333333,2.833333333333333,0.0,2.833333333333333,2.0,1.5,1.8333333333333333,0.0,2.833333333333333]}},\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"e26ba807-3a3a-43be-8db2-601d280799bd\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"xs\":{\"field\":\"edge_xx\"},\"ys\":{\"field\":\"edge_yy\"}},\"id\":\"d41b7979-8903-4ee5-a861-1bf88bfb14ea\",\"type\":\"MultiLine\"},{\"attributes\":{\"source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"}},\"id\":\"dd940c41-87e6-4094-8be6-3dc7f22f0921\",\"type\":\"CDSView\"},{\"attributes\":{\"text\":{\"field\":\"token_text\"},\"text_align\":\"center\",\"text_alpha\":{\"value\":0.1},\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"field\":\"token_font_size\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":-10}},\"id\":\"17a29716-8304-471c-9f48-6dd74ade100a\",\"type\":\"Text\"},{\"attributes\":{},\"id\":\"f3857a7d-2e4f-4ce0-b897-cec5490c8436\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data_source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"d4677ed5-e7ac-4a9f-960d-0463a72b4947\",\"type\":\"MultiLine\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"edges\",\"nonselection_glyph\":{\"id\":\"d41b7979-8903-4ee5-a861-1bf88bfb14ea\",\"type\":\"MultiLine\"},\"selection_glyph\":null,\"view\":{\"id\":\"b553c853-cc22-4ae3-aea6-95ad360ad0fc\",\"type\":\"CDSView\"}},\"id\":\"0657e055-fa58-43fe-a3b8-b2b719174d8a\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"text\":{\"field\":\"token_text\"},\"text_align\":\"center\",\"text_alpha\":{\"value\":0.1},\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"field\":\"token_font_size\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":-10}},\"id\":\"3621fd59-3cb3-4305-8802-6f7f75a23fd6\",\"type\":\"Text\"},{\"attributes\":{\"bounds\":[-11.5,15.333333333333332],\"callback\":null,\"range_padding\":1.0,\"range_padding_units\":\"absolute\"},\"id\":\"3868f6e3-8193-418f-af89-ee5749e490a1\",\"type\":\"DataRange1d\"},{\"attributes\":{\"text\":{\"field\":\"token_text\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"field\":\"token_font_size\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":-10}},\"id\":\"08bbcb52-00b5-4803-9e7a-9252db09708d\",\"type\":\"Text\"},{\"attributes\":{\"below\":[{\"id\":\"84db9569-9f28-4a47-82c8-bfa01402aeb6\",\"type\":\"LinearAxis\"}],\"plot_width\":900,\"renderers\":[{\"id\":\"8033ebc0-a196-49a8-acdc-dbc0ae3fcf54\",\"type\":\"BoxAnnotation\"},{\"id\":\"84db9569-9f28-4a47-82c8-bfa01402aeb6\",\"type\":\"LinearAxis\"},{\"id\":\"d3dfd7db-0295-4068-89b6-6a86f9141772\",\"type\":\"Grid\"},{\"id\":\"978e683c-44ae-4bb3-b7d1-4660f2415803\",\"type\":\"GlyphRenderer\"},{\"id\":\"cdf3b0e4-fe4f-450f-86d4-c51260c5d8c0\",\"type\":\"GlyphRenderer\"},{\"id\":\"a2ab1853-0966-4519-874f-956f801f1c72\",\"type\":\"GlyphRenderer\"},{\"id\":\"d6b0d875-955c-493f-8f95-7f155de46db0\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"5af81591-5793-4721-a459-e0a4ca700855\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"58f26099-07c1-4f46-ba5f-eec6d745dd12\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"14e9976c-9458-4bce-be96-da2f3c304cec\",\"type\":\"Range1d\"},\"x_scale\":{\"id\":\"eabb5e31-0740-4852-bcac-887155d4c0fc\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"3868f6e3-8193-418f-af89-ee5749e490a1\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"a3e71058-805b-4461-9009-2e76107d0dad\",\"type\":\"LinearScale\"}},\"id\":\"327205fd-12df-449f-9614-e6816136cb23\",\"subtype\":\"Figure\",\"type\":\"Plot\"}],\"root_ids\":[\"327205fd-12df-449f-9614-e6816136cb23\",\"91387928-8f01-4237-9a5d-24f1d6f93c23\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.7\"}};\n",
       "              var render_items = [{\"docid\":\"ba84f797-d201-498d-a731-5adafa5447b7\",\"elementid\":\"ff8c3f31-952d-4c2f-8b58-13e7cec51b58\",\"modelid\":\"91387928-8f01-4237-9a5d-24f1d6f93c23\"}];\n",
       "              \n",
       "              Bokeh.embed.embed_items(docs_json, render_items);\n",
       "            });\n",
       "          };\n",
       "          if (document.readyState != \"loading\") fn();\n",
       "          else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "        })();\n",
       "        \n",
       "        </script>\n",
       "    </body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "# Here's what it looks like:\n",
    "!wget -q https://raw.githubusercontent.com/yandexdataschool/nlp_course/2020/resources/beam_search.html\n",
    "HTML(\"beam_search.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_beamsearch(model, prefix=BOS, beam_size=4, length=5):\n",
    "    \"\"\"\n",
    "    Generate a sequence with nucleous sampling\n",
    "    :param prefix: a string containing space-separated previous tokens\n",
    "    :param nucleus: N from the formulae above, N \\in [0, 1]\n",
    "    :param length: generate sequences with at most this many tokens, NOT INCLUDING PREFIX\n",
    "    :returns: beam_size most likely candidates\n",
    "    :note: make sure that nucleous always contains at least one word, even if p(w*) > nucleus\n",
    "    \"\"\"\n",
    "    \n",
    "    <YOUR CODE HERE>\n",
    "    \n",
    "    return <most likely sequence>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_beamsearch(model, prefix=' deep ', beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check it out: which beam size works best?\n",
    "# find at least 5 prefixes where beam_size=1 and 8 generates different sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus quest II: Ultimate Language Model (2+ pts)\n",
    "\n",
    "So you've learned the building blocks of neural language models, you can now build the ultimate monster:  \n",
    "* Make it char-level, word level or maybe use sub-word units like [bpe](https://github.com/rsennrich/subword-nmt);\n",
    "* Combine convolutions, recurrent cells, pre-trained embeddings and all the black magic deep learning has to offer;\n",
    "  * Use strides to get larger window size quickly. Here's a [scheme](https://storage.googleapis.com/deepmind-live-cms/documents/BlogPost-Fig2-Anim-160908-r01.gif) from google wavenet.\n",
    "* Train on large data. Like... really large. Try [1 Billion Words](http://www.statmt.org/lm-benchmark/1-billion-word-language-modeling-benchmark-r13output.tar.gz) benchmark;\n",
    "* Use training schedules to speed up training. Start with small length and increase over time; Take a look at [one cycle](https://medium.com/@nachiket.tanksale/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6) for learning rate;\n",
    "\n",
    "_You are NOT required to submit this assignment. Please make sure you don't miss your deadline because of it :)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits: batch * output * embeddings\n",
    "\n",
    "lengths = compute_lengths(reference_answers) # batch\n",
    "\n",
    "# batch * output\n",
    "# tf.sequence_mask(lengths, logits.shape[1])\n",
    "\n",
    "# batch * logits.shape[1] * logits.shape[2] \n",
    "ttt = tf.stack(\n",
    "    [tf.sequence_mask(lengths, logits.shape[1])]*logits.shape[2], axis=-1, name='stack'\n",
    ")\n",
    "ans_class = tf.where(ttt,softmax_output,[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
